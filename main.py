import requests
import os
import re
import time
import json
import random
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from bs4 import BeautifulSoup
from threading import Lock, Thread
from queue import Queue
import logging
from logging.handlers import RotatingFileHandler
from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type
from collections import defaultdict
import urllib3

# ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ SSL Insecure
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==============================================================================
# --- Ø¨Ø®Ø´ Û±: ØªÙˆØ§Ø¨Ø¹ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ù†Ø¹Ø·Ù Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ ---
# Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ù‡ Ø´Ù…Ø§ Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ø¨Ø§ ÛŒÚ© Ø±Ø´ØªÙ‡ Ù…ØªÙ†ÛŒØŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§
# Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ø³ÛŒØ§Ø± Ø¯Ù‚ÛŒÙ‚ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.
# ==============================================================================
def parse_selected_ids_string(selected_ids_string):
    """Ø±Ø´ØªÙ‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù… ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    result = []
    for part in selected_ids_string.split('|'):
        part = part.strip()
        if not part or ':' not in part:
            continue
        parent_id_str, children_str = part.split(':', 1)
        parent_id = int(parent_id_str.strip())
        selections = []
        for sel in children_str.split(','):
            sel = sel.strip()
            if not sel: continue
            if sel == 'all':
                selections.append({"id": parent_id, "type": "all_subcats"})
            elif sel == 'allz':
                selections.append({"id": parent_id, "type": "only_products"})
            elif sel == 'all-allz':
                selections.append({"id": parent_id, "type": "all_subcats_and_products"})
            elif re.match(r'^\d+-allz$', sel):
                sub_id = int(sel.split('-')[0])
                selections.append({"id": sub_id, "type": "only_products"})
            elif re.match(r'^\d+-all-allz$', sel):
                sub_id = int(sel.split('-')[0])
                selections.append({"id": sub_id, "type": "all_subcats_and_products"})
        result.append({"parent_id": parent_id, "selections": selections})
    return result

def get_direct_subcategories(parent_id, all_cats):
    """ØªÙ…Ø§Ù… Ø²ÛŒØ±Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… ÛŒÚ© Ø¯Ø³ØªÙ‡ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯."""
    return [cat['id'] for cat in all_cats if cat.get('parent_id') == parent_id]

def get_all_subcategories(parent_id, all_cats):
    """ØªÙ…Ø§Ù… Ø²ÛŒØ±Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒÚ© Ø¯Ø³ØªÙ‡ (Ù…Ø³ØªÙ‚ÛŒÙ… Ùˆ ØºÛŒØ±Ù…Ø³ØªÙ‚ÛŒÙ…) Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    result = []
    direct = get_direct_subcategories(parent_id, all_cats)
    result.extend(direct)
    for sub_id in direct:
        result.extend(get_all_subcategories(sub_id, all_cats))
    return result

def get_selected_categories_according_to_selection(parsed_selection, all_cats):
    """Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ØŒ Ù„ÛŒØ³Øª Ù†Ù‡Ø§ÛŒÛŒ Ø¢ÛŒâ€ŒØ¯ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯."""
    selected_ids = set()
    for block in parsed_selection:
        parent_id = block['parent_id']
        for sel in block['selections']:
            cat_id_to_process = sel['id']
            if sel['type'] == 'all_subcats':
                selected_ids.add(cat_id_to_process)
                selected_ids.update(get_direct_subcategories(cat_id_to_process, all_cats))
            elif sel['type'] == 'only_products':
                selected_ids.add(cat_id_to_process)
            elif sel['type'] == 'all_subcats_and_products':
                selected_ids.add(cat_id_to_process)
                selected_ids.update(get_all_subcategories(cat_id_to_process, all_cats))
    return [cat for cat in all_cats if cat['id'] in selected_ids]

# ==============================================================================
# --- Ø¨Ø®Ø´ Û²: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³Ø±Ø§Ø³Ø±ÛŒ Ùˆ Ù„Ø§Ú¯ÛŒÙ†Ú¯ ---
# ==============================================================================
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ Ø«Ø¨Øª ÙˆÙ‚Ø§ÛŒØ¹ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„ Ùˆ ÙØ§ÛŒÙ„
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', handlers=[logging.StreamHandler()])
logger = logging.getLogger(__name__)
# Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ Ú©Ù‡ Ø¨Ø§ Ø­Ø¬Ù… 5 Ù…Ú¯Ø§Ø¨Ø§ÛŒØª Ù…ÛŒâ€ŒÚ†Ø±Ø®Ø¯
handler = RotatingFileHandler('eways_sync.log', maxBytes=5*1024*1024, backupCount=5, encoding='utf-8')
handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)

# Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ (eways)
BASE_URL = "https://panel.eways.co"
SOURCE_CATS_API_URL = f"{BASE_URL}/Store/GetCategories"
PRODUCT_LIST_URL_TEMPLATE = f"{BASE_URL}/Store/List/{{category_id}}/2/2/0/0/0/10000000000?page={{page}}"
PRODUCT_DETAIL_URL_TEMPLATE = f"{BASE_URL}/Store/Detail/{{cat_id}}/{{product_id}}"

# Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø§ÛŒØª Ù…Ù‚ØµØ¯ (ÙˆÙˆÚ©Ø§Ù…Ø±Ø³) - Ø¨Ù‡ØªØ± Ø§Ø³Øª Ø§Ø² Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´ÙˆØ¯
WC_API_URL = os.environ.get("WC_API_URL", "https://your-site.com/wp-json/wc/v3")
WC_CONSUMER_KEY = os.environ.get("WC_CONSUMER_KEY", "ck_your_key")
WC_CONSUMER_SECRET = os.environ.get("WC_CONSUMER_SECRET", "cs_your_secret")

# Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±ÛŒ eways
EWAYS_USERNAME = os.environ.get("EWAYS_USERNAME", "your_eways_username")
EWAYS_PASSWORD = os.environ.get("EWAYS_PASSWORD", "your_eways_password")

# ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¨ÛŒÙ† Ø§Ø¬Ø±Ø§Ù‡Ø§
CACHE_FILE = 'products_cache.json'
WC_PRODUCT_IDS_CACHE_FILE = 'wc_product_ids.json'

# ==============================================================================
# --- Ø¨Ø®Ø´ Û³: ØªÙˆØ§Ø¨Ø¹ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ (eways) ---
# ==============================================================================
def login_eways(username, password):
    """Ø¨Ø±Ø§ÛŒ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ Ø³Ø§ÛŒØª eways Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ú©ÙˆÚ©ÛŒ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª."""
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    })
    session.verify = False # ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø¨Ø±Ø±Ø³ÛŒ SSL

    login_url = f"{BASE_URL}/User/Login"
    payload = {"UserName": username, "Password": password, "RememberMe": "true"}
    logger.info("â³ Ø¯Ø± Ø­Ø§Ù„ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ Ù¾Ù†Ù„ eways ...")
    try:
        resp = session.post(login_url, data=payload, timeout=30)
        resp.raise_for_status()
        if 'Aut' in session.cookies:
            logger.info("âœ… Ù„Ø§Ú¯ÛŒÙ† Ù…ÙˆÙÙ‚! Ú©ÙˆÚ©ÛŒ 'Aut' Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
            return session
        else:
            logger.error("âŒ Ú©ÙˆÚ©ÛŒ 'Aut' Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±ÛŒ ÛŒØ§ ÙˆØ¶Ø¹ÛŒØª Ú©Ù¾Ú†Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
            return None
    except requests.RequestException as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ù„Ø§Ú¯ÛŒÙ†: {e}")
        return None

@retry(retry=retry_if_exception_type(requests.RequestException), stop=stop_after_attempt(5), wait=wait_random_exponential(multiplier=1, max=10))
def get_product_details(session, cat_id, product_id):
    """Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ù…Ø´Ø®ØµØ§Øª ÙÙ†ÛŒ ÛŒÚ© Ù…Ø­ØµÙˆÙ„ Ø±Ø§ Ø§Ø² ØµÙØ­Ù‡ Ø¢Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    url = PRODUCT_DETAIL_URL_TEMPLATE.format(cat_id=cat_id, product_id=product_id)
    try:
        response = session.get(url, timeout=45)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        specs_table = soup.select_one('#link1 .table-responsive table, .table-responsive table, table.table')
        if not specs_table:
            return {}
        specs = {}
        for row in specs_table.find_all("tr"):
            cells = row.find_all("td")
            if len(cells) == 2:
                key, value = cells[0].text.strip(), cells[1].text.strip()
                if key and value:
                    specs[key] = value
        return specs
    except requests.RequestException as e:
        logger.warning(f"      - Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}. ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...")
        raise
    except Exception as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}")
        return {}

def get_and_parse_categories(session):
    """Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    logger.info(f"â³ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø² eways...")
    try:
        response = session.get(SOURCE_CATS_API_URL, timeout=30)
        response.raise_for_status()
        data = response.json()
        final_cats = []
        for c in data:
            real_id_match = re.search(r'/Store/List/(\d+)', c.get('url', ''))
            real_id = int(real_id_match.group(1)) if real_id_match else c.get('id')
            final_cats.append({
                "id": real_id,
                "name": c.get('name', '').strip(),
                "parent_id": c.get('parent_id')
            })
        logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø² API Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
        return final_cats
    except (requests.RequestException, json.JSONDecodeError) as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None

@retry(retry=retry_if_exception_type(requests.RequestException), stop=stop_after_attempt(3), wait=wait_random_exponential(multiplier=1.5, max=15))
def get_available_products_from_category_page(session, category_id, delay=0.4):
    """ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø±Ø§ Ø§Ø² ÛŒÚ© ØµÙØ­Ù‡ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    available_products = []
    seen_product_ids = set()
    page_num = 1
    while True:
        url = PRODUCT_LIST_URL_TEMPLATE.format(category_id=category_id, page=page_num)
        try:
            response = session.get(url, timeout=45)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'lxml')
            
            product_blocks = soup.select(".goods-record:not(.noCount)")
            if not product_blocks: break

            page_had_new_products = False
            for block in product_blocks:
                if block.select_one(".goods-record-unavailable"): continue
                
                a_tag = block.select_one("a[href*='/Store/Detail/']")
                if not a_tag: continue
                
                match = re.search(r'/Store/Detail/\d+/(\d+)', a_tag['href'])
                product_id = match.group(1) if match else None
                if not product_id or product_id in seen_product_ids: continue
                
                seen_product_ids.add(product_id)
                page_had_new_products = True

                name = (block.select_one("span.goods-record-title").text.strip() if block.select_one("span.goods-record-title") else "Ø¨Ø¯ÙˆÙ† Ù†Ø§Ù…")
                price_tag = block.select_one("span.goods-record-price")
                price = re.sub(r'[^\d]', '', price_tag.text.strip()) if price_tag else "0"
                if int(price) <= 0: continue

                image_tag = block.select_one("img.goods-record-image")
                image_url = image_tag.get('data-src') or image_tag.get('src', '')
                specs = get_product_details(session, category_id, product_id)
                
                product = {
                    "id": product_id, "name": name, "price": price,
                    "image": image_url, "category_id": category_id, "specs": specs
                }
                available_products.append(product)
                logger.debug(f"      - Ù…Ø­ØµÙˆÙ„ Ù…ÙˆØ¬ÙˆØ¯ ÛŒØ§ÙØª Ø´Ø¯: {product_id} ({name})")
                time.sleep(random.uniform(delay, delay + 0.2))

            if not page_had_new_products: break
            page_num += 1
        except requests.RequestException as e:
            logger.error(f"    - Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙØ­Ù‡ {page_num} Ø§Ø² Ø¯Ø³ØªÙ‡ {category_id}: {e}. ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...")
            raise
    return available_products

# ==============================================================================
# --- Ø¨Ø®Ø´ Û´: ØªÙˆØ§Ø¨Ø¹ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø´ Ùˆ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ ---
# ==============================================================================
def load_json_cache(file_path, description):
    """ÛŒÚ© ÙØ§ÛŒÙ„ Ú©Ø´ JSON Ø±Ø§ Ø¨Ø§ Ú©Ù†ØªØ±Ù„ Ø®Ø·Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            try:
                cache = json.load(f)
                logger.info(f"âœ… {description} Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§: {len(cache)}")
                return cache
            except json.JSONDecodeError:
                logger.warning(f"âš ï¸ ÙØ§ÛŒÙ„ Ú©Ø´ {file_path} Ø®Ø±Ø§Ø¨ Ø§Ø³Øª. ÛŒÚ© ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ø³Ø§Ø®ØªÙ‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.")
                return {}
    return {}

def save_json_cache(data, file_path, description):
    """Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„ Ú©Ø´ JSON Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    logger.info(f"âœ… {description} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§: {len(data)}")

def transfer_categories_to_wc(source_categories, wc_auth):
    """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² Ù…Ø¨Ø¯Ø§ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ù…Ù†ØªÙ‚Ù„ Ú©Ø±Ø¯Ù‡ Ùˆ Ù†Ú¯Ø§Ø´Øª Ø¢ÛŒâ€ŒØ¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯."""
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ Ø§Ù†ØªÙ‚Ø§Ù„/Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
    source_to_wc_id_map = {}
    wc_cats_by_name_parent = {}

    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù„Ø¯ Ù‚Ø¨Ù„ Ø§Ø² ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
    sorted_cats = sorted(source_categories, key=lambda x: (x.get('parent_id') or 0, x['id']))

    for cat in tqdm(sorted_cats, desc="Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§"):
        wc_parent_id = source_to_wc_id_map.get(cat.get('parent_id'), 0)
        
        # Ú†Ú© Ú©Ø±Ø¯Ù† Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø­Ø§ÙØ¸Ù‡ Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§
        if (cat['name'], wc_parent_id) in wc_cats_by_name_parent:
            source_to_wc_id_map[cat['id']] = wc_cats_by_name_parent[(cat['name'], wc_parent_id)]
            continue

        data = {"name": cat['name'], "parent": wc_parent_id}
        try:
            res = requests.post(f"{WC_API_URL}/products/categories", auth=wc_auth, json=data, verify=False, timeout=20)
            if res.status_code == 201: # Created
                new_cat = res.json()
                source_to_wc_id_map[cat['id']] = new_cat['id']
                wc_cats_by_name_parent[(cat['name'], wc_parent_id)] = new_cat['id']
            elif res.status_code == 400 and res.json().get("code") == "term_exists":
                existing_id = res.json()["data"]["resource_id"]
                source_to_wc_id_map[cat['id']] = existing_id
                wc_cats_by_name_parent[(cat['name'], wc_parent_id)] = existing_id
            else:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ '{cat['name']}': {res.text}")
        except requests.RequestException as e:
            logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ø³Ø§Ø®Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ '{cat['name']}': {e}")
            
    logger.info("âœ… Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯.")
    return source_to_wc_id_map

@retry(retry=retry_if_exception_type(requests.RequestException), stop=stop_after_attempt(3), wait=wait_random_exponential(multiplier=1, max=10))
def batch_update_stock_status_in_wc(products_to_update, wc_ids_cache, wc_auth):
    """ÙˆØ¶Ø¹ÛŒØª Ø§Ù†Ø¨Ø§Ø± Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú¯Ø±ÙˆÙ‡ÛŒ Ø§Ø² Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¯Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¢Ù¾Ø¯ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if not products_to_update: return 0
    update_payload = [
        {"id": wc_ids_cache[p['sku']], "stock_status": p['stock_status'], "stock_quantity": 0}
        for p in products_to_update if p['sku'] in wc_ids_cache
    ]
    if not update_payload: return 0

    logger.info(f"â³ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Batch Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ø¯ÛŒØª ÙˆØ¶Ø¹ÛŒØª Ø§Ù†Ø¨Ø§Ø± {len(update_payload)} Ù…Ø­ØµÙˆÙ„...")
    try:
        res = requests.post(f"{WC_API_URL}/products/batch", auth=wc_auth, json={"update": update_payload}, verify=False, timeout=120)
        res.raise_for_status()
        logger.info(f"âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Batch Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
        return len(update_payload)
    except requests.RequestException as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ HTTP Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Batch: {e.response.text if e.response else e}")
        return 0

def process_price(price_str):
    """Ù‚ÛŒÙ…Øª Ø±ÛŒØ§Ù„ÛŒ Ø±Ø§ Ø¨Ù‡ ØªÙˆÙ…Ø§Ù† ØªØ¨Ø¯ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù†Ø·Ù‚ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ØŒ Ø³ÙˆØ¯ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    try:
        price = float(re.sub(r'[^\d.]', '', price_str)) / 10
        if price <= 1: return "0"
        elif price <= 7_000_000: new_price = price + 260_000
        elif price <= 10_000_000: new_price = price * 1.035
        elif price <= 20_000_000: new_price = price * 1.025
        elif price <= 30_000_000: new_price = price * 1.02
        else: new_price = price * 1.015
        return str(int(round(new_price, -4))) # Ø±Ù†Ø¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø¯Ù‡ Ù‡Ø²Ø§Ø± ØªÙˆÙ…Ø§Ù†
    except (ValueError, TypeError):
        return "0"

@retry(retry=retry_if_exception_type(requests.RequestException), stop=stop_after_attempt(3), wait=wait_random_exponential(multiplier=1, max=10))
def _send_to_woocommerce(sku, data, stats, wc_ids_cache, wc_auth):
    """ÛŒÚ© Ù…Ø­ØµÙˆÙ„ Ø±Ø§ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø§Ø±Ø³Ø§Ù„ (Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§ Ø¢Ù¾Ø¯ÛŒØª) Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    wc_id = wc_ids_cache.get(sku)
    try:
        if wc_id: # Ø¢Ù¾Ø¯ÛŒØª Ù…Ø­ØµÙˆÙ„ Ù…ÙˆØ¬ÙˆØ¯
            res = requests.put(f"{WC_API_URL}/products/{wc_id}", auth=wc_auth, json=data, verify=False, timeout=30)
            res.raise_for_status()
            with stats['lock']: stats['updated'] += 1
        else: # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯
            res = requests.post(f"{WC_API_URL}/products", auth=wc_auth, json=data, verify=False, timeout=30)
            res.raise_for_status()
            new_wc_id = res.json()['id']
            with stats['lock']:
                wc_ids_cache[sku] = new_wc_id
                stats['created'] += 1
    except requests.RequestException as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ SKU {sku} Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³: {e.response.text if e.response else e}")
        with stats['lock']: stats['failed'] += 1
        raise

def process_product_wrapper(args):
    """ÛŒÚ© Ù…Ø­ØµÙˆÙ„ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    product, stats, category_mapping, cat_map, wc_ids_cache, wc_auth = args
    try:
        wc_cat_id = category_mapping.get(product['category_id'])
        if not wc_cat_id:
            logger.warning(f"   âš ï¸ Ø¯Ø³ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {product['id']} Ø¯Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø±Ø¯ Ú©Ø±Ø¯Ù†...")
            return

        attributes = [{"name": k, "options": [v], "visible": True, "variation": False} for k, v in product['specs'].items()]
        tags = [{"name": t} for t in {product['name'].split()[0], cat_map.get(product['category_id'], '')} if t]

        wc_data = {
            "name": product['name'],
            "type": "simple",
            "sku": f"EWAYS-{product['id']}",
            "regular_price": process_price(product['price']),
            "categories": [{"id": wc_cat_id}],
            "images": [{"src": product["image"]}] if product.get("image") else [],
            "stock_quantity": 10, # ÛŒØ§ Ù‡Ø± Ø¹Ø¯Ø¯ Ø¯Ù„Ø®ÙˆØ§Ù‡ Ø¯ÛŒÚ¯Ø±
            "manage_stock": True,
            "stock_status": "instock",
            "attributes": attributes,
            "tags": tags
        }
        _send_to_woocommerce(wc_data['sku'], wc_data, stats, wc_ids_cache, wc_auth)
    except Exception as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØµÙˆÙ„ {product['id']}: {e}")
        with stats['lock']: stats['failed'] += 1

# ==============================================================================
# --- Ø¨Ø®Ø´ Ûµ: ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ ---
# ==============================================================================
def main():
    logger.info("ğŸš€ --- Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù‡Ù…Ú¯Ø§Ù…â€ŒØ³Ø§Ø²ÛŒ Eways Ø¨Ø§ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ --- ğŸš€")
    
    # Ù…Ø±Ø­Ù„Ù‡ Û±: Ù„Ø§Ú¯ÛŒÙ†
    session = login_eways(EWAYS_USERNAME, EWAYS_PASSWORD)
    if not session: return
    wc_auth = (WC_CONSUMER_KEY, WC_CONSUMER_SECRET)
    
    # Ù…Ø±Ø­Ù„Ù‡ Û²: Ø¯Ø±ÛŒØ§ÙØª Ùˆ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
    all_cats_source = get_and_parse_categories(session)
    if not all_cats_source: return
    cat_map_by_id = {c['id']: c['name'] for c in all_cats_source}

    SELECTED_IDS_STRING = "1582:14548-allz,1584-all-allz|16777:all-allz|4882:all-allz|16778:22570-all-allz"
    parsed_selection = parse_selected_ids_string(SELECTED_IDS_STRING)
    filtered_categories = get_selected_categories_according_to_selection(parsed_selection, all_cats_source)
    logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(filtered_categories)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯.")

    # Ù…Ø±Ø­Ù„Ù‡ Û³: Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³
    category_mapping = transfer_categories_to_wc(filtered_categories, wc_auth)

    # Ù…Ø±Ø­Ù„Ù‡ Û´: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø´â€ŒÙ‡Ø§ Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯
    cached_products = load_json_cache(CACHE_FILE, "Ú©Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª (Ø§Ø¬Ø±Ø§ÛŒ Ù‚Ø¨Ù„)")
    wc_ids_cache = load_json_cache(WC_PRODUCT_IDS_CACHE_FILE, "Ú©Ø´ Ø¢ÛŒâ€ŒØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³")
    
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø² Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ...")
    all_available_products_now = {}
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = {executor.submit(get_available_products_from_category_page, session, cat['id']): cat['name'] for cat in filtered_categories}
        for future in tqdm(as_completed(futures), total=len(futures), desc="Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯"):
            try:
                for product in future.result():
                    all_available_products_now[f"EWAYS-{product['id']}"] = product
            except Exception as e:
                logger.error(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø³ØªÙ‡ '{futures[future]}': {e}")
    logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ ÛŒØ§ÙØªâ€ŒØ´Ø¯Ù‡: {len(all_available_products_now)}")

    # Ù…Ø±Ø­Ù„Ù‡ Ûµ: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ú©Ø´ Ùˆ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ØªØºÛŒÛŒØ±Ø§Øª
    logger.info("\nâ³ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ú©Ø´ Ùˆ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ØªØºÛŒÛŒØ±Ø§Øª...")
    current_skus = set(all_available_products_now.keys())
    cached_skus = set(cached_products.keys())

    skus_to_make_unavailable = cached_skus - current_skus
    skus_to_create = current_skus - cached_skus
    skus_to_check_for_update = current_skus.intersection(cached_skus)

    products_to_update = []
    for sku in skus_to_check_for_update:
        current_p = all_available_products_now[sku]
        cached_p = cached_products[sku]
        if (current_p['price'] != cached_p.get('price') or current_p['name'] != cached_p.get('name') or current_p['specs'] != cached_p.get('specs')):
            products_to_update.append(current_p)
    
    logger.info("ğŸ” Ù†ØªØ§ÛŒØ¬ Ù…Ù‚Ø§ÛŒØ³Ù‡:")
    logger.info(f"  - ğŸŸ¢ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯: {len(skus_to_create)}")
    logger.info(f"  - ğŸ”µ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ (ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª/Ù…Ø´Ø®ØµØ§Øª): {len(products_to_update)}")
    logger.info(f"  - ğŸŸ  Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯ Ú©Ø±Ø¯Ù†: {len(skus_to_make_unavailable)}")

    stats = {'created': 0, 'updated': 0, 'failed': 0, 'stock_updated': 0, 'lock': Lock()}
    
    # Ù…Ø±Ø­Ù„Ù‡ Û¶: Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§Øª Ø¯Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³
    if skus_to_make_unavailable:
        products_to_set_oos = [{"sku": sku, "stock_status": "outofstock"} for sku in skus_to_make_unavailable]
        stats['stock_updated'] = batch_update_stock_status_in_wc(products_to_set_oos, wc_ids_cache, wc_auth)

    products_to_process_queue = Queue()
    for sku in skus_to_create:
        products_to_process_queue.put(all_available_products_now[sku])
    for p in products_to_update:
        products_to_process_queue.put(p)

    if not products_to_process_queue.empty():
        logger.info(f"\nğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø±Ø³Ø§Ù„ {products_to_process_queue.qsize()} Ù…Ø­ØµÙˆÙ„ (Ø¬Ø¯ÛŒØ¯/Ø¢Ù¾Ø¯ÛŒØªÛŒ) Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
        
        def worker():
            while not products_to_process_queue.empty():
                try:
                    product = products_to_process_queue.get_nowait()
                    process_product_wrapper((product, stats, category_mapping, cat_map_by_id, wc_ids_cache, wc_auth))
                    products_to_process_queue.task_done()
                except Queue.Empty: break
        
        threads = [Thread(target=worker) for _ in range(5)]
        for t in threads: t.start()
        for t in threads: t.join()

    # Ù…Ø±Ø­Ù„Ù‡ Û·: Ø°Ø®ÛŒØ±Ù‡ Ú©Ø´â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ
    save_json_cache(all_available_products_now, CACHE_FILE, "Ú©Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯")
    save_json_cache(wc_ids_cache, WC_PRODUCT_IDS_CACHE_FILE, "Ú©Ø´ Ø¢ÛŒâ€ŒØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³")

    logger.info("\n===============================")
    logger.info(f"ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ø¹Ù…Ù„ÛŒØ§Øª:")
    logger.info(f"ğŸŸ¢ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: {stats['created']}")
    logger.info(f"ğŸ”µ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯Ù‡: {stats['updated']}")
    logger.info(f"ğŸŸ  Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯ Ø´Ø¯Ù‡: {stats['stock_updated']}")
    logger.info(f"ğŸ”´ Ø¹Ù…Ù„ÛŒØ§Øª Ø´Ú©Ø³Øªâ€ŒØ®ÙˆØ±Ø¯Ù‡: {stats['failed']}")
    logger.info("===============================\nğŸ --- Ù¾Ø§ÛŒØ§Ù† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª --- ğŸ")

if __name__ == "__main__":
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø­Ø³Ø§Ø³ Ø¯Ø± Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
    if "your-site.com" in WC_API_URL or "your_key" in WC_CONSUMER_KEY:
        logger.critical("ğŸš¨ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ (URL/KEY) Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
    elif "your_eways_username" in EWAYS_USERNAME:
        logger.critical("ğŸš¨ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±ÛŒ Eways ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
    else:
        main()
