import requests
import os
import re
import time
import json
import random
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from bs4 import BeautifulSoup
from threading import Lock, Thread
from queue import Queue
import logging
from logging.handlers import RotatingFileHandler
from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type
from collections import defaultdict
import warnings

# Suppress InsecureRequestWarning
warnings.filterwarnings("ignore", category=requests.packages.urllib3.exceptions.InsecureRequestWarning)

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ù†Ø¹Ø·Ù Ø¨Ø§ SELECTED_IDS_STRING ---
# ==============================================================================
def parse_selected_ids_string(selected_ids_string):
    result = []
    for part in selected_ids_string.split('|'):
        part = part.strip()
        if not part or ':' not in part:
            continue
        parent_id_str, children_str = part.split(':', 1)
        parent_id = int(parent_id_str.strip())
        selections = []
        for sel in children_str.split(','):
            sel = sel.strip()
            if not sel:
                continue
            if sel == 'all':
                selections.append({"id": parent_id, "type": "all_subcats"})
            elif sel == 'allz':
                selections.append({"id": parent_id, "type": "only_products"})
            elif sel == 'all-allz':
                selections.append({"id": parent_id, "type": "all_subcats_and_products"})
            elif re.match(r'^\d+-allz$', sel):
                sub_id = int(sel.split('-')[0])
                selections.append({"id": sub_id, "type": "only_products"})
            elif re.match(r'^\d+-all-allz$', sel):
                sub_id = int(sel.split('-')[0])
                selections.append({"id": sub_id, "type": "all_subcats_and_products"})
        result.append({"parent_id": parent_id, "selections": selections})
    return result

def get_direct_subcategories(parent_id, all_cats):
    return [cat['id'] for cat in all_cats if cat.get('parent_id') == parent_id]

def get_all_subcategories(parent_id, all_cats):
    result = []
    direct = get_direct_subcategories(parent_id, all_cats)
    result.extend(direct)
    for sub_id in direct:
        result.extend(get_all_subcategories(sub_id, all_cats))
    return result

def get_selected_categories_according_to_selection(parsed_selection, all_cats):
    selected_ids = set()
    for block in parsed_selection:
        parent_id = block['parent_id']
        selected_ids.add(parent_id) # Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø³ØªÙ‡ Ø§ØµÙ„ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        for sel in block['selections']:
            sel_id = sel['id']
            sel_type = sel['type']
            
            if sel_type == 'all_subcats': # ÙÙ‚Ø· Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
                selected_ids.update(get_direct_subcategories(sel_id, all_cats))
            elif sel_type == 'only_products': # ÙÙ‚Ø· Ø®ÙˆØ¯ Ø¯Ø³ØªÙ‡ (Ú©Ù‡ Ù‚Ø¨Ù„Ø§ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡)
                selected_ids.add(sel_id)
            elif sel_type == 'all_subcats_and_products': # Ø®ÙˆØ¯ Ø¯Ø³ØªÙ‡ Ùˆ ØªÙ…Ø§Ù… Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ
                selected_ids.add(sel_id)
                selected_ids.update(get_all_subcategories(sel_id, all_cats))

    return [cat for cat in all_cats if cat['id'] in selected_ids]

# ==============================================================================
# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯ ---
# ==============================================================================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
handler = RotatingFileHandler('app.log', maxBytes=5*1024*1024, backupCount=5, encoding='utf-8')
handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)

# ==============================================================================
# --- Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ùˆ Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ ---
# ==============================================================================
BASE_URL = "https://panel.eways.co"
SOURCE_CATS_API_URL = f"{BASE_URL}/Store/GetCategories"
PRODUCT_LIST_URL_TEMPLATE = f"{BASE_URL}/Store/List/{{category_id}}/2/2/0/0/0/10000000000?page={{page}}"
PRODUCT_DETAIL_URL_TEMPLATE = f"{BASE_URL}/Store/Detail/{{cat_id}}/{{product_id}}"

WC_API_URL = os.environ.get("WC_API_URL", "https://your-woocommerce-site.com/wp-json/wc/v3")
WC_CONSUMER_KEY = os.environ.get("WC_CONSUMER_KEY", "ck_xxx")
WC_CONSUMER_SECRET = os.environ.get("WC_CONSUMER_SECRET", "cs_xxx")

EWAYS_USERNAME = os.environ.get("EWAYS_USERNAME", "Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„ ÛŒØ§ ÛŒÙˆØ²Ø±Ù†ÛŒÙ…")
EWAYS_PASSWORD = os.environ.get("EWAYS_PASSWORD", "Ù¾Ø³ÙˆØ±Ø¯")

CACHE_FILE = 'products_cache_v2.json'  # ### ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ: Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ú©Ø´ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªØ¯Ø§Ø®Ù„

# ==============================================================================
# --- ØªØ§Ø¨Ø¹ Ù„Ø§Ú¯ÛŒÙ† Ø§ØªÙˆÙ…Ø§ØªÛŒÚ© Ø¨Ù‡ eways ---
# ==============================================================================
def login_eways(username, password):
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': f"{BASE_URL}/",
        'X-Requested-With': 'XMLHttpRequest',
        'Accept-Language': 'en-US,en;q=0.9,fa;q=0.8'
    })
    session.verify = False

    login_url = f"{BASE_URL}/User/Login"
    payload = {
        "UserName": username,
        "Password": password,
        "RememberMe": "true"
    }
    logger.info("â³ Ø¯Ø± Ø­Ø§Ù„ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ Ù¾Ù†Ù„ eways ...")
    try:
        resp = session.post(login_url, data=payload, timeout=30)
        resp.raise_for_status()
    except requests.RequestException as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ù„Ø§Ú¯ÛŒÙ†: {e}")
        return None

    if 'Aut' in session.cookies:
        logger.info("âœ… Ù„Ø§Ú¯ÛŒÙ† Ù…ÙˆÙÙ‚! Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
        return session
    else:
        response_text = resp.text.lower()
        if "Ú©Ù¾Ú†Ø§" in response_text or "captcha" in response_text:
            logger.error("âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ú©Ù¾Ú†Ø§ ÙØ¹Ø§Ù„ Ø§Ø³Øª.")
        elif "Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ" in response_text or "Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±" in response_text:
            logger.error("âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ ÛŒØ§ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª.")
        else:
            logger.error(f"âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø§Ú¯ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚. Ù¾Ø§Ø³Ø® Ø³Ø±ÙˆØ±: {resp.text[:200]}")
        return None

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ (eways) ---
# ==============================================================================

@retry(
    retry=retry_if_exception_type(requests.exceptions.RequestException),
    stop=stop_after_attempt(5),
    wait=wait_random_exponential(multiplier=1, max=5),
    reraise=True
)
def get_product_details(session, cat_id, product_id):
    url = PRODUCT_DETAIL_URL_TEMPLATE.format(cat_id=cat_id, product_id=product_id)
    try:
        response = session.get(url, timeout=60)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        specs_table = soup.select_one('#link1 .table-responsive table, .table-responsive table, table.table')
        if not specs_table:
            logger.debug(f"      - Ù‡ÛŒÚ† Ø¬Ø¯ÙˆÙ„ Ù…Ø´Ø®ØµØ§ØªÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {product_id} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            return {}
        
        specs = {}
        rows = specs_table.find_all("tr")
        for row in rows:
            cells = row.find_all("td")
            if len(cells) == 2:
                key = cells[0].text.strip()
                value = cells[1].text.strip()
                if key and value:
                    specs[key] = value
        logger.debug(f"      - {len(specs)} Ù…Ø´Ø®ØµÙ‡ ÙÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {product_id} Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
        return specs
    except requests.exceptions.RequestException as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}. ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...")
        raise
    except Exception as e:
        logger.error(f"      - Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}")
        return {}

def get_and_parse_categories(session):
    logger.info(f"â³ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø²: {SOURCE_CATS_API_URL}")
    try:
        response = session.get(SOURCE_CATS_API_URL, timeout=30)
        response.raise_for_status()
        data = response.json()
        final_cats = []
        for c in data:
            real_id_match = re.search(r'/Store/List/(\d+)', c.get('url', ''))
            real_id = int(real_id_match.group(1)) if real_id_match else c.get('id')
            final_cats.append({
                "id": real_id,
                "name": c.get('name', '').strip(),
                "parent_id": c.get('parent_id')
            })
        logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø² JSON Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
        return final_cats
    except (requests.RequestException, json.JSONDecodeError) as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None

# ### ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ###
# Ø§ÙØ²Ø§ÛŒØ´ max_pages Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø®ÙˆØ§Ù†Ø¯Ù† ØªÙ…Ø§Ù… Ù…Ø­ØµÙˆÙ„Ø§Øª
@retry(
    retry=retry_if_exception_type((requests.exceptions.RequestException, requests.exceptions.HTTPError)),
    stop=stop_after_attempt(4),
    wait=wait_random_exponential(multiplier=1, max=10),
    reraise=True
)
def get_products_from_category_page(session, category_id, max_pages=100, delay=0.5):
    all_products_in_category = []
    seen_product_ids_this_run = set()
    page_num = 1
    
    while page_num <= max_pages:
        url = PRODUCT_LIST_URL_TEMPLATE.format(category_id=category_id, page=page_num)
        logger.debug(f"  - Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø²: {url}")
        try:
            response = session.get(url, timeout=30)
            if response.status_code in [429, 503, 403]:
                raise requests.exceptions.HTTPError(f"Blocked or rate limited: {response.status_code}", response=response)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'lxml')
            product_blocks = soup.select(".goods_item.goods-record")
            
            if not product_blocks:
                logger.info(f"    - Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ÛŒ Ø¯Ø± ØµÙØ­Ù‡ {page_num} Ø§Ø² Ø¯Ø³ØªÙ‡ {category_id} ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù¾Ø§ÛŒØ§Ù† ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ.")
                break

            found_new_product = False
            for block in product_blocks:
                if block.select_one(".goods-record-unavailable"):
                    continue
                
                a_tag = block.select_one("a[href*='/Store/Detail/']")
                if not a_tag:
                    continue

                href = a_tag['href']
                match = re.search(r'/Store/Detail/\d+/(\d+)', href)
                product_id = match.group(1) if match else None

                if not product_id or product_id in seen_product_ids_this_run:
                    continue

                name = block.select_one("span.goods-record-title").text.strip()
                price_text = block.select_one("span.goods-record-price").text.strip()
                price = re.sub(r'[^\d]', '', price_text)
                image_url = block.select_one("img.goods-record-image").get('data-src', '')

                if not name or not price or int(price) <= 0:
                    continue

                # Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª ÙÙ‚Ø· ÛŒÚ©Ø¨Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ø­ØµÙˆÙ„ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ø§ÛŒÙ†Ø¬Ø§ ÙÙ‚Ø· Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø§ÛŒÙ‡ Ø±Ø§ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
                product = {
                    "id": product_id,
                    "name": name,
                    "price": price,
                    "stock": 1, # Ù…ÙˆØ¬ÙˆØ¯ ÙØ±Ø¶ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                    "image": image_url,
                    "category_id": category_id,
                }
                all_products_in_category.append(product)
                seen_product_ids_this_run.add(product_id)
                found_new_product = True

            if not found_new_product:
                logger.info(f"    - Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¯Ø± Ø§ÛŒÙ† ØµÙØ­Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ ØªÙˆÙ‚Ù ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡ {category_id}.")
                break

            page_num += 1
            time.sleep(random.uniform(delay, delay + 0.2))

        except requests.exceptions.RequestException as e:
            logger.error(f"    - Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙØ­Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø³ØªÙ‡ {category_id}: {e}")
            raise # Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… tenacity Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†Ø¯

    logger.info(f"    - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ø§Ø² Ø¯Ø³ØªÙ‡ {category_id}: {len(all_products_in_category)}")
    return all_products_in_category

# ==============================================================================
# --- Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª (Ú©Ù„ÛŒØ¯: product_id) ---
# ==============================================================================
def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                cache = json.load(f)
                logger.info(f"âœ… Ú©Ø´ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± Ú©Ø´: {len(cache)}")
                return cache
        except (json.JSONDecodeError, IOError) as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ú©Ø´: {e}. ÛŒÚ© Ú©Ø´ Ø¬Ø¯ÛŒØ¯ Ø³Ø§Ø®ØªÙ‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.")
            return {}
    logger.info("âš ï¸ Ú©Ø´ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù…Ù„ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    return {}

def save_cache(products_data):
    try:
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(products_data, f, ensure_ascii=False, indent=4)
        logger.info(f"âœ… Ú©Ø´ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª: {len(products_data)}")
    except IOError as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ú©Ø´: {e}")

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ ---
# ==============================================================================
def get_wc_categories():
    wc_cats, page = [], 1
    while True:
        try:
            res = requests.get(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), params={"per_page": 100, "page": page}, verify=False, timeout=30)
            res.raise_for_status()
            data = res.json()
            if not data: break
            wc_cats.extend(data)
            if len(data) < 100: break
            page += 1
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³: {e}")
            break
    logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒâ€ŒØ´Ø¯Ù‡: {len(wc_cats)}")
    return {cat["id"]: cat for cat in wc_cats}

def transfer_categories_to_wc(source_categories):
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
    # ... (Ú©Ø¯ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯) ...
    return source_to_wc_id_map # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ù‡Ù…Ø§Ù†Ø·ÙˆØ± Ú©Ù‡ Ø¨ÙˆØ¯ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯

def process_price(price_value):
    try:
        price_value = float(re.sub(r'[^\d.]', '', str(price_value)))
        price_value /= 10 # ØªØ¨Ø¯ÛŒÙ„ Ø±ÛŒØ§Ù„ Ø¨Ù‡ ØªÙˆÙ…Ø§Ù†
    except (ValueError, TypeError): return "0"
    if price_value <= 1: return "0"
    elif price_value <= 7000000: new_price = price_value + 260000
    elif price_value <= 10000000: new_price = price_value * 1.035
    elif price_value <= 20000000: new_price = price_value * 1.025
    elif price_value <= 30000000: new_price = price_value * 1.02
    else: new_price = price_value * 1.015
    return str(int(round(new_price, -4))) # Ø±Ù†Ø¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Û±Û° Ù‡Ø²Ø§Ø± ØªÙˆÙ…Ø§Ù†

@retry(
    retry=retry_if_exception_type((requests.exceptions.RequestException, requests.exceptions.HTTPError)),
    stop=stop_after_attempt(3),
    wait=wait_random_exponential(multiplier=1, max=10),
    reraise=True
)
def _send_to_woocommerce(sku, data, stats):
    try:
        auth = (WC_CONSUMER_KEY, WC_CONSUMER_SECRET)
        logger.debug(f"   - Ú†Ú© Ú©Ø±Ø¯Ù† SKU {sku} Ø¯Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
        check_url = f"{WC_API_URL}/products?sku={sku}"
        r_check = requests.get(check_url, auth=auth, verify=False, timeout=20)
        r_check.raise_for_status()
        existing = r_check.json()

        if existing:
            product_id = existing[0]['id']
            # ### ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ###
            # Ù‡Ù†Ú¯Ø§Ù… Ø¢Ù¾Ø¯ÛŒØªØŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ù‡Ù… Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
            update_data = {
                "regular_price": data["regular_price"],
                "stock_quantity": data["stock_quantity"],
                "stock_status": data["stock_status"],
                "attributes": data["attributes"],
                "tags": data.get("tags", []),
                "categories": data["categories"] # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ù…Ø­ØµÙˆÙ„ Ø¯Ø± Ù‡Ù…Ù‡ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯
            }
            logger.debug(f"   - Ø¢Ù¾Ø¯ÛŒØª Ù…Ø­ØµÙˆÙ„ {product_id} Ø¨Ø§ {len(update_data['attributes'])} Ù…Ø´Ø®ØµÙ‡ Ùˆ {len(update_data['categories'])} Ø¯Ø³ØªÙ‡...")
            res = requests.put(f"{WC_API_URL}/products/{product_id}", auth=auth, json=update_data, verify=False, timeout=30)
            res.raise_for_status()
            with stats['lock']: stats['updated'] += 1
            logger.info(f"   âœ… Ù…Ø­ØµÙˆÙ„ {sku} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯.")
        else:
            logger.debug(f"   - Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ SKU {sku} Ùˆ {len(data['attributes'])} Ù…Ø´Ø®ØµÙ‡ ÙÙ†ÛŒ...")
            res = requests.post(f"{WC_API_URL}/products", auth=auth, json=data, verify=False, timeout=30)
            res.raise_for_status()
            with stats['lock']: stats['created'] += 1
            logger.info(f"   âœ… Ù…Ø­ØµÙˆÙ„ {sku} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.")
    except requests.exceptions.HTTPError as e:
        error_text = e.response.text if e.response else "No response body"
        logger.error(f"   âŒ Ø®Ø·Ø§ÛŒ HTTP Ø¨Ø±Ø§ÛŒ SKU {sku}: {e.response.status_code} - Ù¾Ø§Ø³Ø®: {error_text}")
        raise
    except Exception as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø±Ø§ÛŒ SKU {sku}: {e}")
        raise

# ==============================================================================
# --- Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø³Ø¦Ùˆ Ù…Ø­ÙˆØ± (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
# ==============================================================================
def smart_tags_for_product(product, cat_map):
    # ... (Ú©Ø¯ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯) ...
    return [{"name": t} for t in sorted(tags)]

# ### ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ###
# Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø­Ø§Ù„Ø§ ÛŒÚ© Ù…Ø­ØµÙˆÙ„ Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§ Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
def process_product_wrapper(args):
    source_id, product_data, stats, category_mapping, cat_map, session = args
    try:
        product_details = product_data['details']
        source_cat_ids = list(product_data['categories'])

        # ØªØ¨Ø¯ÛŒÙ„ Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¨Ø¯Ø§ Ø¨Ù‡ Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³
        wc_cat_ids = [category_mapping.get(cat_id) for cat_id in source_cat_ids]
        wc_cat_ids = [cid for cid in wc_cat_ids if cid is not None]

        if not wc_cat_ids:
            logger.warning(f"   âš ï¸ Ù‡ÛŒÚ† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {source_id} ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø±Ø¯ Ú©Ø±Ø¯Ù†...")
            with stats['lock']: stats['no_category'] += 1
            return

        # Ø¯Ø±ÛŒØ§ÙØª Ù…Ø´Ø®ØµØ§Øª ÙÙ†ÛŒ Ù…Ø­ØµÙˆÙ„ (ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø±)
        # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ù…Ø´Ø®ØµØ§Øª Ø¯Ø± Ù‡Ù…Ù‡ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ ÛŒÚ©Ø³Ø§Ù† Ø§Ø³ØªØŒ Ù¾Ø³ Ø§Ø² Ø§ÙˆÙ„ÛŒÙ† Ø¯Ø³ØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        specs = get_product_details(session, source_cat_ids[0], source_id)
        
        attributes = []
        for i, (key, value) in enumerate(specs.items()):
            attributes.append({
                "name": key, "options": [value], "position": i,
                "visible": True, "variation": False
            })

        tags = smart_tags_for_product(product_details, cat_map)

        wc_data = {
            "name": product_details.get('name', 'Ø¨Ø¯ÙˆÙ† Ù†Ø§Ù…'),
            "type": "simple",
            "sku": f"EWAYS-{source_id}",
            "regular_price": process_price(product_details.get('price', 0)),
            "categories": [{"id": wc_id} for wc_id in wc_cat_ids],
            "images": [{"src": product_details.get("image")}] if product_details.get("image") else [],
            "stock_quantity": product_details.get('stock', 0),
            "manage_stock": True,
            "stock_status": "instock" if product_details.get('stock', 0) > 0 else "outofstock",
            "attributes": attributes,
            "tags": tags
        }

        _send_to_woocommerce(wc_data['sku'], wc_data, stats)
        time.sleep(random.uniform(0.2, 0.8)) # Ú©Ø§Ù‡Ø´ ØªØ§Ø®ÛŒØ± Ú†ÙˆÙ† Ø¬Ø²Ø¦ÛŒØ§Øª Ù‚Ø¨Ù„Ø§ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡

    except Exception as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØµÙˆÙ„ {source_id}: {e}", exc_info=True)
        with stats['lock']: stats['failed'] += 1

# ==============================================================================
# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ---
# ==============================================================================
def main():
    session = login_eways(EWAYS_USERNAME, EWAYS_PASSWORD)
    if not session:
        logger.error("âŒ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ Ù¾Ù†Ù„ eways Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
        return

    all_cats = get_and_parse_categories(session)
    if not all_cats:
        logger.error("âŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯.")
        return
    cat_map = {cat['id']: cat['name'] for cat in all_cats}
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Û±: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯: {len(all_cats)}")

    SELECTED_IDS_STRING = "16777:all-allz|4882:all-allz|16778:22570-all-allz"
    parsed_selection = parse_selected_ids_string(SELECTED_IDS_STRING)
    filtered_categories = get_selected_categories_according_to_selection(parsed_selection, all_cats)
    selected_cat_ids = {cat['id'] for cat in filtered_categories}
    logger.info(f"âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±Ù¾: {len(filtered_categories)} Ø¹Ø¯Ø¯")

    category_mapping = transfer_categories_to_wc(filtered_categories)
    if not category_mapping:
        logger.error("âŒ Ù†Ú¯Ø§Ø´Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
        return
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Û²: Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯.")

    # ### ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ###
    # Ù…Ø±Ø­Ù„Ù‡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø§Ù… Ù…Ø­ØµÙˆÙ„Ø§Øª Ù‚Ø¨Ù„ Ø§Ø² Ù‡Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯ÛŒÚ¯Ø±ÛŒ
    all_products_raw = []
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_catid = {executor.submit(get_products_from_category_page, session, cat_id): cat_id for cat_id in selected_cat_ids}
        
        pbar = tqdm(as_completed(future_to_catid), total=len(selected_cat_ids), desc="Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§")
        for future in pbar:
            cat_id = future_to_catid[future]
            try:
                products_in_cat = future.result()
                all_products_raw.extend(products_in_cat)
            except Exception as e:
                logger.error(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø³ØªÙ‡ {cat_id}: {e}")
        
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Û³: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®Ø§Ù… Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ (Ø¨Ø§ ØªÚ©Ø±Ø§Ø±): {len(all_products_raw)}")

    # ### ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ###
    # Ù…Ø±Ø­Ù„Ù‡ Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ù†Ø§Ø³Ù‡ ÛŒÚ©ØªØ§
    products_by_source_id = defaultdict(lambda: {"details": None, "categories": set()})
    for p in all_products_raw:
        source_id = p['id']
        products_by_source_id[source_id]['details'] = p
        products_by_source_id[source_id]['categories'].add(p['category_id'])

    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Û´: Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª ÛŒÚ©ØªØ§: {len(products_by_source_id)}")
    
    # Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª Ú†Ù†Ø¯ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ
    for pid, data in products_by_source_id.items():
        if len(data['categories']) > 1:
            cat_names = [cat_map.get(cid, str(cid)) for cid in data['categories']]
            logger.debug(f"  - Ù…Ø­ØµÙˆÙ„ Ú†Ù†Ø¯ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ: {data['details']['name']} (ID: {pid}) Ø¯Ø± Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ: {', '.join(cat_names)}")

    # ### ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ###
    # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ú©Ø´ Ùˆ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯/ØªØºÛŒÛŒØ±ÛŒØ§ÙØªÙ‡
    cached_products = load_cache()
    products_to_send = {}
    
    for source_id, current_data in products_by_source_id.items():
        is_changed = True
        if source_id in cached_products:
            cached_data = cached_products[source_id]
            # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‚ÛŒÙ…ØªØŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
            if (cached_data.get('price') == current_data['details']['price'] and
                set(cached_data.get('categories', [])) == current_data['categories']):
                is_changed = False
        
        if is_changed:
            products_to_send[source_id] = current_data
        
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Ûµ: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ú©Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯/ØªØºÛŒÛŒØ±ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„: {len(products_to_send)}")

    # Ø³Ø§Ø®Øª Ú©Ø´ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ
    new_cache_data = {}
    for source_id, data in products_by_source_id.items():
        new_cache_data[source_id] = {
            "price": data['details']['price'],
            "categories": list(data['categories'])
        }
    save_cache(new_cache_data)

    if not products_to_send:
        logger.info("âœ… Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ ÛŒØ§ ØªØºÛŒÛŒØ±ÛŒØ§ÙØªÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. Ù¾Ø§ÛŒØ§Ù† Ú©Ø§Ø±.")
        return

    # ### ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ###
    # Ø§Ø±Ø³Ø§Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³
    stats = {'created': 0, 'updated': 0, 'failed': 0, 'no_category': 0, 'lock': Lock()}
    logger.info(f"\nğŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø§Ø±Ø³Ø§Ù„ {len(products_to_send)} Ù…Ø­ØµÙˆÙ„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
    
    tasks = [(source_id, data, stats, category_mapping, cat_map, session) for source_id, data in products_to_send.items()]

    with ThreadPoolExecutor(max_workers=3) as executor:
        list(tqdm(executor.map(process_product_wrapper, tasks), total=len(tasks), desc="Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³"))

    logger.info("\n===============================")
    logger.info(f"ğŸ“¦ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {len(products_to_send)}")
    logger.info(f"ğŸŸ¢ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: {stats['created']}")
    logger.info(f"ğŸ”µ Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯Ù‡: {stats['updated']}")
    logger.info(f"ğŸ”´ Ø´Ú©Ø³Øªâ€ŒØ®ÙˆØ±Ø¯Ù‡: {stats['failed']}")
    logger.info(f"ğŸŸ¡ Ø¨Ø¯ÙˆÙ† Ø¯Ø³ØªÙ‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³: {stats['no_category']}")
    logger.info("===============================\nØªÙ…Ø§Ù…!")

if __name__ == "__main__":
    main()
