import requests
import os
import re
import time
import json
import random
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from bs4 import BeautifulSoup
from threading import Lock, Thread
from queue import Queue
import logging
from logging.handlers import RotatingFileHandler
from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type
from collections import defaultdict

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ù†Ø¹Ø·Ù Ø¨Ø§ SELECTED_IDS_STRING ---
# ==============================================================================
def parse_selected_ids_string(selected_ids_string):
    result = []
    for part in selected_ids_string.split('|'):
        part = part.strip()
        if not part or ':' not in part:
            continue
        parent_id_str, children_str = part.split(':', 1)
        parent_id = int(parent_id_str.strip())
        selections = []
        for sel in children_str.split(','):
            sel = sel.strip()
            if not sel:
                continue
            if sel == 'all':
                selections.append({"id": parent_id, "type": "all_subcats"})
            elif sel == 'allz':
                selections.append({"id": parent_id, "type": "only_products"})
            elif sel == 'all-allz':
                selections.append({"id": parent_id, "type": "all_subcats_and_products"})
            elif re.match(r'^\d+-allz$', sel):
                sub_id = int(sel.split('-')[0])
                selections.append({"id": sub_id, "type": "only_products"})
            elif re.match(r'^\d+-all-allz$', sel):
                sub_id = int(sel.split('-')[0])
                selections.append({"id": sub_id, "type": "all_subcats_and_products"})
        result.append({"parent_id": parent_id, "selections": selections})
    return result

def get_direct_subcategories(parent_id, all_cats):
    return [cat['id'] for cat in all_cats if cat['parent_id'] == parent_id]

def get_all_subcategories(parent_id, all_cats):
    result = []
    direct = get_direct_subcategories(parent_id, all_cats)
    result.extend(direct)
    for sub_id in direct:
        result.extend(get_all_subcategories(sub_id, all_cats))
    return result

def get_selected_categories_according_to_selection(parsed_selection, all_cats):
    selected_ids = set()
    for block in parsed_selection:
        parent_id = block['parent_id']
        selected_ids.add(parent_id)
        for sel in block['selections']:
            if sel['type'] == 'all_subcats' and sel['id'] == parent_id:
                selected_ids.update(get_direct_subcategories(parent_id, all_cats))
            elif sel['type'] == 'only_products' and sel['id'] == parent_id:
                selected_ids.add(parent_id)
            elif sel['type'] == 'all_subcats_and_products' and sel['id'] == parent_id:
                direct_subs = get_direct_subcategories(parent_id, all_cats)
                selected_ids.update(direct_subs)
                for sub_id in direct_subs:
                    selected_ids.update(get_all_subcategories(sub_id, all_cats))
                selected_ids.add(parent_id)
            elif sel['type'] == 'only_products' and sel['id'] != parent_id:
                selected_ids.add(sel['id'])
            elif sel['type'] == 'all_subcats_and_products' and sel['id'] != parent_id:
                selected_ids.add(sel['id'])
                selected_ids.update(get_all_subcategories(sel['id'], all_cats))
    return [cat for cat in all_cats if cat['id'] in selected_ids]

# ==============================================================================
# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯ ---
# ==============================================================================
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
handler = RotatingFileHandler('app.log', maxBytes=1024*1024, backupCount=5)
handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)

# ==============================================================================
# --- Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ùˆ Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ ---
# ==============================================================================
BASE_URL = "https://panel.eways.co"
SOURCE_CATS_API_URL = f"{BASE_URL}/Store/GetCategories"
PRODUCT_LIST_URL_TEMPLATE = f"{BASE_URL}/Store/List/{{category_id}}/2/2/0/0/0/10000000000?page={{page}}"
PRODUCT_DETAIL_URL_TEMPLATE = f"{BASE_URL}/Store/Detail/{{cat_id}}/{{product_id}}"

WC_API_URL = os.environ.get("WC_API_URL") or "https://your-woocommerce-site.com/wp-json/wc/v3"
WC_CONSUMER_KEY = os.environ.get("WC_CONSUMER_KEY") or "ck_xxx"
WC_CONSUMER_SECRET = os.environ.get("WC_CONSUMER_SECRET") or "cs_xxx"

EWAYS_USERNAME = os.environ.get("EWAYS_USERNAME") or "Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„ ÛŒØ§ ÛŒÙˆØ²Ø±Ù†ÛŒÙ…"
EWAYS_PASSWORD = os.environ.get("EWAYS_PASSWORD") or "Ù¾Ø³ÙˆØ±Ø¯"

CACHE_FILE = 'products_cache.json'  # ÙØ§ÛŒÙ„ Ú©Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ù†Ø¨Ø¹
WC_CACHE_FILE = 'wc_products_cache.json'  # ÙØ§ÛŒÙ„ Ú©Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ (Ø¬Ø¯ÛŒØ¯)
SPECS_CACHE_FILE = 'specs_cache.json'  # Ú©Ø´ Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø®ØµØ§Øª ÙÙ†ÛŒ (Ø¬Ø¯ÛŒØ¯)

# ==============================================================================
# --- ØªØ§Ø¨Ø¹ Ù„Ø§Ú¯ÛŒÙ† Ø§ØªÙˆÙ…Ø§ØªÛŒÚ© Ø¨Ù‡ eways ---
# ==============================================================================
def login_eways(username, password):
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': f"{BASE_URL}/",
        'X-Requested-With': 'XMLHttpRequest',
        'Accept-Language': 'en-US,en;q=0.9,fa;q=0.8'
    })
    session.verify = False

    login_url = f"{BASE_URL}/User/Login"
    payload = {
        "UserName": username,
        "Password": password,
        "RememberMe": "true"
    }
    logger.info("â³ Ø¯Ø± Ø­Ø§Ù„ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ Ù¾Ù†Ù„ eways ...")
    resp = session.post(login_url, data=payload, timeout=30)
    if resp.status_code != 200:
        logger.error(f"âŒ Ù„Ø§Ú¯ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚! Ú©Ø¯ ÙˆØ¶Ø¹ÛŒØª: {resp.status_code} - Ù…ØªÙ† Ù¾Ø§Ø³Ø®: {resp.text[:200]}")
        return None

    if 'Aut' in session.cookies:
        logger.info("âœ… Ù„Ø§Ú¯ÛŒÙ† Ù…ÙˆÙÙ‚! Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
        return session
    else:
        if "Ú©Ù¾Ú†Ø§" in resp.text or "captcha" in resp.text.lower():
            logger.error("âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ú©Ù¾Ú†Ø§ ÙØ¹Ø§Ù„ Ø§Ø³Øª.")
        elif "Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ" in resp.text or "Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±" in resp.text:
            logger.error("âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ ÛŒØ§ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª.")
        else:
            logger.error("âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø§Ú¯ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚ ÛŒØ§ Ø¯Ù„ÛŒÙ„ Ù†Ø§Ù…Ø´Ø®Øµ.")
        return None

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ (eways) ---
# ==============================================================================

@retry(
    retry=retry_if_exception_type(requests.exceptions.RequestException),
    stop=stop_after_attempt(5),
    wait=wait_random_exponential(multiplier=1, max=5),
    reraise=True
)
def get_product_details(session, cat_id, product_id, specs_cache):
    cache_key = f"{cat_id}|{product_id}"
    if cache_key in specs_cache:
        logger.debug(f"      - Ù…Ø´Ø®ØµØ§Øª {product_id} Ø§Ø² Ú©Ø´ Ù…Ø­Ù„ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        return specs_cache[cache_key]
    
    url = PRODUCT_DETAIL_URL_TEMPLATE.format(cat_id=cat_id, product_id=product_id)
    try:
        response = session.get(url, timeout=60)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        specs_table = soup.select_one('#link1 .table-responsive table')
        if not specs_table:
            specs_table = soup.select_one('.table-responsive table')
            if not specs_table:
                specs_table = soup.find('table', class_='table')
                if not specs_table:
                    logger.debug(f"      - Ù‡ÛŒÚ† Ø¬Ø¯ÙˆÙ„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. HTML Ø®Ø§Ù… ØµÙØ­Ù‡: {soup.prettify()[:1000]}...")
                    return {}
        specs = {}
        rows = specs_table.find_all("tr")
        for row in rows:
            cells = row.find_all("td")
            if len(cells) == 2:
                key = cells[0].text.strip()
                value = cells[1].text.strip()
                if key and value:
                    specs[key] = value
        if not specs:
            logger.debug(f"      - Ù‡ÛŒÚ† Ø±Ø¯ÛŒÙÛŒ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. HTML Ø®Ø§Ù… Ø¬Ø¯ÙˆÙ„: {specs_table.prettify()}")
        logger.debug(f"      - Ù…Ø´Ø®ØµØ§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {product_id} (Ú©Ø§Ù…Ù„): {json.dumps(specs, ensure_ascii=False, indent=4)}")
        
        specs_cache[cache_key] = specs
        return specs
    except requests.exceptions.RequestException as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}. Retry...")
        raise
    except Exception as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}")
        return {}

def get_and_parse_categories(session):
    logger.info(f"â³ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø²: {SOURCE_CATS_API_URL}")
    try:
        response = session.get(SOURCE_CATS_API_URL, timeout=30)
        response.raise_for_status()
        try:
            data = response.json()
            logger.info("âœ… Ù¾Ø§Ø³Ø® JSON Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")
            final_cats = []
            for c in data:
                real_id_match = re.search(r'/Store/List/(\d+)', c.get('url', ''))
                real_id = int(real_id_match.group(1)) if real_id_match else c.get('id')
                final_cats.append({
                    "id": real_id,
                    "name": c.get('name', '').strip(),
                    "parent_id": c.get('parent_id')
                })
            logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø² JSON Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
            return final_cats
        except json.JSONDecodeError:
            logger.warning("âš ï¸ Ù¾Ø§Ø³Ø® JSON Ù†ÛŒØ³Øª. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø³ HTML...")

        soup = BeautifulSoup(response.text, 'lxml')
        all_menu_items = soup.select("li[id^='menu-item-']")
        if not all_menu_items:
            logger.error("âŒ Ù‡ÛŒÚ† Ø¢ÛŒØªÙ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø± HTML Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            return []
        logger.info(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ {len(all_menu_items)} Ø¢ÛŒØªÙ… Ù…Ù†Ùˆ Ù¾ÛŒØ¯Ø§ Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")

        cats_map = {}
        for item in all_menu_items:
            cat_id_raw = item.get('id', '')
            match = re.search(r'(\d+)', cat_id_raw)
            if not match: continue
            cat_menu_id = int(match.group(1))
            a_tag = item.find('a', recursive=False) or item.select_one("a")
            if not a_tag or not a_tag.get('href'): continue
            name = a_tag.text.strip()
            real_id_match = re.search(r'/Store/List/(\d+)', a_tag['href'])
            real_id = int(real_id_match.group(1)) if real_id_match else None
            if name and real_id and name != "#":
                cats_map[cat_menu_id] = {"id": real_id, "name": name, "parent_id": None}
        for item in all_menu_items:
            cat_id_raw = item.get('id', '')
            match = re.search(r'(\d+)', cat_id_raw)
            if not match: continue
            cat_menu_id = int(match.group(1))
            parent_li = item.find_parent("li", class_="menu-item-has-children")
            if parent_li:
                parent_id_raw = parent_li.get('id', '')
                parent_match = re.search(r'(\d+)', parent_id_raw)
                if parent_match:
                    parent_menu_id = int(parent_match.group(1))
                    if cat_menu_id in cats_map and parent_menu_id in cats_map:
                        cats_map[cat_menu_id]['parent_id'] = cats_map[parent_menu_id]['id']
        final_cats = list(cats_map.values())
        logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
        return final_cats
    except requests.RequestException as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None

# ==============================================================================
# --- Ú¯Ø±ÙØªÙ† Ù…Ø­ØµÙˆÙ„Ø§Øª Ù‡Ø± Ø¯Ø³ØªÙ‡ (ÙÙ‚Ø· Ù…ÙˆØ¬ÙˆØ¯Ù‡Ø§ Ùˆ ØªÙˆÙ‚Ù Ù‡ÙˆØ´Ù…Ù†Ø¯) Ø¨Ø§ Ù…ÙˆØ§Ø²ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª ---
# ==============================================================================
@retry(
    retry=retry_if_exception_type((requests.exceptions.RequestException, requests.exceptions.HTTPError)),
    stop=stop_after_attempt(4),
    wait=wait_random_exponential(multiplier=1, max=10),
    reraise=True
)
def get_products_from_category_page(session, category_id, max_pages=10, delay=0.5, specs_cache={}):
    all_products_in_category = []
    seen_product_ids = set()
    page = 1
    error_count = 0
    while page <= max_pages:
        # --- Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ HTML ---
        if page == 1:
            url = f"{BASE_URL}/Store/List/{category_id}/2/2/0/0/0/10000000000?text=%DA%AF%D9%88%D8%B4%DB%8C-%D9%85%D9%88%D8%A8%D8%A7%DB%8C%D9%84"
        else:
            url = f"{BASE_URL}/Store/List/{category_id}/2/2/{page-1}/0/0/10000000000?brands=&isMobile=false"
        logger.info(f"â³ Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ø² HTML ØµÙØ­Ù‡ {page} ...")
        try:
            resp = session.get(url, timeout=30)
            if resp.status_code != 200:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª HTML ØµÙØ­Ù‡ {page} - status: {resp.status_code} - url: {url}")
                break
            soup = BeautifulSoup(resp.text, 'lxml')
            product_blocks = soup.select(".goods-record")
            html_products = []
            for block in product_blocks:
                a_tag = block.select_one("a")
                name_tag = block.select_one("span.goods-record-title")
                unavailable = block.select_one(".goods-record-unavailable")
                is_available = unavailable is None
                if a_tag and name_tag:
                    product_id = None
                    href = a_tag['href']
                    match = re.search(r'/Store/Detail/\d+/(\d+)', href)
                    if match:
                        product_id = match.group(1)
                    name = name_tag.text.strip()
                    price_tag = block.select_one("span.goods-record-price")
                    price_text = price_tag.text.strip() if price_tag else ""
                    price = re.sub(r'[^\d]', '', price_text) if price_text else "0"
                    image_tag = block.select_one("img.goods-record-image")
                    image_url = image_tag.get('data-src', '') if image_tag else ''
                    if is_available and product_id and product_id not in seen_product_ids:
                        html_products.append({
                            'id': product_id,
                            'name': name,
                            'category_id': category_id,
                            'price': price,
                            'stock': 1,
                            'image': image_url,
                            'specs': None  # Ø¨Ø¹Ø¯Ø§Ù‹ Ù¾Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯
                        })
                        seen_product_ids.add(product_id)
            logger.info(f"ğŸŸ¢ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§ÙˆÙ„ÛŒÙ‡ (HTML) ØµÙØ­Ù‡ {page}: {len(html_products)}")

            # --- Ù…Ø­ØµÙˆÙ„Ø§Øª Lazy ---
            lazy_products = []
            lazy_page = 1
            referer_url = url
            while True:
                data = {
                    "ListViewType": 0,
                    "CatId": category_id,
                    "Order": 2,
                    "Sort": 2,
                    "LazyPageIndex": lazy_page,
                    "PageIndex": page - 1,
                    "PageSize": 24,
                    "Available": 0,
                    "MinPrice": 0,
                    "MaxPrice": 10000000000,
                    "IsLazyLoading": "true"
                }
                headers = {
                    "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
                    "X-Requested-With": "XMLHttpRequest",
                    "Referer": referer_url
                }
                logger.info(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª LazyPageIndex={lazy_page} ØµÙØ­Ù‡ {page} ...")
                resp = session.post(f"{BASE_URL}/Store/ListLazy", data=data, headers=headers, timeout=30)
                if resp.status_code != 200:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª (Ú©Ø¯: {resp.status_code})")
                    break
                try:
                    result = resp.json()
                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù¾Ø§Ø³Ø® Ø¨Ù‡ json: {e}")
                    logger.error(f"Ù…ØªÙ† Ù¾Ø§Ø³Ø® Ø³Ø±ÙˆØ±:\n{resp.text[:500]}")
                    break
                if not result or "Goods" not in result or not result["Goods"]:
                    logger.info(f"ğŸš© Ø¨Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Lazy ØµÙØ­Ù‡ {page} Ø±Ø³ÛŒØ¯ÛŒÙ… ÛŒØ§ Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
                    break
                goods = result["Goods"]
                for g in goods:
                    if g.get("Availability", True):
                        product_id = str(g["Id"])
                        if product_id not in seen_product_ids:
                            lazy_products.append({
                                "id": product_id,
                                "name": g["Name"],
                                "category_id": category_id,
                                "price": g.get("Price", "0"),
                                "stock": 1,
                                "image": g.get("ImageUrl", ""),
                                "specs": None  # Ø¨Ø¹Ø¯Ø§Ù‹ Ù¾Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯
                            })
                            seen_product_ids.add(product_id)
                logger.info(f"ğŸŸ¢ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§ÛŒÙ† ØµÙØ­Ù‡ Lazy: {len([g for g in goods if g.get('Availability', True)])}")
                lazy_page += 1

            # Ø¬Ù…Ø¹ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§ÛŒÙ† ØµÙØ­Ù‡
            products_in_page = html_products + lazy_products
            if not products_in_page:
                logger.info(f"â›”ï¸ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ø¯Ø± ØµÙØ­Ù‡ {page} Ù†Ø¨ÙˆØ¯. Ø¨Ø±Ø±Ø³ÛŒ ØµÙØ­Ø§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
                break

            # Ù…ÙˆØ§Ø²ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª
            with ThreadPoolExecutor(max_workers=4) as executor:  # Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ 4 Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú©
                future_to_product = {executor.submit(get_product_details, session, category_id, p['id'], specs_cache): p for p in products_in_page}
                for future in as_completed(future_to_product):
                    p = future_to_product[future]
                    try:
                        p['specs'] = future.result()
                    except Exception as e:
                        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª {p['id']}: {e}")
                        p['specs'] = {}
                    time.sleep(random.uniform(0.2, 0.5))  # delay Ú©ÙˆÚ†Ú© Ø¨ÛŒÙ† threadÙ‡Ø§

            all_products_in_category.extend([p for p in products_in_page if p['specs'] is not None])
            page += 1
            error_count = 0
            save_specs_cache(specs_cache)  # Ø°Ø®ÛŒØ±Ù‡ Ú©Ø´ Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø± ØµÙØ­Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ…Ù†ÛŒ
        except Exception as e:
            error_count += 1
            logger.error(f"    - Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙØ­Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª: {e} (ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·Ø§: {error_count})")
            if error_count >= 3:
                logger.critical(f"ğŸš¨ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…ØªÙˆØ§Ù„ÛŒ Ø¯Ø± Ø¯Ø³ØªÙ‡ {category_id} Ø¨Ù‡ {error_count} Ø±Ø³ÛŒØ¯! ØªÙˆÙ‚Ù Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡.")
                break
            time.sleep(2)
    logger.info(f"    - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ø§Ø² Ø¯Ø³ØªÙ‡ {category_id}: {len(all_products_in_category)}")
    return all_products_in_category

# ==============================================================================
# --- Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ù†Ø¨Ø¹ Ùˆ Ù…Ø´Ø®ØµØ§Øª (Ø¬Ø¯ÛŒØ¯: Ú©Ø´ Ù…Ø´Ø®ØµØ§Øª) ---
# ==============================================================================
def load_cache():
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r') as f:
            cache = json.load(f)
            logger.info(f"âœ… Ú©Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ù†Ø¨Ø¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯: {len(cache)}")
            return cache
    return {}

def save_cache(products):
    with open(CACHE_FILE, 'w') as f:
        json.dump(products, f, ensure_ascii=False, indent=4)

def load_specs_cache():
    if os.path.exists(SPECS_CACHE_FILE):
        with open(SPECS_CACHE_FILE, 'r') as f:
            cache = json.load(f)
            logger.info(f"âœ… Ú©Ø´ Ù…Ø´Ø®ØµØ§Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯: {len(cache)}")
            return cache
    return {}

def save_specs_cache(specs_cache):
    with open(SPECS_CACHE_FILE, 'w') as f:
        json.dump(specs_cache, f, ensure_ascii=False, indent=4)

# ==============================================================================
# --- Ú©Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ (Ø¬Ø¯ÛŒØ¯) ---
# ==============================================================================
def load_wc_cache():
    if os.path.exists(WC_CACHE_FILE):
        with open(WC_CACHE_FILE, 'r') as f:
            cache = json.load(f)
            logger.info(f"âœ… Ú©Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯: {len(cache)}")
            return cache
    return None

def save_wc_cache(products):
    with open(WC_CACHE_FILE, 'w') as f:
        json.dump(products, f, ensure_ascii=False, indent=4)

def get_all_wc_products_with_prefix(prefix="EWAYS-"):
    cached = load_wc_cache()
    if cached:
        logger.info("âœ… Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø§Ø² Ú©Ø´ Ù…Ø­Ù„ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        return cached
    
    products = []
    page = 1
    while True:
        try:
            res = requests.get(f"{WC_API_URL}/products", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), params={
                "per_page": 100, "page": page
            }, verify=False)
            res.raise_for_status()
            data = res.json()
            if not data: break
            filtered = [p for p in data if p.get('sku', '').startswith(prefix)]
            products.extend(filtered)
            logger.debug(f"      - ØµÙØ­Ù‡ {page}: {len(filtered)} Ù…Ø­ØµÙˆÙ„ Ø¨Ø§ Ù¾ÛŒØ´ÙˆÙ†Ø¯ {prefix} Ù¾ÛŒØ¯Ø§ Ø´Ø¯.")
            if len(data) < 100: break
            page += 1
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ (ØµÙØ­Ù‡ {page}): {e}")
            break
    save_wc_cache(products)
    logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø§ Ù¾ÛŒØ´ÙˆÙ†Ø¯ '{prefix}' Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒâ€ŒØ´Ø¯Ù‡: {len(products)}")
    return products

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ (Ø¨Ø§ batch Ø¬Ø¯ÛŒØ¯) ---
# ==============================================================================
def get_wc_categories():
    wc_cats, page = [], 1
    while True:
        try:
            res = requests.get(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), params={"per_page": 100, "page": page}, verify=False)
            res.raise_for_status()
            data = res.json()
            if not data: break
            wc_cats.extend(data)
            if len(data) < 100: break
            page += 1
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³: {e}")
            break
    logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒâ€ŒØ´Ø¯Ù‡: {len(wc_cats)}")
    return wc_cats

def check_existing_category(name, parent):
    try:
        res = requests.get(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), params={
            "search": name, "per_page": 1, "parent": parent
        }, verify=False)
        res.raise_for_status()
        data = res.json()
        for cat in data:
            if cat["name"].strip() == name and cat["parent"] == parent:
                return cat["id"]
        return None
    except Exception as e:
        logger.debug(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ú†Ú© ÙˆØ¬ÙˆØ¯ Ø¯Ø³ØªÙ‡ '{name}' (parent: {parent}): {e}")
        return None

def transfer_categories_to_wc(source_categories):
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
    wc_cats = get_wc_categories()
    wc_cats_map = {}
    for cat in wc_cats:
        key = (cat["name"].strip(), cat.get("parent", 0))
        wc_cats_map[key] = cat["id"]
    sorted_cats = []
    id_to_cat = {cat['id']: cat for cat in source_categories}
    def add_with_parents(cat):
        if cat['parent_id'] and cat['parent_id'] in id_to_cat:
            parent_cat = id_to_cat[cat['parent_id']]
            if parent_cat not in sorted_cats:
                add_with_parents(parent_cat)
        if cat not in sorted_cats:
            sorted_cats.append(cat)
    for cat in source_categories:
        add_with_parents(cat)
    source_to_wc_id_map = {}
    transferred = 0
    for cat in tqdm(sorted_cats, desc="Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§"):
        name = cat["name"].strip()
        parent_id = cat.get("parent_id") or 0
        wc_parent = source_to_wc_id_map.get(parent_id, 0)
        lookup_key = (name, wc_parent)
        existing_id = check_existing_category(name, wc_parent)
        if existing_id:
            source_to_wc_id_map[cat["id"]] = existing_id
            logger.debug(f"âœ… Ø¯Ø³ØªÙ‡ '{name}' (parent: {wc_parent}) Ù‚Ø¨Ù„Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ (ID: {existing_id}). Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ÙˆØ¬ÙˆØ¯.")
            transferred += 1
            continue
        data = {"name": name, "parent": wc_parent}
        try:
            res = requests.post(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), json=data, verify=False)
            if res.status_code in [200, 201]:
                new_id = res.json()["id"]
                source_to_wc_id_map[cat["id"]] = new_id
                wc_cats_map[lookup_key] = new_id
                logger.debug(f"âœ… Ø¯Ø³ØªÙ‡ '{name}' (parent: {wc_parent}) Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ (ID: {new_id}).")
                transferred += 1
            else:
                error_data = res.json()
                if error_data.get("code") == "term_exists" and "data" in error_data and "resource_id" in error_data["data"]:
                    existing_id = error_data["data"]["resource_id"]
                    source_to_wc_id_map[cat["id"]] = existing_id
                    wc_cats_map[lookup_key] = existing_id
                    logger.info(f"âœ… Ø¯Ø³ØªÙ‡ '{name}' (parent: {wc_parent}) ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´Øª (ID: {existing_id}). Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² resource_id Ù…ÙˆØ¬ÙˆØ¯.")
                    transferred += 1
                else:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ '{name}' (parent: {wc_parent}): {res.text}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ø³Ø§Ø®Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ '{name}': {e}")
    logger.info(f"âœ… Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†ØªÙ‚Ù„â€ŒØ´Ø¯Ù‡: {transferred}/{len(source_categories)}")
    return source_to_wc_id_map

def process_price(price_value):
    try:
        price_value = float(re.sub(r'[^\d.]', '', str(price_value)))
        price_value /= 10
    except (ValueError, TypeError): return "0"
    if price_value <= 1: return "0"
    elif price_value <= 7000000: new_price = price_value + 260000
    elif price_value <= 10000000: new_price = price_value * 1.035
    elif price_value <= 20000000: new_price = price_value * 1.025
    elif price_value <= 30000000: new_price = price_value * 1.02
    else: new_price = price_value * 1.015
    return str(int(round(new_price, -4)))

@retry(
    retry=retry_if_exception_type((requests.exceptions.RequestException, requests.exceptions.HTTPError)),
    stop=stop_after_attempt(3),
    wait=wait_random_exponential(multiplier=1, max=10),
    reraise=True
)
def send_batch_to_woocommerce(batch_data, stats, is_outofstock=False):
    try:
        auth = (WC_CONSUMER_KEY, WC_CONSUMER_SECRET)
        res = requests.post(f"{WC_API_URL}/products/batch", auth=auth, json=batch_data, verify=False, timeout=60)
        if res.status_code == 429:  # Rate limit
            logger.warning("âš ï¸ Rate limit Ø±Ø³ÛŒØ¯. ØªØ§Ø®ÛŒØ± Ø§Ø¶Ø§ÙÙ‡...")
            time.sleep(5)
        res.raise_for_status()
        response = res.json()
        created = len(response.get('create', []))
        updated = len(response.get('update', []))
        stats['created'] += created
        stats['updated'] += updated
        if is_outofstock:
            stats['outofstock_updated'] += updated
        logger.info(f"âœ… Batch Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯: Ø§ÛŒØ¬Ø§Ø¯ {created}, Ø¢Ù¾Ø¯ÛŒØª {updated}")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ batch: {e}")
        stats['failed'] += len(batch_data.get('create', [])) + len(batch_data.get('update', []))

# ==============================================================================
# --- Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø³Ø¦Ùˆ Ù…Ø­ÙˆØ± ---
# ==============================================================================
def smart_tags_for_product(product, cat_map):
    tags = set()
    name = product.get('name', '')
    specs = product.get('specs', {})
    cat_id = product.get('category_id')
    cat_name = cat_map.get(cat_id, '').strip()
    price = int(product.get('price', 0))

    name_parts = [w for w in re.split(r'\s+', name) if w and len(w) > 2]
    common_words = {'Ú¯ÙˆØ´ÛŒ', 'Ù…ÙˆØ¨Ø§ÛŒÙ„', 'ØªØ¨Ù„Øª', 'Ù„Ù¾ØªØ§Ù¾', 'Ù„Ù¾â€ŒØªØ§Ù¾', 'Ù…Ø¯Ù„', 'Ù…Ø­ØµÙˆÙ„', 'Ú©Ø§Ù„Ø§', 'Ø¬Ø¯ÛŒØ¯'}
    for part in name_parts[:2]:
        if part not in common_words:
            tags.add(part)

    if cat_name and cat_name not in common_words:
        tags.add(cat_name)

    important_keys = ['Ø±Ù†Ú¯', 'Color', 'Ø­Ø§ÙØ¸Ù‡', 'Ø¸Ø±ÙÛŒØª', 'Ø§Ù†Ø¯Ø§Ø²Ù‡', 'Ø³Ø§ÛŒØ²', 'Size', 'Ù…Ø¯Ù„', 'Ø¨Ø±Ù†Ø¯']
    for key, value in specs.items():
        if any(imp in key for imp in important_keys):
            val = value.strip()
            if 2 < len(val) < 30 and val not in common_words:
                tags.add(val)

    if price > 0:
        if price < 5000000:
            tags.add('Ø§Ù‚ØªØµØ§Ø¯ÛŒ')
        elif price > 20000000:
            tags.add('Ù„ÙˆÚ©Ø³')

    tags.add('Ø®Ø±ÛŒØ¯ Ø¢Ù†Ù„Ø§ÛŒÙ†')
    tags.add('Ú¯Ø§Ø±Ø§Ù†ØªÛŒ Ø¯Ø§Ø±')

    tags = {t for t in tags if t and len(t) <= 30 and t.lower() not in ['test', 'spam', 'Ù…Ø­ØµÙˆÙ„', 'Ú©Ø§Ù„Ø§']}

    return [{"name": t} for t in sorted(tags)]

# ==============================================================================
# --- ØªÙ‡ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ batch ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ ---
# ==============================================================================
def prepare_wc_data(product, category_mapping, cat_map, sku_to_wc):
    wc_cat_id = category_mapping.get(product.get('category_id'))
    if not wc_cat_id:
        return None
    specs = product.get('specs', {})
    attributes = []
    position = 0
    for key, value in specs.items():
        attributes.append({
            "name": key,
            "options": [value],
            "position": position,
            "visible": True,
            "variation": False
        })
        position += 1

    tags = smart_tags_for_product(product, cat_map)

    data = {
        "name": product.get('name', 'Ø¨Ø¯ÙˆÙ† Ù†Ø§Ù…'),
        "type": "simple",
        "sku": f"EWAYS-{product.get('id')}",
        "regular_price": process_price(product.get('price', 0)),
        "categories": [{"id": wc_cat_id}],
        "images": [{"src": product.get("image")}] if product.get("image") else [],
        "stock_quantity": product.get('stock', 0),
        "manage_stock": True,
        "stock_status": "instock" if product.get('stock', 0) > 0 else "outofstock",
        "attributes": attributes,
        "tags": tags
    }

    sku = data['sku']
    if sku in sku_to_wc:
        data['id'] = sku_to_wc[sku]['id']  # Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ø¯ÛŒØª
        return ('update', data)
    return ('create', data)

# ==============================================================================
# --- Ù¾Ø±ÛŒÙ†Øª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø´Ø§Ø®Ù‡â€ŒØ§ÛŒ Ùˆ Ù…Ø±ØªØ¨ ---
# ==============================================================================
def print_products_tree(products, categories):
    cat_map = {cat['id']: cat['name'] for cat in categories}
    tree = defaultdict(list)
    for key, product in products.items():
        if '|' not in key:
            logger.warning(f"Ú©Ù„ÛŒØ¯ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¯Ø± Ú©Ø´ ÛŒØ§ Ù…Ø­ØµÙˆÙ„Ø§Øª: {key} (Ø±Ø¯ Ø´Ø¯)")
            continue
        pid, catid = key.split('|')
        tree[catid].append(product)
    for catid in sorted(tree, key=lambda x: int(x)):
        logger.info(f"Ø¯Ø³ØªÙ‡ [{catid}] {cat_map.get(int(catid), 'Ù†Ø§Ù…Ø´Ø®Øµ')}:")
        for p in sorted(tree[catid], key=lambda x: int(x['id'])):
            logger.info(f"   - {p['name']} (ID: {p['id']})")

# ==============================================================================
# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ---
# ==============================================================================
def main():
    session = login_eways(EWAYS_USERNAME, EWAYS_PASSWORD)
    if not session:
        logger.error("âŒ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ Ù¾Ù†Ù„ eways Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
        return

    all_cats = get_and_parse_categories(session)
    if not all_cats:
        logger.error("âŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯.")
        return
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ 1: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯: {len(all_cats)}")

    SELECTED_IDS_STRING = "16777:all-allz|4882:all-allz|16778:22570-all-allz"
    parsed_selection = parse_selected_ids_string(SELECTED_IDS_STRING)
    logger.info(f"âœ… Ø§Ù†ØªØ®Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø¯Ù„Ø®ÙˆØ§Ù‡: {parsed_selection}")

    filtered_categories = get_selected_categories_according_to_selection(parsed_selection, all_cats)
    logger.info(f"âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ: {[cat['name'] for cat in filtered_categories]}")

    category_mapping = transfer_categories_to_wc(filtered_categories)
    if not category_mapping:
        logger.error("âŒ Ù†Ú¯Ø§Ø´Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
        return
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ 5: Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù†Ú¯Ø§Ø´Øªâ€ŒØ´Ø¯Ù‡: {len(category_mapping)}")

    cached_products = load_cache()
    specs_cache = load_specs_cache()

    max_workers = 3
    delay = 0.5
    min_workers = 1
    max_max_workers = 6
    min_delay = 0.2
    max_delay = 2.0

    selected_ids = [cat['id'] for cat in filtered_categories]
    all_products = {}
    logger.info(f"\nâ³ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ØªÙ…Ø§Ù… Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ù‡Ù…Ù‡ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ùˆ Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§...")

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_catid = {}
        for cat_id in selected_ids:
            future = executor.submit(get_products_from_category_page, session, cat_id, 10, delay, specs_cache)
            future_to_catid[future] = cat_id

        pbar = tqdm(total=len(selected_ids), desc="Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§")
        for future in as_completed(future_to_catid):
            cat_id = future_to_catid[future]
            try:
                products_in_cat = future.result()
                for product in products_in_cat:
                    key = f"{product['id']}|{cat_id}"
                    all_products[key] = product
                if max_workers < max_max_workers:
                    max_workers += 1
                if delay > min_delay:
                    delay = max(min_delay, delay - 0.05)
            except Exception as e:
                logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø³ØªÙ‡ {cat_id}: {e}")
                if "Blocked" in str(e) or "rate limited" in str(e) or "429" in str(e):
                    if max_workers > min_workers:
                        max_workers -= 1
                    if delay < max_delay:
                        delay = min(max_delay, delay + 0.2)
                    logger.warning(f"ğŸš¦ Ø³Ø±Ø¹Øª Ú©Ù… Ø´Ø¯: max_workers={max_workers}, delay={delay:.2f}")
            pbar.update(1)
        pbar.close()

    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ 6: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØµÙˆÙ„Ø§Øª Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡: {len(all_products)}")

    print_products_tree(all_products, filtered_categories)

    updated_products = {}
    changed_products = []
    new_products_by_category = {}

    for key, p in all_products.items():
        if key in cached_products and cached_products[key]['price'] == p['price'] and cached_products[key]['stock'] == p['stock'] and cached_products[key]['specs'] == p['specs']:
            updated_products[key] = cached_products[key]
        else:
            updated_products[key] = p
            changed_products.append(p)
            cat_id = p['category_id']
            new_products_by_category[cat_id] = new_products_by_category.get(cat_id, 0) + 1

    changed_count = len(changed_products)
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ 7: Ø§Ø¯ØºØ§Ù… Ø¨Ø§ Ú©Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª ØªØºÛŒÛŒØ±Ø´Ø¯Ù‡/Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„: {changed_count}")

    logger.info("ğŸ“Š Ø¢Ù…Ø§Ø± Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯/ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ:")
    cat_map = {cat['id']: cat['name'] for cat in filtered_categories}
    for cat_id, count in sorted(new_products_by_category.items(), key=lambda x: -x[1]):
        logger.info(f"  - {cat_map.get(cat_id, str(cat_id))}: {count} Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯/ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡")

    save_cache(updated_products)
    save_specs_cache(specs_cache)

    # ==============================================================================
    # --- Ù…Ø±Ø­Ù„Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯ Ùˆ Ú©Ø´ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ ---
    # ==============================================================================
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯...")
    wc_products = get_all_wc_products_with_prefix("EWAYS-")
    sku_to_wc = {p['sku']: p for p in wc_products}  # Ú©Ø´ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ú†Ú© Ø³Ø±ÛŒØ¹
    extracted_skus = {f"EWAYS-{p['id']}" for p in all_products.values()}
    outofstock_ids = []

    # Ù…Ø­ØµÙˆÙ„Ø§Øª Ú©Ø´ Ù‚Ø¨Ù„ÛŒ Ú©Ù‡ Ø§Ù„Ø§Ù† Ù†ÛŒØ³ØªÙ†Ø¯
    for key in cached_products:
        if '|' not in key: continue
        pid, _ = key.split('|')
        sku = f"EWAYS-{pid}"
        if sku not in extracted_skus and sku in sku_to_wc and sku_to_wc[sku]['stock_status'] != "outofstock":
            outofstock_ids.append(sku_to_wc[sku]['id'])

    # Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ú©Ù‡ Ø§Ù„Ø§Ù† Ù†ÛŒØ³ØªÙ†Ø¯
    for sku, p in sku_to_wc.items():
        if sku not in extracted_skus and p['stock_status'] != "outofstock":
            outofstock_ids.append(p['id'])

    outofstock_count = len(outofstock_ids)
    logger.info(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ø¯ÛŒØª Ø¨Ù‡ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯: {outofstock_count}")

    stats = {'created': 0, 'updated': 0, 'failed': 0, 'no_category': 0, 'outofstock_updated': 0, 'lock': Lock()}
    logger.info(f"\nğŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø§Ø±Ø³Ø§Ù„ {changed_count} Ù…Ø­ØµÙˆÙ„ (ØªØºÛŒÛŒØ±Ø´Ø¯Ù‡/Ø¬Ø¯ÛŒØ¯) Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø§ batch...")

    # ØªÙ‡ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ batch Ù…Ø­ØµÙˆÙ„Ø§Øª ØªØºÛŒÛŒØ±Ø´Ø¯Ù‡/Ø¬Ø¯ÛŒØ¯
    batch_create = []
    batch_update = []
    no_category_count = 0
    for product in changed_products:
        prepared = prepare_wc_data(product, category_mapping, cat_map, sku_to_wc)
        if not prepared:
            no_category_count += 1
            continue
        action, data = prepared
        if action == 'create':
            batch_create.append(data)
        else:
            batch_update.append(data)

    stats['no_category'] = no_category_count

    # Ø§Ø±Ø³Ø§Ù„ batch Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª ØªØºÛŒÛŒØ±Ø´Ø¯Ù‡
    batch_size = 50  # Ø§Ù†Ø¯Ø§Ø²Ù‡ batch (Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…)
    for i in range(0, len(batch_create), batch_size):
        batch_data = {"create": batch_create[i:i+batch_size]}
        send_batch_to_woocommerce(batch_data, stats)
        time.sleep(random.uniform(1, 2))  # delay Ø¨ÛŒÙ† batchÙ‡Ø§

    for i in range(0, len(batch_update), batch_size):
        batch_data = {"update": batch_update[i:i+batch_size]}
        send_batch_to_woocommerce(batch_data, stats)
        time.sleep(random.uniform(1, 2))

    # batch Ø¨Ø±Ø§ÛŒ outofstock
    batch_outofstock = []
    for pid in outofstock_ids:
        batch_outofstock.append({
            "id": pid,
            "stock_quantity": 0,
            "stock_status": "outofstock",
            "manage_stock": True
        })

    for i in range(0, len(batch_outofstock), batch_size):
        batch_data = {"update": batch_outofstock[i:i+batch_size]}
        send_batch_to_woocommerce(batch_data, stats, is_outofstock=True)
        time.sleep(random.uniform(1, 2))

    logger.info("\n===============================")
    logger.info(f"ğŸ“¦ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ (Ù…ÙˆØ¬ÙˆØ¯): {changed_count}")
    logger.info(f"ğŸŸ¢ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: {stats['created']}")
    logger.info(f"ğŸ”µ Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯Ù‡: {stats['updated']}")
    logger.info(f"ğŸŸ  Ø¢Ù¾Ø¯ÛŒØª Ø¨Ù‡ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯: {stats['outofstock_updated']}")
    logger.info(f"ğŸ”´ Ø´Ú©Ø³Øªâ€ŒØ®ÙˆØ±Ø¯Ù‡: {stats['failed']}")
    logger.info(f"ğŸŸ¡ Ø¨Ø¯ÙˆÙ† Ø¯Ø³ØªÙ‡: {stats.get('no_category', 0)}")
    logger.info("===============================\nØªÙ…Ø§Ù…!")

if __name__ == "__main__":
    main()
