import requests
import urllib3
import os
import re
import time
import json
import sys
import random
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
from bs4 import BeautifulSoup
from threading import Lock
import logging
from logging.handlers import RotatingFileHandler
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

# ==============================================================================
# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯ ---
# ==============================================================================
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')  # Ø³Ø·Ø­ DEBUG Ø¨Ø±Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±
logger = logging.getLogger(__name__)
handler = RotatingFileHandler('app.log', maxBytes=1024*1024, backupCount=5)  # 1MB per file, 5 backups
handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)

# ==============================================================================
# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ ---
# ==============================================================================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø§ÛŒØª Eways ---
BASE_URL = "https://panel.eways.co"
AUT_COOKIE_VALUE = os.environ.get("EWAYS_AUTH_TOKEN")
SOURCE_CATS_API_URL = f"{BASE_URL}/Store/GetCategories"
PRODUCT_LIST_URL_TEMPLATE = f"{BASE_URL}/Store/List/{{category_id}}/2/2/0/0/0/10000000000?page={{page}}"
PRODUCT_DETAIL_URL_TEMPLATE = f"{BASE_URL}/Store/Detail/{{cat_id}}/{{product_id}}"

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ (Eways.co) ---
# ==============================================================================

def get_session():
    """ÛŒÚ© Session Ø¨Ø§ Ú©ÙˆÚ©ÛŒ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ùˆ retry mechanism Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': f"{BASE_URL}/",
        'X-Requested-With': 'XMLHttpRequest'
    })
    if AUT_COOKIE_VALUE:
        session.cookies.set('Aut', AUT_COOKIE_VALUE, domain='panel.eways.co')
    session.verify = False
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† retry Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§
    retry_strategy = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    return session

def get_and_parse_categories(session):
    """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² API Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ© Ù„ÛŒØ³Øª Ù…Ø³Ø·Ø­ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯."""
    logger.info(f"â³ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø²: {SOURCE_CATS_API_URL}")
    try:
        response = session.get(SOURCE_CATS_API_URL, timeout=30)
        response.raise_for_status()
        logger.info("âœ… Ù¾Ø§Ø³Ø® Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
        
        # Ø§ÙˆÙ„ Ø³Ø¹ÛŒ Ø¯Ø± Ù¾Ø§Ø±Ø³ JSON (Ø§Ú¯Ø± API JSON Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯)
        try:
            data = response.json()
            logger.info("âœ… Ù¾Ø§Ø³Ø® JSON Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")
            final_cats = []
            for c in data:  # ÙØ±Ø¶ Ø³Ø§Ø®ØªØ§Ø±: [{'id': int, 'name': str, 'parent_id': int or None, 'url': str}]
                real_id_match = re.search(r'/Store/List/(\d+)', c.get('url', ''))
                real_id = int(real_id_match.group(1)) if real_id_match else c.get('id')
                final_cats.append({
                    "id": real_id,
                    "name": c.get('name', '').strip(),
                    "parent_id": c.get('parent_id')
                })
            logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø² JSON Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
            return final_cats
        except json.JSONDecodeError:
            logger.warning("âš ï¸ Ù¾Ø§Ø³Ø® JSON Ù†ÛŒØ³Øª. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø³ HTML...")
        
        # Ø§Ú¯Ø± JSON Ù†Ø¨ÙˆØ¯ØŒ Ù¾Ø§Ø±Ø³ HTML
        soup = BeautifulSoup(response.text, 'lxml')
        all_menu_items = soup.select("li[id^='menu-item-']")
        
        if not all_menu_items:
            logger.error("âŒ Ù‡ÛŒÚ† Ø¢ÛŒØªÙ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø± HTML Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            return []
            
        logger.info(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ {len(all_menu_items)} Ø¢ÛŒØªÙ… Ù…Ù†Ùˆ Ù¾ÛŒØ¯Ø§ Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")
        
        cats_map = {}
        for item in all_menu_items:
            cat_id_raw = item.get('id', '')
            match = re.search(r'(\d+)', cat_id_raw)
            if not match: continue
            cat_menu_id = int(match.group(1))

            a_tag = item.find('a', recursive=False) or item.select_one("a")
            if not a_tag or not a_tag.get('href'): continue
            
            name = a_tag.text.strip()
            real_id_match = re.search(r'/Store/List/(\d+)', a_tag['href'])
            real_id = int(real_id_match.group(1)) if real_id_match else None

            if name and real_id and name != "#":
                cats_map[cat_menu_id] = {"id": real_id, "name": name, "parent_id": None}

        for item in all_menu_items:
            cat_id_raw = item.get('id', '')
            match = re.search(r'(\d+)', cat_id_raw)
            if not match: continue
            cat_menu_id = int(match.group(1))

            parent_li = item.find_parent("li", class_="menu-item-has-children")
            if parent_li:
                parent_id_raw = parent_li.get('id', '')
                parent_match = re.search(r'(\d+)', parent_id_raw)
                if parent_match:
                    parent_menu_id = int(parent_match.group(1))
                    if cat_menu_id in cats_map and parent_menu_id in cats_map:
                        cats_map[cat_menu_id]['parent_id'] = cats_map[parent_menu_id]['id']
        
        final_cats = list(cats_map.values())
        logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
        return final_cats
    except requests.RequestException as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None

def build_category_tree(categories):
    """Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø±Ø®ØªÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ parent_id Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯."""
    tree = {}
    for cat in categories:
        tree[cat['id']] = cat.copy()
        tree[cat['id']]['children'] = []
    
    for cat in categories:
        parent_id = cat.get('parent_id')
        if parent_id and parent_id in tree:
            tree[parent_id]['children'].append(cat['id'])
    
    return tree

def get_selected_categories_flexible(source_categories):
    """Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ø§Ø±Ø¨Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†Ø¯. Ø¯Ø± Ù…Ø­ÛŒØ· ØºÛŒØ±ØªØ¹Ø§Ù…Ù„ÛŒØŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if not source_categories:
        logger.warning("âš ï¸ Ù‡ÛŒÚ† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return []
    
    logger.info("ğŸ“‹ Ù„ÛŒØ³Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§:")
    for i, cat in enumerate(source_categories):
        logger.info(f"{i+1}: {cat['name']} (ID: {cat['id']})")
    
    try:
        selected_input = input("Ø´Ù…Ø§Ø±Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø¨Ø§ Ú©Ø§Ù…Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (Ù…Ø«Ù„ 1,3) ÛŒØ§ 'all' Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡: ").strip().lower()
    except EOFError:
        logger.warning("âš ï¸ ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª (EOF). Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ (IDÙ‡Ø§ÛŒ 1582 Ùˆ 2541).")
        default_ids = [1582, 2541]  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Ø¬Ø§Ù†Ø¨ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ùˆ Ø¬Ø§Ù†Ø¨ÛŒ Ø±Ø§ÛŒØ§Ù†Ù‡
        selected = [c for c in source_categories if c['id'] in default_ids]
        logger.info(f"âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡: {[c['name'] for c in selected]}")
        return selected
    
    if selected_input == 'all':
        return source_categories
    
    try:
        indices = [int(x.strip()) - 1 for x in selected_input.split(',')]
        selected = [source_categories[i] for i in indices if 0 <= i < len(source_categories)]
        logger.info(f"âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡: {[c['name'] for c in selected]}")
        return selected
    except ValueError:
        logger.error("âŒ ÙˆØ±ÙˆØ¯ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±. Ù‡ÛŒÚ† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯.")
        return []

def get_product_detail(session, cat_id, product_id):
    """Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ Ø±Ø§ Ø§Ø² ØµÙØ­Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ú†Ú© Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù†)."""
    if not product_id or product_id.startswith('##'):  # Skip placeholder IDs
        logger.debug(f"      - Ø±Ø¯ Ú©Ø±Ø¯Ù† product_id Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {product_id}")
        return None
    
    url = PRODUCT_DETAIL_URL_TEMPLATE.format(cat_id=cat_id, product_id=product_id)
    logger.debug(f"      - Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ Ø§Ø²: {url}")
    try:
        response = session.get(url, timeout=30)
        if response.status_code != 200:
            logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª: status {response.status_code}")
            return None
        soup = BeautifulSoup(response.text, 'lxml')
        
        name = soup.select_one("h1.product-title").text.strip() if soup.select_one("h1.product-title") else None
        price_tag = soup.select_one(".product-price .price")
        price = re.sub(r'[^\d]', '', price_tag.text.strip()) if price_tag else "0"
        stock_tag = soup.select_one(".product-stock span")
        stock = int(re.sub(r'[^\d]', '', stock_tag.text.strip())) if stock_tag else 0
        
        if name and int(price) > 0 and stock > 0:
            return True  # ÙÙ‚Ø· Ú†Ú© Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù‡
        else:
            return False
    except Exception as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø±Ø³ Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}")
        return False

def count_products_in_category(session, category_id, max_pages=5):
    """ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± ÛŒÚ© Ø¯Ø³ØªÙ‡ Ø±Ø§ Ø´Ù…Ø§Ø±Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Ø¨Ø¯ÙˆÙ† Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒØ³Øª)."""
    count = 0
    seen_product_ids = set()
    page_num = 1
    
    while page_num <= max_pages:
        url = PRODUCT_LIST_URL_TEMPLATE.format(category_id=category_id, page=page_num)
        logger.info(f"  - Ø¯Ø± Ø­Ø§Ù„ Ø´Ù…Ø§Ø±Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø²: {url}")
        
        try:
            response = session.get(url, timeout=30)
            if response.status_code != 200: break
                
            soup = BeautifulSoup(response.text, 'lxml')
            product_blocks = soup.select(".goods_item.goods-record")
            if not product_blocks: break

            for block in product_blocks:
                try:
                    classes = block.get('class', [])
                    if 'soldOut' in classes: continue

                    a_tag = block.select_one("a")
                    href = a_tag['href'] if a_tag else None
                    product_id = None
                    if href:
                        match = re.search(r'/Store/Detail/\d+/(\d+)', href)
                        product_id = match.group(1) if match else None
                    if not product_id or product_id in seen_product_ids or product_id.startswith('##'):
                        continue

                    # Ú†Ú© Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨Ø±Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù†
                    if get_product_detail(session, category_id, product_id):
                        seen_product_ids.add(product_id)
                        count += 1
                except Exception as e:
                    logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© Ø¨Ù„Ø§Ú© Ù…Ø­ØµÙˆÙ„: {e}")

            if len(product_blocks) == 0:
                break

            page_num += 1
            time.sleep(random.uniform(2, 3))
        except Exception as e:
            logger.error(f"    - Ø®Ø·Ø§ Ø¯Ø± Ø´Ù…Ø§Ø±Ø´ ØµÙØ­Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª: {e}")
            break
            
    return count

def count_products_recursive(session, cat_id, category_tree):
    """ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡ Ùˆ ØªÙ…Ø§Ù… Ø²ÛŒØ± Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    cat = category_tree.get(cat_id)
    if not cat:
        return 0
    
    # Ú†Ø§Ù¾ Ø¹Ù†ÙˆØ§Ù† Ø¯Ø³ØªÙ‡ Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ Ø§ØµÙ„ÛŒ
    print(f"Ø¹Ù†ÙˆØ§Ù† Ø¯Ø³ØªÙ‡: {cat['name']} (ID: {cat_id})")
    
    # Ø´Ù…Ø§Ø±Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡
    direct_count = count_products_in_category(session, cat_id)
    
    # Ø´Ù…Ø§Ø±Ø´ Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ Ø²ÛŒØ± Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§
    total_count = direct_count
    for child_id in cat.get('children', []):
        total_count += count_products_recursive(session, child_id, category_tree)
    
    # ÙÙ‚Ø· ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ø§ Ø¯Ø± Ù„Ø§Ú¯ Ú†Ø§Ù¾ Ú©Ù†
    logger.info(f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± Ø¯Ø³ØªÙ‡ '{cat['name']}' (ID: {cat_id}) Ùˆ ØªÙ…Ø§Ù… Ø²ÛŒØ± Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§: {total_count}")
    
    return total_count

# ==============================================================================
# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ ---
# ==============================================================================
def main():
    if not AUT_COOKIE_VALUE:
        logger.error("âŒ Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ EWAYS_AUTH_TOKEN ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return

    session = get_session()
    
    # 1. Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
    source_categories = get_and_parse_categories(session)
    if not source_categories: return

    filtered_categories = get_selected_categories_flexible(source_categories)
    if not filtered_categories:
        logger.info("âœ… Ù‡ÛŒÚ† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
        return

    # 2. Ø³Ø§Ø®Øª Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø±Ø®ØªÛŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§
    category_tree = build_category_tree(source_categories)

    # 3. Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ Ùˆ Ø´Ù…Ø§Ø±Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ Ùˆ Ø´Ù…Ø§Ø±Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª...")
    total_products = 0
    for category in tqdm(filtered_categories, desc="Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§"):
        total_products += count_products_recursive(session, category['id'], category_tree)
    
    logger.info(f"\nâœ… ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± ØªÙ…Ø§Ù… Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ Ùˆ Ø²ÛŒØ± Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§: {total_products}")

if __name__ == "__main__":
    main()
