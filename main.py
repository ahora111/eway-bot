import requests
from bs4 import BeautifulSoup
import re
import time

BASE_URL = "https://panel.eways.co"
CATEGORY_ID = 4286  # Ø¯Ø³ØªÙ‡ Ú¯ÙˆØ´ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„
PRODUCT_LIST_URL = f"{BASE_URL}/Store/List/{CATEGORY_ID}/2/2/0/0/0/10000000000"

def login_eways(username, password):
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': BASE_URL + '/user/login',
        'X-Requested-With': 'XMLHttpRequest',
        'Accept-Language': 'fa',
        'Origin': BASE_URL
    })
    session.verify = False

    # Ù…Ø±Ø­Ù„Ù‡ 1: Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡ Ù„Ø§Ú¯ÛŒÙ† Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆÚ©Ù†
    login_page = session.get(BASE_URL + "/user/login")
    soup = BeautifulSoup(login_page.text, 'lxml')
    token_input = soup.find('input', {'name': '__RequestVerificationToken'})
    token_value = token_input['value'] if token_input else ''
    if not token_value:
        print("âŒ Ù†ØªÙˆØ§Ù†Ø³ØªÙ… ØªÙˆÚ©Ù† Ø¢Ù†ØªÛŒâ€ŒÙÙˆØ±Ø¬Ø±ÛŒ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ù…!")
        return None

    time.sleep(0.5)  # ØªØ§Ø®ÛŒØ± Ú©ÙˆØªØ§Ù‡

    # Ù…Ø±Ø­Ù„Ù‡ 2: Ø§Ø±Ø³Ø§Ù„ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ø§ ØªÙˆÚ©Ù†
    login_url = BASE_URL + "/User/Login"
    payload = {
        "UserName": username,
        "Password": password,
        "RememberMe": "true",
        "__RequestVerificationToken": token_value
    }
    resp = session.post(login_url, data=payload, timeout=30)
    if resp.status_code == 200 and 'Aut' in session.cookies:
        print("âœ… Login OK")
        return session
    if "Ú©Ù¾Ú†Ø§" in resp.text or "captcha" in resp.text.lower():
        print("âŒ Ú©Ù¾Ú†Ø§ ÙØ¹Ø§Ù„ Ø´Ø¯Ù‡! Ù„Ø§Ú¯ÛŒÙ† Ø¨Ø§ Ø±Ø¨Ø§Øª Ù…Ù…Ú©Ù† Ù†ÛŒØ³Øª.")
    else:
        print("âŒ Login failed")
    return None

def get_all_products(session):
    all_products = []
    page = 1
    while True:
        url = f"{PRODUCT_LIST_URL}?page={page}"
        print(f"â³ Fetching page {page} ...")
        resp = session.get(url, timeout=30)
        if resp.status_code != 200:
            print("âŒ Error fetching page")
            break
        soup = BeautifulSoup(resp.text, 'lxml')
        product_blocks = soup.select(".goods-record")
        if not product_blocks:
            print("ğŸš© No more products found.")
            break
        for block in product_blocks:
            a_tag = block.select_one("a")
            name_tag = block.select_one("span.goods-record-title")
            if a_tag and name_tag:
                product_id = None
                href = a_tag['href']
                match = re.search(r'/Store/Detail/\d+/(\d+)', href)
                if match:
                    product_id = match.group(1)
                name = name_tag.text.strip()
                all_products.append({'id': product_id, 'name': name})
        # Ø§Ú¯Ø± ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÛŒÙ† ØµÙØ­Ù‡ Ú©Ù…ØªØ± Ø§Ø² 96 Ø´Ø¯ØŒ ÛŒØ¹Ù†ÛŒ Ø¢Ø®Ø±ÛŒÙ† ØµÙØ­Ù‡ Ø§Ø³Øª
        if len(product_blocks) < 96:
            break
        page += 1
        time.sleep(1)
    return all_products

if __name__ == "__main__":
    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù„Ø§Ú¯ÛŒÙ† Ø®ÙˆØ¯Øª Ø±Ùˆ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø°Ø§Ø±
    username = "Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„ ÛŒØ§ ÛŒÙˆØ²Ø±Ù†ÛŒÙ…"
    password = "Ù¾Ø³ÙˆØ±Ø¯"
    session = login_eways(username, password)
    if not session:
        exit(1)
    products = get_all_products(session)
    print(f"\nâœ… ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡: {len(products)}\n")
    for i, p in enumerate(products, 1):
        print(f"{i:03d}. {p['name']} (ID: {p['id']})")
