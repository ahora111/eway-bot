import requests
import os
import re
import time
import json
import random
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
from bs4 import BeautifulSoup
from threading import Lock
import logging
from logging.handlers import RotatingFileHandler
from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø§Ù†ØªØ®Ø§Ø¨ ---
# ==============================================================================
def get_all_descendants(parent_id, all_cats_map):
    """ØªÙ…Ø§Ù… Ù†ÙˆØ§Ø¯Ú¯Ø§Ù† ÛŒÚ© Ø¯Ø³ØªÙ‡ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    descendants = set()
    children = [cat['id'] for cat in all_cats_map.values() if cat.get('parent_id') == parent_id]
    for child_id in children:
        descendants.add(child_id)
        descendants.update(get_all_descendants(child_id, all_cats_map))
    return descendants

def process_selection_rules(rule_string, all_cats, logger_instance):
    """Ø±Ø´ØªÙ‡ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ùˆ Ù„ÛŒØ³Øª ID Ù…Ø¬Ø²Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯."""
    structure_ids, product_ids = set(), set()
    all_cats_map = {cat['id']: cat for cat in all_cats}
    for rule in rule_string.split('|'):
        rule = rule.strip()
        if not rule or ':' not in rule: continue
        try:
            parent_id_str, selections_str = rule.split(':', 1)
            parent_id = int(parent_id_str.strip())
            if parent_id not in all_cats_map:
                logger_instance.warning(f"âš ï¸ Ø´Ù†Ø§Ø³Ù‡ ÙˆØ§Ù„Ø¯ {parent_id} Ø¯Ø± Ù‚Ø§Ù†ÙˆÙ† '{rule}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                continue
            structure_ids.add(parent_id)
            for sel in selections_str.split(','):
                sel = sel.strip()
                if not sel: continue
                if sel == 'all':
                    direct_children = [cat['id'] for cat in all_cats if cat.get('parent_id') == parent_id]
                    structure_ids.update(direct_children)
                    product_ids.update(direct_children)
                elif sel == 'allz':
                    product_ids.add(parent_id)
                elif sel == 'all-allz':
                    product_ids.add(parent_id)
                    descendants = get_all_descendants(parent_id, all_cats_map)
                    structure_ids.update(descendants)
                    product_ids.update(descendants)
                else:
                    match = re.match(r'^(\d+)-(.+)$', sel)
                    if not match:
                        logger_instance.warning(f"âš ï¸ ÙØ±Ù…Øª Ø§Ù†ØªØ®Ø§Ø¨ '{sel}' Ø¯Ø± Ù‚Ø§Ù†ÙˆÙ† '{rule}' Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
                        continue
                    child_id, command = int(match.group(1)), match.group(2)
                    if child_id not in all_cats_map:
                        logger_instance.warning(f"âš ï¸ Ø´Ù†Ø§Ø³Ù‡ ÙØ±Ø²Ù†Ø¯ {child_id} Ø¯Ø± Ù‚Ø§Ù†ÙˆÙ† '{rule}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                        continue
                    structure_ids.add(child_id)
                    if command == 'allz': product_ids.add(child_id)
                    elif command == 'all-allz':
                        product_ids.add(child_id)
                        descendants = get_all_descendants(child_id, all_cats_map)
                        structure_ids.update(descendants)
                        product_ids.update(descendants)
        except Exception as e:
            logger_instance.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‚Ø§Ù†ÙˆÙ† '{rule}': {e}")
    return list(structure_ids), list(product_ids)

# ==============================================================================
# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ ---
# ==============================================================================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
file_handler = RotatingFileHandler('app.log', maxBytes=2*1024*1024, backupCount=5, encoding='utf-8')
file_handler.setLevel(logging.DEBUG)
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
if not any(isinstance(h, RotatingFileHandler) for h in logger.handlers):
    logger.addHandler(file_handler)

BASE_URL = "https://panel.eways.co"
SOURCE_CATS_API_URL = f"{BASE_URL}/Store/GetCategories"
PRODUCT_LIST_URL_TEMPLATE = f"{BASE_URL}/Store/List/{{category_id}}/2/2/0/0/0/10000000000?page={{page}}"
PRODUCT_DETAIL_URL_TEMPLATE = f"{BASE_URL}/Store/Detail/{{cat_id}}/{{product_id}}"
WC_API_URL = os.environ.get("WC_API_URL") or "https://your-woocommerce-site.com/wp-json/wc/v3"
WC_CONSUMER_KEY = os.environ.get("WC_CONSUMER_KEY") or "ck_xxx"
WC_CONSUMER_SECRET = os.environ.get("WC_CONSUMER_SECRET") or "cs_xxx"
EWAYS_USERNAME = os.environ.get("EWAYS_USERNAME") or "Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„ ÛŒØ§ ÛŒÙˆØ²Ø±Ù†ÛŒÙ…"
EWAYS_PASSWORD = os.environ.get("EWAYS_PASSWORD") or "Ù¾Ø³ÙˆØ±Ø¯"
CACHE_FILE = 'products_cache.json'
requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ ---
# ==============================================================================
def login_eways(username, password):
    session = requests.Session()
    session.headers.update({'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'})
    session.verify = False
    login_url = f"{BASE_URL}/User/Login"
    payload = {"UserName": username, "Password": password, "RememberMe": "true"}
    logger.info("â³ Ø¯Ø± Ø­Ø§Ù„ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ Ù¾Ù†Ù„ eways ...")
    try:
        resp = session.post(login_url, data=payload, timeout=30)
        resp.raise_for_status()
        if 'Aut' in session.cookies:
            logger.info("âœ… Ù„Ø§Ú¯ÛŒÙ† Ù…ÙˆÙÙ‚!")
            return session
        logger.error("âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø§Ú¯ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚ ÛŒØ§ Ú©Ù¾Ú†Ø§ ÙØ¹Ø§Ù„ Ø§Ø³Øª.")
        return None
    except requests.RequestException as e:
        logger.error(f"âŒ Ù„Ø§Ú¯ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚! Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡: {e}")
        return None

def get_and_parse_categories(session):
    logger.info("â³ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§...")
    try:
        response = session.get(SOURCE_CATS_API_URL, timeout=30)
        response.raise_for_status()
        try:
            data = response.json()
            final_cats = []
            for c in data:
                real_id_match = re.search(r'/Store/List/(\d+)', c.get('url', ''))
                real_id = int(real_id_match.group(1)) if real_id_match else c.get('id')
                final_cats.append({"id": real_id, "name": c.get('name', '').strip(), "parent_id": c.get('parent_id')})
            logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø² JSON Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
            return final_cats
        except json.JSONDecodeError:
            logger.warning("âš ï¸ Ù¾Ø§Ø³Ø® JSON Ù†Ø¨ÙˆØ¯. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø³ HTML...")
        soup = BeautifulSoup(response.text, 'lxml')
        all_menu_items = soup.select("li[id^='menu-item-']")
        if not all_menu_items:
            logger.error("âŒ Ù‡ÛŒÚ† Ø¢ÛŒØªÙ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø± HTML Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            return []
        cats_map = {}
        for item in all_menu_items:
            cat_id_raw = item.get('id', ''); match = re.search(r'(\d+)', cat_id_raw)
            if not match: continue
            cat_menu_id = int(match.group(1))
            a_tag = item.find('a', recursive=False) or item.select_one("a")
            if not a_tag or not a_tag.get('href'): continue
            name = a_tag.text.strip()
            real_id_match = re.search(r'/Store/List/(\d+)', a_tag['href'])
            real_id = int(real_id_match.group(1)) if real_id_match else None
            if name and real_id and name != "#":
                cats_map[cat_menu_id] = {"id": real_id, "name": name, "parent_id": None}
        for item in all_menu_items:
            cat_id_raw = item.get('id', ''); match = re.search(r'(\d+)', cat_id_raw)
            if not match: continue
            cat_menu_id = int(match.group(1))
            parent_li = item.find_parent("li", class_="menu-item-has-children")
            if parent_li:
                parent_id_raw = parent_li.get('id', ''); parent_match = re.search(r'(\d+)', parent_id_raw)
                if parent_match:
                    parent_menu_id = int(parent_match.group(1))
                    if cat_menu_id in cats_map and parent_menu_id in cats_map:
                        cats_map[cat_menu_id]['parent_id'] = cats_map[parent_menu_id]['id']
        final_cats = list(cats_map.values())
        logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ø² HTML Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
        return final_cats
    except requests.RequestException as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None

def check_wc_connection():
    logger.info("â³ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
    try:
        res = requests.get(WC_API_URL, auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), verify=False, timeout=15)
        if res.status_code == 401:
            logger.error("âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ù†Ø§Ù…ÙˆÙÙ‚: Ø®Ø·Ø§ÛŒ 401 Unauthorized. Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
            return False
        res.raise_for_status()
        logger.info("âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² Ø§Ø³Øª.")
        return True
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ù†Ø§Ù…ÙˆÙÙ‚: Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡. Ù„Ø·ÙØ§Ù‹ Ø¢Ø¯Ø±Ø³ API ({WC_API_URL}) Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯. Ø®Ø·Ø§: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø¨Ø±Ø±Ø³ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³: {e}")
        return False

def transfer_categories_to_wc(source_categories, all_cats_from_source):
    logger.info(f"\nâ³ Ø´Ø±ÙˆØ¹ Ø§Ù†ØªÙ‚Ø§Ù„ {len(source_categories)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
    source_cat_map = {cat['id']: cat for cat in all_cats_from_source}
    source_to_wc_id_map = {}
    def get_depth(cat_id):
        depth = 0
        current_id = cat_id
        while current_id and source_cat_map.get(current_id, {}).get('parent_id'):
            depth += 1
            current_id = source_cat_map.get(current_id, {}).get('parent_id')
        return depth
    sorted_cats = sorted(source_categories, key=lambda c: get_depth(c['id']))
    for cat in tqdm(sorted_cats, desc="Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§"):
        name = cat["name"].strip()
        source_parent_id = cat.get("parent_id")
        wc_parent_id = source_to_wc_id_map.get(source_parent_id, 0)
        logger.debug(f"  - Ù¾Ø±Ø¯Ø§Ø²Ø´ '{name}' (Source ID: {cat['id']}). ÙˆØ§Ù„Ø¯ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ø± WC: {wc_parent_id}")
        try:
            params = {"search": name, "parent": wc_parent_id, "per_page": 100}
            res_check = requests.get(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), params=params, verify=False, timeout=20)
            res_check.raise_for_status()
            existing_cats = res_check.json()
            exact_match = next((wc_cat for wc_cat in existing_cats if wc_cat['name'].strip() == name and wc_cat['parent'] == wc_parent_id), None)
            if exact_match:
                source_to_wc_id_map[cat["id"]] = exact_match["id"]
                logger.debug(f"    -> Ø¯Ø³ØªÙ‡ '{name}' Ø¨Ø§ ÙˆØ§Ù„Ø¯ ØµØ­ÛŒØ­ ({wc_parent_id}) Ø§Ø² Ù‚Ø¨Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯. WC ID: {exact_match['id']}")
                continue
            logger.debug(f"    -> Ø¯Ø³ØªÙ‡ '{name}' Ø¨Ø§ ÙˆØ§Ù„Ø¯ {wc_parent_id} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª...")
            data = {"name": name, "parent": wc_parent_id}
            res_create = requests.post(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), json=data, verify=False, timeout=20)
            if res_create.status_code in [200, 201]:
                new_id = res_create.json()["id"]
                source_to_wc_id_map[cat["id"]] = new_id
                logger.debug(f"    -> âœ… Ø¯Ø³ØªÙ‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯. WC ID Ø¬Ø¯ÛŒØ¯: {new_id}")
            else:
                error_data = res_create.json()
                if error_data.get("code") == "term_exists" and error_data.get("data", {}).get("resource_id"):
                    existing_id = error_data["data"]["resource_id"]
                    source_to_wc_id_map[cat["id"]] = existing_id
                    logger.warning(f"    -> Ø¯Ø³ØªÙ‡ '{name}' Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ 'term_exists' Ø¨Ø§ ID Ù…ÙˆØ¬ÙˆØ¯ {existing_id} Ù…Ù¾ Ø´Ø¯.")
                else:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ø¯Ø³ØªÙ‡ '{name}' Ø¨Ø§ ÙˆØ§Ù„Ø¯ {wc_parent_id}: {res_create.text}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ø­ÛŒÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡ '{name}': {e}")
            return None
    logger.info(f"âœ… Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù†Ú¯Ø§Ø´Øªâ€ŒØ´Ø¯Ù‡: {len(source_to_wc_id_map)}")
    return source_to_wc_id_map

@retry(
    retry=retry_if_exception_type(requests.exceptions.RequestException),
    stop=stop_after_attempt(5),
    wait=wait_random_exponential(multiplier=1, max_value=5),
    reraise=True
)
def get_product_details(session, cat_id, product_id):
    url = PRODUCT_DETAIL_URL_TEMPLATE.format(cat_id=cat_id, product_id=product_id)
    try:
        response = session.get(url, timeout=60)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        specs_table = soup.select_one('#link1 .table-responsive table') or soup.select_one('.table-responsive table') or soup.find('table', class_='table')
        if not specs_table:
            return {}
        specs = {}
        for row in specs_table.find_all("tr"):
            cells = row.find_all("td")
            if len(cells) == 2:
                key = cells[0].text.strip()
                value = cells[1].text.strip()
                if key and value:
                    specs[key] = value
        return specs
    except requests.exceptions.RequestException as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}. ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...")
        raise
    except Exception as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}")
        return {}

def get_products_from_category_page(session, category_id, max_pages=100):
    all_products = []
    seen_product_ids = set()
    page_num = 1
    while page_num <= max_pages:
        url = PRODUCT_LIST_URL_TEMPLATE.format(category_id=category_id, page=page_num)
        logger.info(f"  - Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯Ø³ØªÙ‡ {category_id}ØŒ ØµÙØ­Ù‡ {page_num}...")
        try:
            response = session.get(url, timeout=30)
            if response.status_code != 200:
                break
            soup = BeautifulSoup(response.text, 'lxml')
            product_blocks = soup.select(".goods_item.goods-record")
            if not product_blocks:
                break
            page_has_new = False
            for block in product_blocks:
                try:
                    if block.select_one(".goods-record-unavailable"):
                        continue
                    a_tag = block.select_one("a")
                    href = a_tag['href'] if a_tag else None
                    match = re.search(r'/Store/Detail/\d+/(\d+)', href) if href else None
                    product_id = match.group(1) if match else None
                    if not product_id or product_id in seen_product_ids:
                        continue
                    page_has_new = True
                    seen_product_ids.add(product_id)
                    name = block.select_one("span.goods-record-title").text.strip()
                    price = re.sub(r'[^\d]', '', block.select_one("span.goods-record-price").text)
                    image_url = block.select_one("img.goods-record-image").get('data-src', '')
                    if not all([name, price, int(price) > 0]):
                        continue
                    specs = get_product_details(session, category_id, product_id)
                    time.sleep(random.uniform(0.3, 0.8))
                    product = {"id": product_id, "name": name, "price": price, "stock": 1, "image": image_url, "category_id": category_id, "specs": specs}
                    all_products.append(product)
                except Exception as e:
                    logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© Ø¨Ù„Ø§Ú© Ù…Ø­ØµÙˆÙ„: {e}")
            if not page_has_new:
                break
            page_num += 1
            time.sleep(random.uniform(0.5, 1.5))
        except requests.RequestException as e:
            logger.error(f"    - Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙØ­Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª: {e}")
            break
    return all_products

def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}
    return {}

def save_cache(products):
    try:
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(products, f, ensure_ascii=False, indent=4)
    except IOError as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ú©Ø´: {e}")

@retry(retry=retry_if_exception_type((requests.exceptions.RequestException, requests.exceptions.HTTPError)), stop=stop_after_attempt(3), wait=wait_random_exponential(multiplier=1, max=10), reraise=True)
def _send_to_woocommerce(sku, data, stats):
    try:
        auth = (WC_CONSUMER_KEY, WC_CONSUMER_SECRET)
        check_url = f"{WC_API_URL}/products?sku={sku}"
        r_check = requests.get(check_url, auth=auth, verify=False, timeout=20)
        r_check.raise_for_status()
        existing = r_check.json()
        if existing:
            product_id = existing[0]['id']
            update_data = {
                "regular_price": data["regular_price"],
                "stock_quantity": data["stock_quantity"],
                "stock_status": data["stock_status"],
                "attributes": data["attributes"]
            }
            res = requests.put(f"{WC_API_URL}/products/{product_id}", auth=auth, json=update_data, verify=False, timeout=30)
            res.raise_for_status()
            with stats['lock']:
                stats['updated'] += 1
        else:
            res = requests.post(f"{WC_API_URL}/products", auth=auth, json=data, verify=False, timeout=30)
            res.raise_for_status()
            with stats['lock']:
                stats['created'] += 1
    except requests.exceptions.HTTPError as e:
        logger.error(f"   âŒ HTTP Ø®Ø·Ø§ Ø¨Ø±Ø§ÛŒ SKU {sku}: {e.response.status_code} - Response: {e.response.text}")
        raise
    except Exception as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø±Ø§ÛŒ SKU {sku}: {e}")
        raise

def process_product_wrapper(args):
    product, stats, category_mapping = args
    try:
        wc_cat_id = category_mapping.get(product.get('category_id'))
        if not wc_cat_id:
            return
        attributes = [{"name": k, "options": [v], "position": i, "visible": True, "variation": False} for i, (k, v) in enumerate(product.get('specs', {}).items())]
        wc_data = {
            "name": product.get('name', 'Ø¨Ø¯ÙˆÙ† Ù†Ø§Ù…'),
            "type": "simple",
            "sku": f"EWAYS-{product.get('id')}",
            "regular_price": process_price(product.get('price', 0)),
            "categories": [{"id": wc_cat_id}],
            "images": [{"src": product.get("image")}] if product.get("image") else [],
            "stock_quantity": product.get('stock', 0),
            "manage_stock": True,
            "stock_status": "instock" if product.get('stock', 0) > 0 else "outofstock",
            "attributes": attributes
        }
        _send_to_woocommerce(wc_data['sku'], wc_data, stats)
        time.sleep(random.uniform(0.5, 1.5))
    except Exception as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØµÙˆÙ„ {product.get('id', '')}: {e}")
        with stats['lock']:
            stats['failed'] += 1

def process_price(price_value):
    try:
        price_value = float(re.sub(r'[^\d.]', '', str(price_value))) / 10
    except (ValueError, TypeError):
        return "0"
    if price_value <= 7000000:
        new_price = price_value + 260000
    elif price_value <= 10000000:
        new_price = price_value * 1.035
    elif price_value <= 20000000:
        new_price = price_value * 1.025
    elif price_value <= 30000000:
        new_price = price_value * 1.02
    else:
        new_price = price_value * 1.015
    return str(int(round(new_price, -4)))

# ==============================================================================
# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ---
# ==============================================================================
def main():
    session = login_eways(EWAYS_USERNAME, EWAYS_PASSWORD)
    if not session:
        return

    all_cats = get_and_parse_categories(session)
    if not all_cats:
        return
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Û±: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯: {len(all_cats)}")

    if not check_wc_connection():
        logger.error("Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø¹Ø¯Ù… Ø§Ù…Ú©Ø§Ù† Ø§ØªØµØ§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø®Ø§ØªÙ…Ù‡ ÛŒØ§ÙØª.")
        return

    SELECTED_IDS_STRING = "1582:14548-allz,1584-all-allz|16777:all-allz|4882:all-allz|16778:22570-all-allz"
    structure_cat_ids, product_cat_ids = process_selection_rules(SELECTED_IDS_STRING, all_cats, logger)
    
    cat_name_map = {cat['id']: cat['name'] for cat in all_cats}
    structure_cat_names = [cat_name_map.get(cat_id, f'ID Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡:{cat_id}') for cat_id in sorted(list(structure_cat_ids))]
    product_cat_names = [cat_name_map.get(cat_id, f'ID Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡:{cat_id}') for cat_id in sorted(list(product_cat_ids))]
    
    logger.info(f"âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„: {structure_cat_names}")
    logger.info(f"âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬: {product_cat_names}")

    cats_for_wc_transfer = [cat for cat in all_cats if cat['id'] in structure_cat_ids]
    category_mapping = transfer_categories_to_wc(cats_for_wc_transfer, all_cats)
    if not category_mapping:
        logger.error("âŒ Ù†Ú¯Ø§Ø´Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
        return
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Û²: Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ú©Ø§Ù…Ù„ Ø´Ø¯.")

    cached_products = load_cache()
    all_products = {}
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª...")
    for cat_id in tqdm(product_cat_ids, desc="Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª"):
        products_in_cat = get_products_from_category_page(session, cat_id)
        for product in products_in_cat:
            all_products[product['id']] = product
    
    new_products_list = list(all_products.values())
    logger.info(f"\nâœ… Ù…Ø±Ø­Ù„Ù‡ Û³: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØµÙˆÙ„Ø§Øª Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯: {len(new_products_list)}")

    products_to_send = []
    updated_cache_data = {}
    for p in new_products_list:
        pid = str(p['id'])
        cached_p = cached_products.get(pid)
        if not cached_p or cached_p.get('price') != p.get('price') or cached_p.get('specs') != p.get('specs'):
            products_to_send.append(p)
        updated_cache_data[pid] = p
        
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Û´: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ú©Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯. Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯/ØªØºÛŒÛŒØ±Ú©Ø±Ø¯Ù‡: {len(products_to_send)}")
    save_cache(updated_cache_data)

    if not products_to_send:
        logger.info("ğŸ‰ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ ÛŒØ§ ØªØºÛŒÛŒØ±Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯!")
        return

    stats = {'created': 0, 'updated': 0, 'failed': 0, 'lock': Lock()}
    logger.info(f"\nğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø±Ø³Ø§Ù„ {len(products_to_send)} Ù…Ø­ØµÙˆÙ„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
    with ThreadPoolExecutor(max_workers=3) as executor:
        args_list = [(p, stats, category_mapping) for p in products_to_send]
        list(tqdm(executor.map(process_product_wrapper, args_list), total=len(products_to_send), desc="Ø§Ø±Ø³Ø§Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª"))

    logger.info("\n===============================")
    logger.info("ğŸ“¦ Ø®Ù„Ø§ØµÙ‡ Ø¹Ù…Ù„ÛŒØ§Øª:")
    logger.info(f"ğŸŸ¢ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: {stats['created']}")
    logger.info(f"ğŸ”µ Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯Ù‡: {stats['updated']}")
    logger.info(f"ğŸ”´ Ø´Ú©Ø³Øªâ€ŒØ®ÙˆØ±Ø¯Ù‡: {stats['failed']}")
    logger.info("===============================")

if __name__ == "__main__":
    main()
