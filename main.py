import requests
import os
import re
import time
import json
import random
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
from bs4 import BeautifulSoup
from threading import Lock
import logging
from logging.handlers import RotatingFileHandler
from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø§Ù†ØªØ®Ø§Ø¨ ---
# Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ø§Ù…Ù„ Ù…Ù†Ø·Ù‚ Ø§Ù†ØªØ®Ø§Ø¨ Ù‚Ø¨Ù„ÛŒ Ø´Ù…Ø§ Ø´Ø¯Ù‡ Ø§Ø³Øª.
# ==============================================================================

def get_all_descendants(parent_id, all_cats_map):
    """ØªÙ…Ø§Ù… Ù†ÙˆØ§Ø¯Ú¯Ø§Ù† (Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ…Ø§Ù… Ø³Ø·ÙˆØ­) ÛŒÚ© Ø¯Ø³ØªÙ‡ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    descendants = set()
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙØ±Ø²Ù†Ø¯Ø§Ù† Ù…Ø³ØªÙ‚ÛŒÙ…
    children = [cat['id'] for cat in all_cats_map.values() if cat.get('parent_id') == parent_id]
    for child_id in children:
        descendants.add(child_id)
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†ÙˆØ§Ø¯Ú¯Ø§Ù† Ù‡Ø± ÙØ±Ø²Ù†Ø¯
        descendants.update(get_all_descendants(child_id, all_cats_map))
    return descendants

def process_selection_rules(rule_string, all_cats):
    """
    Ø±Ø´ØªÙ‡ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ùˆ Ù„ÛŒØ³Øª ID Ù…Ø¬Ø²Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯:
    1. structure_ids: ØªÙ…Ø§Ù… IDÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø±Ø®ØªÛŒ Ø¯Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ù„Ø§Ø²Ù…Ù†Ø¯.
    2. product_ids: ØªÙ…Ø§Ù… IDÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ù…Ø­ØµÙˆÙ„Ø§ØªØ´Ø§Ù† Ø§Ø² Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´ÙˆÙ†Ø¯.
    """
    structure_ids = set()
    product_ids = set()

    # Ø³Ø§Ø®Øª ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø§Ø² Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ø§ ID
    all_cats_map = {cat['id']: cat for cat in all_cats}

    for rule in rule_string.split('|'):
        rule = rule.strip()
        if not rule or ':' not in rule:
            continue

        try:
            parent_id_str, selections_str = rule.split(':', 1)
            parent_id = int(parent_id_str.strip())

            if parent_id not in all_cats_map:
                logger.warning(f"âš ï¸ Ø´Ù†Ø§Ø³Ù‡ ÙˆØ§Ù„Ø¯ {parent_id} Ø¯Ø± Ù‚Ø§Ù†ÙˆÙ† '{rule}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø±Ø¯ Ø´Ø¯Ù†...")
                continue
            
            # Ø¯Ø³ØªÙ‡ ÙˆØ§Ù„Ø¯ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø³Ø§Ø®ØªØ§Ø± Ù„Ø§Ø²Ù… Ø§Ø³Øª
            structure_ids.add(parent_id)

            for sel in selections_str.split(','):
                sel = sel.strip()
                if not sel: continue

                # Ø­Ø§Ù„Øª Û±: Ù‚ÙˆØ§Ù†ÛŒÙ† Ø±ÙˆÛŒ Ø®ÙˆØ¯ Ø¯Ø³ØªÙ‡ ÙˆØ§Ù„Ø¯ Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ (all, allz, all-allz)
                if sel == 'all': # ØªÙ…Ø§Ù… Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… (Ø³Ø§Ø®ØªØ§Ø±) Ùˆ Ù…Ø­ØµÙˆÙ„Ø§ØªØ´Ø§Ù† (Ù…Ø­ØµÙˆÙ„)
                    direct_children = [cat['id'] for cat in all_cats if cat.get('parent_id') == parent_id]
                    structure_ids.update(direct_children)
                    product_ids.update(direct_children)

                elif sel == 'allz': # ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª Ø®ÙˆØ¯ Ø¯Ø³ØªÙ‡ ÙˆØ§Ù„Ø¯
                    product_ids.add(parent_id)

                elif sel == 'all-allz': # Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆØ§Ù„Ø¯ + ØªÙ…Ø§Ù… Ù†ÙˆØ§Ø¯Ú¯Ø§Ù† Ùˆ Ù…Ø­ØµÙˆÙ„Ø§ØªØ´Ø§Ù†
                    product_ids.add(parent_id)
                    descendants = get_all_descendants(parent_id, all_cats_map)
                    structure_ids.update(descendants)
                    product_ids.update(descendants)
                
                # Ø­Ø§Ù„Øª Û²: Ù‚ÙˆØ§Ù†ÛŒÙ† Ø±ÙˆÛŒ ÛŒÚ© Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø®Ø§Øµ Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ (Ù…Ø«Ù„Ø§: 14548-allz)
                else:
                    match = re.match(r'^(\d+)-(.+)$', sel)
                    if not match:
                        logger.warning(f"âš ï¸ ÙØ±Ù…Øª Ø§Ù†ØªØ®Ø§Ø¨ '{sel}' Ø¯Ø± Ù‚Ø§Ù†ÙˆÙ† '{rule}' Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
                        continue
                    
                    child_id, command = int(match.group(1)), match.group(2)

                    if child_id not in all_cats_map:
                        logger.warning(f"âš ï¸ Ø´Ù†Ø§Ø³Ù‡ ÙØ±Ø²Ù†Ø¯ {child_id} Ø¯Ø± Ù‚Ø§Ù†ÙˆÙ† '{rule}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                        continue

                    # ÙØ±Ø²Ù†Ø¯ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø³Ø§Ø®ØªØ§Ø± Ù„Ø§Ø²Ù… Ø§Ø³Øª
                    structure_ids.add(child_id)

                    if command == 'allz': # ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÛŒÙ† ÙØ±Ø²Ù†Ø¯
                        product_ids.add(child_id)
                    
                    elif command == 'all-allz': # Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÛŒÙ† ÙØ±Ø²Ù†Ø¯ + ØªÙ…Ø§Ù… Ù†ÙˆØ§Ø¯Ú¯Ø§Ù† Ùˆ Ù…Ø­ØµÙˆÙ„Ø§ØªØ´Ø§Ù†
                        product_ids.add(child_id)
                        descendants = get_all_descendants(child_id, all_cats_map)
                        structure_ids.update(descendants)
                        product_ids.update(descendants)
                    else:
                        logger.warning(f"âš ï¸ Ø¯Ø³ØªÙˆØ± '{command}' Ø¨Ø±Ø§ÛŒ ÙØ±Ø²Ù†Ø¯ {child_id} Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‚Ø§Ù†ÙˆÙ† '{rule}': {e}")


    return list(structure_ids), list(product_ids)

# ==============================================================================
# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯ ---
# ==============================================================================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # Ø³Ø·Ø­ Ù„Ø§Ú¯ Ø¨Ù‡ INFO ØªØºÛŒÛŒØ± Ú©Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ ØªÙ…ÛŒØ²ØªØ±
logger = logging.getLogger(__name__)
handler = RotatingFileHandler('app.log', maxBytes=1024*1024, backupCount=5, encoding='utf-8')
handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)

# ==============================================================================
# --- Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ùˆ Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ ---
# ==============================================================================
BASE_URL = "https://panel.eways.co"
SOURCE_CATS_API_URL = f"{BASE_URL}/Store/GetCategories"
PRODUCT_LIST_URL_TEMPLATE = f"{BASE_URL}/Store/List/{{category_id}}/2/2/0/0/0/10000000000?page={{page}}"
PRODUCT_DETAIL_URL_TEMPLATE = f"{BASE_URL}/Store/Detail/{{cat_id}}/{{product_id}}"

WC_API_URL = os.environ.get("WC_API_URL") or "https://your-woocommerce-site.com/wp-json/wc/v3"
WC_CONSUMER_KEY = os.environ.get("WC_CONSUMER_KEY") or "ck_xxx"
WC_CONSUMER_SECRET = os.environ.get("WC_CONSUMER_SECRET") or "cs_xxx"

EWAYS_USERNAME = os.environ.get("EWAYS_USERNAME") or "Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„ ÛŒØ§ ÛŒÙˆØ²Ø±Ù†ÛŒÙ…"
EWAYS_PASSWORD = os.environ.get("EWAYS_PASSWORD") or "Ù¾Ø³ÙˆØ±Ø¯"

CACHE_FILE = 'products_cache.json'  # ÙØ§ÛŒÙ„ Ú©Ø´

# ==============================================================================
# --- ØªØ§Ø¨Ø¹ Ù„Ø§Ú¯ÛŒÙ† Ø§ØªÙˆÙ…Ø§ØªÛŒÚ© Ø¨Ù‡ eways ---
# ==============================================================================
def login_eways(username, password):
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': f"{BASE_URL}/",
        'X-Requested-With': 'XMLHttpRequest',
        'Accept-Language': 'en-US,en;q=0.9,fa;q=0.8'
    })
    session.verify = False

    login_url = f"{BASE_URL}/User/Login"
    payload = {
        "UserName": username,
        "Password": password,
        "RememberMe": "true"
    }
    logger.info("â³ Ø¯Ø± Ø­Ø§Ù„ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ Ù¾Ù†Ù„ eways ...")
    resp = session.post(login_url, data=payload, timeout=30)
    if resp.status_code != 200:
        logger.error(f"âŒ Ù„Ø§Ú¯ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚! Ú©Ø¯ ÙˆØ¶Ø¹ÛŒØª: {resp.status_code}")
        return None

    if 'Aut' in session.cookies:
        logger.info("âœ… Ù„Ø§Ú¯ÛŒÙ† Ù…ÙˆÙÙ‚! Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
        return session
    else:
        logger.error("âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø§Ú¯ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚ ÛŒØ§ Ú©Ù¾Ú†Ø§ ÙØ¹Ø§Ù„ Ø§Ø³Øª.")
        return None

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ (eways) ---
# ==============================================================================
def get_and_parse_categories(session):
    logger.info(f"â³ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø²: {SOURCE_CATS_API_URL}")
    try:
        response = session.get(SOURCE_CATS_API_URL, timeout=30)
        response.raise_for_status()
        try:
            data = response.json()
            logger.info("âœ… Ù¾Ø§Ø³Ø® JSON Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")
            final_cats = []
            for c in data:
                real_id_match = re.search(r'/Store/List/(\d+)', c.get('url', ''))
                real_id = int(real_id_match.group(1)) if real_id_match else c.get('id')
                final_cats.append({
                    "id": real_id,
                    "name": c.get('name', '').strip(),
                    "parent_id": c.get('parent_id')
                })
            logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø² JSON Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
            return final_cats
        except json.JSONDecodeError:
            logger.warning("âš ï¸ Ù¾Ø§Ø³Ø® JSON Ù†ÛŒØ³Øª. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø³ HTML...")

        soup = BeautifulSoup(response.text, 'lxml')
        all_menu_items = soup.select("li[id^='menu-item-']")
        if not all_menu_items:
            logger.error("âŒ Ù‡ÛŒÚ† Ø¢ÛŒØªÙ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø± HTML Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            return []
        logger.info(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ {len(all_menu_items)} Ø¢ÛŒØªÙ… Ù…Ù†Ùˆ Ù¾ÛŒØ¯Ø§ Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")

        cats_map = {}
        for item in all_menu_items:
            cat_id_raw = item.get('id', '')
            match = re.search(r'(\d+)', cat_id_raw)
            if not match: continue
            cat_menu_id = int(match.group(1))
            a_tag = item.find('a', recursive=False) or item.select_one("a")
            if not a_tag or not a_tag.get('href'): continue
            name = a_tag.text.strip()
            real_id_match = re.search(r'/Store/List/(\d+)', a_tag['href'])
            real_id = int(real_id_match.group(1)) if real_id_match else None
            if name and real_id and name != "#":
                cats_map[cat_menu_id] = {"id": real_id, "name": name, "parent_id": None}
        for item in all_menu_items:
            cat_id_raw = item.get('id', '')
            match = re.search(r'(\d+)', cat_id_raw)
            if not match: continue
            cat_menu_id = int(match.group(1))
            parent_li = item.find_parent("li", class_="menu-item-has-children")
            if parent_li:
                parent_id_raw = parent_li.get('id', '')
                parent_match = re.search(r'(\d+)', parent_id_raw)
                if parent_match:
                    parent_menu_id = int(parent_match.group(1))
                    if cat_menu_id in cats_map and parent_menu_id in cats_map:
                        cats_map[cat_menu_id]['parent_id'] = cats_map[parent_menu_id]['id']
        final_cats = list(cats_map.values())
        logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
        return final_cats
    except requests.RequestException as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None

@retry(
    retry=retry_if_exception_type(requests.exceptions.RequestException),
    stop=stop_after_attempt(5),
    wait=wait_random_exponential(multiplier=1, max=5),
    reraise=True
)
def get_product_details(session, cat_id, product_id):
    url = PRODUCT_DETAIL_URL_TEMPLATE.format(cat_id=cat_id, product_id=product_id)
    try:
        response = session.get(url, timeout=60)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        
        specs_table = soup.select_one('#link1 .table-responsive table')
        if not specs_table:
            specs_table = soup.select_one('.table-responsive table')
            if not specs_table:
                specs_table = soup.find('table', class_='table')
                if not specs_table:
                    logger.debug(f"      - Ù‡ÛŒÚ† Ø¬Ø¯ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {product_id} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
                    return {}

        specs = {}
        rows = specs_table.find_all("tr")
        for row in rows:
            cells = row.find_all("td")
            if len(cells) == 2:
                key = cells[0].text.strip()
                value = cells[1].text.strip()
                if key and value:
                    specs[key] = value
        
        logger.debug(f"      - Ù…Ø´Ø®ØµØ§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {product_id}: {specs}")
        return specs
    except requests.exceptions.RequestException as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}. ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...")
        raise
    except Exception as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}")
        return {}

def get_products_from_category_page(session, category_id, max_pages=100):
    all_products_in_category = []
    seen_product_ids = set()
    page_num = 1
    while page_num <= max_pages:
        url = PRODUCT_LIST_URL_TEMPLATE.format(category_id=category_id, page=page_num)
        logger.info(f"  - Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø²: {url}")
        try:
            response = session.get(url, timeout=30)
            if response.status_code != 200: break
            soup = BeautifulSoup(response.text, 'lxml')
            product_blocks = soup.select(".goods_item.goods-record")
            if not product_blocks:
                logger.info("    - Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ÛŒ Ø¯Ø± Ø§ÛŒÙ† ØµÙØ­Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù¾Ø§ÛŒØ§Ù† ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ.")
                break
            
            current_page_product_ids = []
            for block in product_blocks:
                try:
                    if block.select_one(".goods-record-unavailable"):
                        continue

                    a_tag = block.select_one("a")
                    href = a_tag['href'] if a_tag else None
                    match = re.search(r'/Store/Detail/\d+/(\d+)', href) if href else None
                    product_id = match.group(1) if match else None
                    if not product_id or product_id in seen_product_ids or product_id.startswith('##'):
                        continue

                    name = block.select_one("span.goods-record-title").text.strip()
                    price_text = block.select_one("span.goods-record-price").text.strip()
                    price = re.sub(r'[^\d]', '', price_text)
                    image_url = block.select_one("img.goods-record-image").get('data-src', '')

                    if not all([name, price, int(price) > 0]):
                        continue

                    specs = get_product_details(session, category_id, product_id)
                    time.sleep(random.uniform(0.3, 0.8))

                    product = {
                        "id": product_id, "name": name, "price": price, "stock": 1,
                        "image": image_url, "category_id": category_id, "specs": specs
                    }
                    seen_product_ids.add(product_id)
                    current_page_product_ids.append(product_id)
                    all_products_in_category.append(product)
                    logger.info(f"      - Ù…Ø­ØµÙˆÙ„ {product_id} ({name}) Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")
                except Exception as e:
                    logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© Ø¨Ù„Ø§Ú© Ù…Ø­ØµÙˆÙ„: {e}. Ø±Ø¯ Ø´Ø¯Ù†...")
            
            if not current_page_product_ids:
                logger.info("    - Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¯Ø± Ø§ÛŒÙ† ØµÙØ­Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ ØªÙˆÙ‚Ù ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ.")
                break
            page_num += 1
            time.sleep(random.uniform(0.5, 1.5))
        except requests.RequestException as e:
            logger.error(f"    - Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙØ­Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª: {e}")
            break
        except Exception as e:
            logger.error(f"    - Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙØ­Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª: {e}")
            break
    return all_products_in_category

# ==============================================================================
# --- Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª ---
# ==============================================================================
def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                cache = json.load(f)
                logger.info(f"âœ… Ú©Ø´ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± Ú©Ø´: {len(cache)}")
                return cache
        except (json.JSONDecodeError, IOError) as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÛŒØ§ Ù¾Ø§Ø±Ø³ ÙØ§ÛŒÙ„ Ú©Ø´: {e}. ÛŒÚ© Ú©Ø´ Ø¬Ø¯ÛŒØ¯ Ø³Ø§Ø®ØªÙ‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.")
            return {}
    logger.info("âš ï¸ Ú©Ø´ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù…Ù„ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    return {}

def save_cache(products):
    try:
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(products, f, ensure_ascii=False, indent=4)
        logger.info(f"âœ… Ú©Ø´ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª: {len(products)}")
    except IOError as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ú©Ø´: {e}")


# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ ---
# ==============================================================================
def transfer_categories_to_wc(source_categories, all_cats_from_source):
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
    
    # Ø³Ø§Ø®Øª ÛŒÚ© Ù†Ù‚Ø´Ù‡ Ø§Ø² ID Ø¨Ù‡ Ø¢Ø¨Ø¬Ú©Øª Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹ ÙˆØ§Ù„Ø¯Ù‡Ø§
    source_cat_map = {cat['id']: cat for cat in all_cats_from_source}
    
    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ ÙˆØ§Ù„Ø¯Ù‡Ø§ Ù‚Ø¨Ù„ Ø§Ø² ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
    sorted_cats = sorted(source_categories, key=lambda c: (source_cat_map.get(c.get('parent_id'), {}).get('name', ''), c['name']))

    # Ù†Ù‚Ø´Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ID Ù‡Ø§ÛŒ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¯Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ (Source ID -> WC ID)
    source_to_wc_id_map = {}
    
    # tqdm Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
    for cat in tqdm(sorted_cats, desc="Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³"):
        name = cat["name"].strip()
        source_parent_id = cat.get("parent_id")
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ID ÙˆØ§Ù„Ø¯ Ø¯Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø§Ø² Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡
        wc_parent_id = source_to_wc_id_map.get(source_parent_id, 0)
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø³ØªÙ‡ Ø¨Ø§ Ù†Ø§Ù… Ùˆ ÙˆØ§Ù„Ø¯ ÛŒÚ©Ø³Ø§Ù† Ø¯Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³
        try:
            res_check = requests.get(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), 
                                     params={"search": name, "parent": wc_parent_id}, verify=False)
            res_check.raise_for_status()
            existing_cats = res_check.json()
            
            exact_match = next((wc_cat for wc_cat in existing_cats if wc_cat['name'].strip() == name and wc_cat['parent'] == wc_parent_id), None)
            
            if exact_match:
                source_to_wc_id_map[cat["id"]] = exact_match["id"]
                continue # Ø¯Ø³ØªÙ‡ Ø§Ø² Ù‚Ø¨Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø¨Ù‡ Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±Ùˆ
        except Exception as e:
            logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø³ØªÙ‡ '{name}': {e}")

        # Ø³Ø§Ø®Øª Ø¯Ø³ØªÙ‡ Ø¬Ø¯ÛŒØ¯
        data = {"name": name, "parent": wc_parent_id}
        try:
            res = requests.post(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), json=data, verify=False)
            if res.status_code in [200, 201]:
                new_id = res.json()["id"]
                source_to_wc_id_map[cat["id"]] = new_id
            else:
                error_data = res.json()
                if error_data.get("code") == "term_exists" and error_data.get("data", {}).get("resource_id"):
                    existing_id = error_data["data"]["resource_id"]
                    source_to_wc_id_map[cat["id"]] = existing_id
                else:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ø¯Ø³ØªÙ‡ '{name}': {res.text}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ø³Ø§Ø®Øª Ø¯Ø³ØªÙ‡ '{name}': {e}")

    logger.info(f"âœ… Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù†Ú¯Ø§Ø´Øªâ€ŒØ´Ø¯Ù‡: {len(source_to_wc_id_map)}")
    return source_to_wc_id_map

def process_price(price_value):
    try:
        price_value = float(re.sub(r'[^\d.]', '', str(price_value)))
        price_value /= 10
    except (ValueError, TypeError): return "0"
    if price_value <= 1: return "0"
    elif price_value <= 7000000: new_price = price_value + 260000
    elif price_value <= 10000000: new_price = price_value * 1.035
    elif price_value <= 20000000: new_price = price_value * 1.025
    elif price_value <= 30000000: new_price = price_value * 1.02
    else: new_price = price_value * 1.015
    return str(int(round(new_price, -4)))

@retry(
    retry=retry_if_exception_type((requests.exceptions.RequestException, requests.exceptions.HTTPError)),
    stop=stop_after_attempt(3),
    wait=wait_random_exponential(multiplier=1, max=10),
    reraise=True
)
def _send_to_woocommerce(sku, data, stats):
    try:
        auth = (WC_CONSUMER_KEY, WC_CONSUMER_SECRET)
        check_url = f"{WC_API_URL}/products?sku={sku}"
        r_check = requests.get(check_url, auth=auth, verify=False, timeout=20)
        r_check.raise_for_status()
        existing = r_check.json()
        
        if existing:
            product_id = existing[0]['id']
            update_data = {
                "regular_price": data["regular_price"],
                "stock_quantity": data["stock_quantity"],
                "stock_status": data["stock_status"],
                "attributes": data["attributes"]
            }
            logger.debug(f"   - Ø¢Ù¾Ø¯ÛŒØª Ù…Ø­ØµÙˆÙ„ {product_id}...")
            res = requests.put(f"{WC_API_URL}/products/{product_id}", auth=auth, json=update_data, verify=False, timeout=30)
            res.raise_for_status()
            with stats['lock']: stats['updated'] += 1
        else:
            logger.debug(f"   - Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ SKU {sku}...")
            res = requests.post(f"{WC_API_URL}/products", auth=auth, json=data, verify=False, timeout=30)
            res.raise_for_status()
            with stats['lock']: stats['created'] += 1
    except requests.exceptions.HTTPError as e:
        logger.error(f"   âŒ HTTP Ø®Ø·Ø§ Ø¨Ø±Ø§ÛŒ SKU {sku}: {e.response.status_code} - Response: {e.response.text}")
        raise
    except Exception as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø±Ø§ÛŒ SKU {sku}: {e}")
        raise

def process_product_wrapper(args):
    product, stats, category_mapping = args
    try:
        wc_cat_id = category_mapping.get(product.get('category_id'))
        if not wc_cat_id:
            logger.warning(f"   âš ï¸ Ø¯Ø³ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {product.get('id')} Ø¯Ø± Ù†Ù‚Ø´Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø±Ø¯ Ú©Ø±Ø¯Ù†...")
            return
            
        attributes = []
        for i, (key, value) in enumerate(product.get('specs', {}).items()):
            attributes.append({"name": key, "options": [value], "position": i, "visible": True, "variation": False})
            
        wc_data = {
            "name": product.get('name', 'Ø¨Ø¯ÙˆÙ† Ù†Ø§Ù…'),
            "type": "simple",
            "sku": f"EWAYS-{product.get('id')}",
            "regular_price": process_price(product.get('price', 0)),
            "categories": [{"id": wc_cat_id}],
            "images": [{"src": product.get("image")}] if product.get("image") else [],
            "stock_quantity": product.get('stock', 0),
            "manage_stock": True,
            "stock_status": "instock" if product.get('stock', 0) > 0 else "outofstock",
            "attributes": attributes
        }
        _send_to_woocommerce(wc_data['sku'], wc_data, stats)
        time.sleep(random.uniform(0.5, 1.5))
    except Exception as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØµÙˆÙ„ {product.get('id', '')}: {e}")
        with stats['lock']: stats['failed'] += 1

# ==============================================================================
# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ---
# ==============================================================================
def main():
    session = login_eways(EWAYS_USERNAME, EWAYS_PASSWORD)
    if not session:
        return

    all_cats = get_and_parse_categories(session)
    if not all_cats:
        return
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Û±: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯: {len(all_cats)}")

    # --- ØªØ¹Ø±ÛŒÙ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø§Ù†ØªØ®Ø§Ø¨ ---
    # Ø§ÛŒÙ† Ø±Ø´ØªÙ‡ØŒ Ù‚Ù„Ø¨ ØªÙ¾Ù†Ø¯Ù‡ Ø§Ù†ØªØ®Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§Ø³Øª. Ø¢Ù† Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯.
    # ÙØ±Ù…Øª: "ID_ÙˆØ§Ù„Ø¯:ID_ÙØ±Ø²Ù†Ø¯-Ø¯Ø³ØªÙˆØ±,ID_ÙØ±Ø²Ù†Ø¯-Ø¯Ø³ØªÙˆØ±|ID_ÙˆØ§Ù„Ø¯_Ø¯ÛŒÚ¯Ø±:Ø¯Ø³ØªÙˆØ±_Ú©Ù„ÛŒ"
    # Ø¯Ø³ØªÙˆØ±Ù‡Ø§: allz (ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª), all-allz (Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ ØªÙ…Ø§Ù… Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§)
    SELECTED_IDS_STRING = "1582:14548-allz,1584-all-allz|16777:all-allz|2045:all-allz|16778:22570-all-allz"
    
    # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ú¯Ø±ÙØªÙ† Ø¯Ùˆ Ù„ÛŒØ³Øª Ù…Ø¬Ø²Ø§
    structure_cat_ids, product_cat_ids = process_selection_rules(SELECTED_IDS_STRING, all_cats)
    
    logger.info(f"âœ… IDÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³: {structure_cat_ids}")
    logger.info(f"âœ… IDÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬: {product_cat_ids}")

    # --- Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ ---
    cats_for_wc_transfer = [cat for cat in all_cats if cat['id'] in structure_cat_ids]
    category_mapping = transfer_categories_to_wc(cats_for_wc_transfer, all_cats)
    if not category_mapping:
        logger.error("âŒ Ù†Ú¯Ø§Ø´Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
        return
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Û²: Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ú©Ø§Ù…Ù„ Ø´Ø¯.")

    # --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ---
    cached_products = load_cache()
    
    all_products = {}
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ØªÙ…Ø§Ù… Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡â€ŒØ´Ø¯Ù‡...")
    for cat_id in tqdm(product_cat_ids, desc="Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª"):
        products_in_cat = get_products_from_category_page(session, cat_id)
        for product in products_in_cat:
            all_products[product['id']] = product # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø­ØµÙˆÙ„ ØªÚ©Ø±Ø§Ø±ÛŒ
    
    new_products_list = list(all_products.values())
    logger.info(f"\nâœ… Ù…Ø±Ø­Ù„Ù‡ Û³: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØµÙˆÙ„Ø§Øª Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª ÛŒÚ©ØªØ§: {len(new_products_list)}")

    # --- Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ú©Ø´ Ùˆ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ØªØºÛŒÛŒØ±Ø§Øª ---
    products_to_send = []
    updated_cache_data = {}
    for p in new_products_list:
        pid = p['id']
        cached_p = cached_products.get(pid)
        # Ø§Ú¯Ø± Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ Ø§Ø³Øª ÛŒØ§ Ù‚ÛŒÙ…ØªØŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒ ÛŒØ§ Ù…Ø´Ø®ØµØ§ØªØ´ ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†
        if not cached_p or cached_p.get('price') != p.get('price') or cached_p.get('specs') != p.get('specs'):
            products_to_send.append(p)
        updated_cache_data[pid] = p # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ø´ Ø¨Ø§ Ø¢Ø®Ø±ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª
        
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ Û´: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ú©Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª ØªØºÛŒÛŒØ±Ú©Ø±Ø¯Ù‡/Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„: {len(products_to_send)}")

    # Ø°Ø®ÛŒØ±Ù‡ Ú©Ø´ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ù‡â€ŒØ±ÙˆØ²
    save_cache(updated_cache_data)

    if not products_to_send:
        logger.info("ğŸ‰ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ ÛŒØ§ ØªØºÛŒÛŒØ±Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. Ú©Ø§Ø± ØªÙ…Ø§Ù… Ø´Ø¯!")
        return

    # --- Ø§Ø±Ø³Ø§Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ ---
    stats = {'created': 0, 'updated': 0, 'failed': 0, 'lock': Lock()}
    logger.info(f"\nğŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø§Ø±Ø³Ø§Ù„ {len(products_to_send)} Ù…Ø­ØµÙˆÙ„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
    
    with ThreadPoolExecutor(max_workers=3) as executor:
        args_list = [(p, stats, category_mapping) for p in products_to_send]
        list(tqdm(executor.map(process_product_wrapper, args_list), total=len(products_to_send), desc="Ø§Ø±Ø³Ø§Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª"))

    logger.info("\n===============================")
    logger.info(f"ğŸ“¦ Ø®Ù„Ø§ØµÙ‡ Ø¹Ù…Ù„ÛŒØ§Øª:")
    logger.info(f"ğŸŸ¢ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: {stats['created']}")
    logger.info(f"ğŸ”µ Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯Ù‡: {stats['updated']}")
    logger.info(f"ğŸ”´ Ø´Ú©Ø³Øªâ€ŒØ®ÙˆØ±Ø¯Ù‡: {stats['failed']}")
    logger.info("===============================\nØªÙ…Ø§Ù…!")

if __name__ == "__main__":
    main()
