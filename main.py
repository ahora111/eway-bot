import requests
import os
import re
import time
import json
import random
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
from bs4 import BeautifulSoup
from threading import Lock, Thread
from queue import Queue
import logging
from logging.handlers import RotatingFileHandler
from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type
from collections import defaultdict
from urllib.parse import urljoin

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ù†Ø¹Ø·Ù Ø¨Ø§ SELECTED_IDS_STRING ---
# ==============================================================================
def parse_selected_ids_string(selected_ids_string):
    result = []
    for part in selected_ids_string.split('|'):
        part = part.strip()
        if not part or ':' not in part:
            continue
        parent_id_str, children_str = part.split(':', 1)
        parent_id = int(parent_id_str.strip())
        selections = []
        for sel in children_str.split(','):
            sel = sel.strip()
            if not sel:
                continue
            if sel == 'all':
                selections.append({"id": parent_id, "type": "all_subcats"})
            elif sel == 'allz':
                selections.append({"id": parent_id, "type": "only_products"})
            elif sel == 'all-allz':
                selections.append({"id": parent_id, "type": "all_subcats_and_products"})
            elif re.match(r'^\d+-allz$', sel):
                sub_id = int(sel.split('-')[0])
                selections.append({"id": sub_id, "type": "only_products"})
            elif re.match(r'^\d+-all-allz$', sel):
                sub_id = int(sel.split('-')[0])
                selections.append({"id": sub_id, "type": "all_subcats_and_products"})
        result.append({"parent_id": parent_id, "selections": selections})
    return result

def get_direct_subcategories(parent_id, all_cats):
    return [cat['id'] for cat in all_cats if cat['parent_id'] == parent_id]

def get_all_subcategories(parent_id, all_cats):
    result = []
    direct = get_direct_subcategories(parent_id, all_cats)
    result.extend(direct)
    for sub_id in direct:
        result.extend(get_all_subcategories(sub_id, all_cats))
    return result

# Ø®Ø±ÙˆØ¬ÛŒ: (Ù„ÛŒØ³Øª Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³Ú©Ø±Ù¾ØŒ Ù„ÛŒØ³Øª Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø§ ÙˆØ§Ù„Ø¯Ù‡Ø§)
def get_selected_categories_according_to_selection(parsed_selection, all_cats):
    selected_scrape = set()    # ÙÙ‚Ø· Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ù…Ø­ØµÙˆÙ„Ø§Øªâ€ŒØ´Ø§Ù† Ø¬Ù…Ø¹ Ø´ÙˆØ¯
    selected_transfer = set()  # Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¯Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø³Ø§Ø®ØªÙ‡ Ø´ÙˆÙ†Ø¯ (Ø§Ø³Ú©Ø±Ù¾â€ŒÙ‡Ø§ + ØªÙ…Ø§Ù… ÙˆØ§Ù„Ø¯Ù‡Ø§)

    id_to_cat = {c['id']: c for c in all_cats}

    def add_ancestors(cid):
        while cid:
            if cid in selected_transfer:
                break
            selected_transfer.add(cid)
            cid = id_to_cat.get(cid, {}).get('parent_id')

    def add_all_subs(xid):
        # Ø§ÙØ²ÙˆØ¯Ù† Ù‡Ù…Ù‡â€ŒÛŒ Ø²ÛŒØ±Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ (Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ) Ø¨Ù‡ selected_scrape Ùˆ ÙˆØ§Ù„Ø¯Ù‡Ø§ Ø¨Ù‡ selected_transfer
        for c in all_cats:
            if c['parent_id'] == xid:
                selected_scrape.add(c['id'])
                add_ancestors(c['id'])
                add_all_subs(c['id'])

    for block in parsed_selection:
        parent_id = block['parent_id']
        # ÙˆØ§Ù„Ø¯ Ø±Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ù‡ Ù„ÛŒØ³Øª Ø§Ø³Ú©Ø±Ù¾ Ø§Ø¶Ø§ÙÙ‡ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        for sel in block['selections']:
            typ, sid = sel['type'], sel['id']

            if typ == 'all_subcats' and sid == parent_id:
                # ÙÙ‚Ø· Ø²ÛŒØ±Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
                subs = get_direct_subcategories(parent_id, all_cats)
                for sc_id in subs:
                    selected_scrape.add(sc_id)
                    add_ancestors(sc_id)

            elif typ == 'only_products' and sid == parent_id:
                # Ø®ÙˆØ¯ ÙˆØ§Ù„Ø¯
                selected_scrape.add(parent_id)
                add_ancestors(parent_id)

            elif typ == 'all_subcats_and_products' and sid == parent_id:
                # ÙˆØ§Ù„Ø¯ + Ù‡Ù…Ù‡ Ø²ÛŒØ±Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ÛŒØ´
                selected_scrape.add(parent_id)
                add_ancestors(parent_id)
                # ØªÙ…Ø§Ù… Ø²ÛŒØ±Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÛŒÙ‚
                for sub in get_all_subcategories(parent_id, all_cats):
                    selected_scrape.add(sub)
                    add_ancestors(sub)

            elif typ == 'only_products' and sid != parent_id:
                # ÙÙ‚Ø· Ø®ÙˆØ¯ Ø²ÛŒØ±Ø´Ø§Ø®Ù‡ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡
                selected_scrape.add(sid)
                add_ancestors(sid)

            elif typ == 'all_subcats_and_products' and sid != parent_id:
                # Ø²ÛŒØ±Ø´Ø§Ø®Ù‡ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ + Ù‡Ù…Ù‡ Ø²ÛŒØ±Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ÛŒØ´
                selected_scrape.add(sid)
                add_ancestors(sid)
                for sub in get_all_subcategories(sid, all_cats):
                    selected_scrape.add(sub)
                    add_ancestors(sub)

    scrape_categories = [cat for cat in all_cats if cat['id'] in selected_scrape]
    transfer_categories = [cat for cat in all_cats if cat['id'] in selected_transfer]
    return scrape_categories, transfer_categories

# ==============================================================================
# --- Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§: ÙˆØ§Ù„Ø¯/ÙØ±Ø²Ù†Ø¯ØŒ Ø¹Ù…Ù‚ØŒ Ø¨Ø±Ú¯â€ŒÙ‡Ø§ ---
# ==============================================================================
def build_category_index(categories):
    parent_of = {}
    children_of = defaultdict(list)
    ids = set()

    for c in categories:
        cid = c['id']
        pid = c.get('parent_id')
        ids.add(cid)
        parent_of[cid] = pid
        if pid:
            children_of[pid].append(cid)

    # Ø¹Ù…Ù‚ Ø¨Ø§ memo
    depth_memo = {}
    def depth(cid):
        if cid in depth_memo:
            return depth_memo[cid]
        p = parent_of.get(cid)
        if not p:
            depth_memo[cid] = 0
        else:
            depth_memo[cid] = 1 + depth(p)
        return depth_memo[cid]

    for cid in ids:
        depth(cid)

    leaf_ids = {cid for cid in ids if len(children_of.get(cid, [])) == 0}
    return parent_of, children_of, depth_memo, leaf_ids

def condense_products_to_leaf(all_products_by_catkey, categories):
    # all_products_by_catkey: dict with key "pid|catid" and value product dict
    parent_of, children_of, depth_of, leaf_ids = build_category_index(categories)

    # Ú¯Ø±ÙˆÙ‡Ø¨Ù†Ø¯ÛŒ Ø¨Ø±Ø­Ø³Ø¨ pid
    occurrences = defaultdict(list)
    for key, p in all_products_by_catkey.items():
        pid = str(p['id'])
        occurrences[pid].append(p)

    canonical = {}
    for pid, plist in occurrences.items():
        # Ú©Ø§Ù†Ø¯ÛŒØ¯Ù‡Ø§ÛŒ Ø¨Ø±Ú¯
        leaf_candidates = [p for p in plist if p.get('category_id') in leaf_ids]
        candidates = leaf_candidates if leaf_candidates else plist
        # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø± Ù…Ø¨Ù†Ø§ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø¹Ù…Ù‚ØŒ Ø³Ù¾Ø³ Ú©Ù…ØªØ±ÛŒÙ† id Ø¯Ø³ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø«Ø¨Ø§Øª
        candidates.sort(key=lambda p: (depth_of.get(p.get('category_id'), 0), -int(p.get('category_id', 0))), reverse=True)
        chosen = candidates[0]
        canonical[pid] = chosen
    return canonical

def normalize_cache(cached_products, categories):
    # Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú©Ø´ Ù‚Ø¯ÛŒÙ…ÛŒ (Ú©Ù„ÛŒØ¯ id|cat) Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ú©Ø´ Ø¬Ø¯ÛŒØ¯ (Ú©Ù„ÛŒØ¯ pid)
    if not cached_products:
        return {}
    # Ø§Ú¯Ø± Ú©Ù„ÛŒØ¯Ù‡Ø§ Ø´Ø§Ù…Ù„ '|' Ù‡Ø³ØªÙ†Ø¯ ÛŒØ¹Ù†ÛŒ ÙØ±Ù…Øª Ù‚Ø¯ÛŒÙ…
    if any('|' in k for k in cached_products.keys()):
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø³Ø§Ø®ØªØ§Ø± Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² condense
        all_products_by_catkey = {}
        for key, p in cached_products.items():
            # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ category_id Ø¯Ø§Ø®Ù„ Ø±Ú©ÙˆØ±Ø¯
            if 'category_id' not in p:
                try:
                    _, catid = key.split('|')
                    p['category_id'] = int(catid)
                except:
                    pass
            all_products_by_catkey[key] = p
        return condense_products_to_leaf(all_products_by_catkey, categories)
    else:
        # ÙØ±Ù…Øª Ø¬Ø¯ÛŒØ¯: Ú©Ù„ÛŒØ¯ pid Ø§Ø³Øª
        normalized = {}
        for pid, p in cached_products.items():
            if 'category_id' in p and isinstance(p['category_id'], str) and p['category_id'].isdigit():
                p['category_id'] = int(p['category_id'])
            normalized[str(pid)] = p
        return normalized

# ==============================================================================
# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯ ---
# ==============================================================================
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
handler = RotatingFileHandler('app.log', maxBytes=1024*1024, backupCount=5, encoding='utf-8')  # UTF-8
handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(handler)

# ==============================================================================
# --- Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ùˆ Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ ---
# ==============================================================================
BASE_URL = "https://panel.eways.co"
SOURCE_CATS_API_URL = f"{BASE_URL}/Store/GetCategories"
PRODUCT_LIST_URL_TEMPLATE = f"{BASE_URL}/Store/List/{{category_id}}/2/2/0/0/0/10000000000?page={{page}}"
PRODUCT_DETAIL_URL_TEMPLATE = f"{BASE_URL}/Store/Detail/{{cat_id}}/{{product_id}}"

WC_API_URL = os.environ.get("WC_API_URL") or "https://your-woocommerce-site.com/wp-json/wc/v3"
WC_CONSUMER_KEY = os.environ.get("WC_CONSUMER_KEY") or "ck_xxx"
WC_CONSUMER_SECRET = os.environ.get("WC_CONSUMER_SECRET") or "cs_xxx"

EWAYS_USERNAME = os.environ.get("EWAYS_USERNAME") or "Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„ ÛŒØ§ ÛŒÙˆØ²Ø±Ù†ÛŒÙ…"
EWAYS_PASSWORD = os.environ.get("EWAYS_PASSWORD") or "Ù¾Ø³ÙˆØ±Ø¯"

CACHE_FILE = 'products_cache.json'  # ÙØ§ÛŒÙ„ Ú©Ø´

# ==============================================================================
# --- Ú©Ù…Ú©â€ŒØªØ§Ø¨Ø¹ URL Ù…Ø·Ù„Ù‚ Ø¨Ø±Ø§ÛŒ ØªØµØ§ÙˆÛŒØ± ---
# ==============================================================================
def abs_url(u):
    if not u:
        return u
    return u if u.startswith('http') else urljoin(BASE_URL, u)

# ==============================================================================
# --- ØªØ§Ø¨Ø¹ Ù„Ø§Ú¯ÛŒÙ† Ø§ØªÙˆÙ…Ø§ØªÛŒÚ© Ø¨Ù‡ eways ---
# ==============================================================================
def login_eways(username, password):
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': f"{BASE_URL}/",
        'X-Requested-With': 'XMLHttpRequest',
        'Accept-Language': 'en-US,en;q=0.9,fa;q=0.8'
    })
    session.verify = False

    login_url = f"{BASE_URL}/User/Login"
    payload = {
        "UserName": username,
        "Password": password,
        "RememberMe": "true"
    }
    logger.info("â³ Ø¯Ø± Ø­Ø§Ù„ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ Ù¾Ù†Ù„ eways ...")
    resp = session.post(login_url, data=payload, timeout=30)
    if resp.status_code != 200:
        logger.error(f"âŒ Ù„Ø§Ú¯ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚! Ú©Ø¯ ÙˆØ¶Ø¹ÛŒØª: {resp.status_code} - Ù…ØªÙ† Ù¾Ø§Ø³Ø®: {resp.text[:200]}")
        return None

    if 'Aut' in session.cookies:
        logger.info("âœ… Ù„Ø§Ú¯ÛŒÙ† Ù…ÙˆÙÙ‚! Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
        return session
    else:
        if "Ú©Ù¾Ú†Ø§" in resp.text or "captcha" in resp.text.lower():
            logger.error("âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ú©Ù¾Ú†Ø§ ÙØ¹Ø§Ù„ Ø§Ø³Øª.")
        elif "Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ" in resp.text or "Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±" in resp.text:
            logger.error("âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ ÛŒØ§ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª.")
        else:
            logger.error("âŒ Ú©ÙˆÚ©ÛŒ Aut Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø§Ú¯ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚ ÛŒØ§ Ø¯Ù„ÛŒÙ„ Ù†Ø§Ù…Ø´Ø®Øµ.")
        return None

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø³Ø§ÛŒØª Ù…Ø¨Ø¯Ø§ (eways) ---
# ==============================================================================
@retry(
    retry=retry_if_exception_type(requests.exceptions.RequestException),
    stop=stop_after_attempt(5),
    wait=wait_random_exponential(multiplier=1, max=5),
    reraise=True
)
def get_product_details(session, cat_id, product_id):
    url = PRODUCT_DETAIL_URL_TEMPLATE.format(cat_id=cat_id, product_id=product_id)
    try:
        response = session.get(url, timeout=60)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        specs_table = soup.select_one('#link1 .table-responsive table')
        if not specs_table:
            specs_table = soup.select_one('.table-responsive table')
            if not specs_table:
                specs_table = soup.find('table', class_='table')
                if not specs_table:
                    logger.debug(f"      - Ù‡ÛŒÚ† Ø¬Ø¯ÙˆÙ„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. HTML Ø®Ø§Ù… ØµÙØ­Ù‡: {soup.prettify()[:1000]}...")
                    return {}
        specs = {}
        rows = specs_table.find_all("tr")
        for row in rows:
            cells = row.find_all("td")
            if len(cells) == 2:
                key = cells[0].text.strip()
                value = cells[1].text.strip()
                if key and value:
                    specs[key] = value
        if not specs:
            logger.debug(f"      - Ù‡ÛŒÚ† Ø±Ø¯ÛŒÙÛŒ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. HTML Ø®Ø§Ù… Ø¬Ø¯ÙˆÙ„: {specs_table.prettify()}")
        logger.debug(f"      - Ù…Ø´Ø®ØµØ§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {product_id} (Ú©Ø§Ù…Ù„): {json.dumps(specs, ensure_ascii=False, indent=4)}")
        return specs
    except requests.exceptions.RequestException as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}. Retry...")
        raise
    except Exception as e:
        logger.warning(f"      - Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª Ù…Ø­ØµÙˆÙ„ {product_id}: {e}")
        return {}

def get_and_parse_categories(session):
    logger.info(f"â³ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø²: {SOURCE_CATS_API_URL}")
    try:
        response = session.get(SOURCE_CATS_API_URL, timeout=30)
        response.raise_for_status()
        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ JSON Ø¨Ø§ Ù†Ú¯Ø§Ø´Øª ØµØ­ÛŒØ­ parent_id Ø¨Ù‡ real_id
        try:
            data = response.json()
            logger.info("âœ… Ù¾Ø§Ø³Ø® JSON Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù†Ú¯Ø§Ø´Øª ÙˆØ§Ù„Ø¯-ÙØ±Ø²Ù†Ø¯...")
            # Ø³Ø§Ø®Øª Ù†Ú¯Ø§Ø´Øª id Ø§ØµÙ„ÛŒ â†’ real_id Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ø§Ø² URL
            id_map = {}
            for c in data:
                real_id_match = re.search(r'/Store/List/(\d+)', c.get('url', '') or '')
                real_id = int(real_id_match.group(1)) if real_id_match else c.get('id')
                if c.get('id') is not None:
                    id_map[c['id']] = real_id

            final_cats = []
            for c in data:
                real_id = id_map.get(c.get('id'))
                if real_id is None:
                    continue
                parent_src = c.get('parent_id')
                parent_real = id_map.get(parent_src) if parent_src is not None else None
                final_cats.append({
                    "id": real_id,
                    "name": (c.get('name') or '').strip(),
                    "parent_id": parent_real
                })
            logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø² JSON Ø¨Ø§ ÙˆØ§Ù„Ø¯ ØµØ­ÛŒØ­ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
            return final_cats
        except json.JSONDecodeError:
            logger.warning("âš ï¸ Ù¾Ø§Ø³Ø® JSON Ù†ÛŒØ³Øª. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø³ HTML...")

        # Ù¾Ø§Ø±Ø³ HTML Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†
        soup = BeautifulSoup(response.text, 'lxml')
        all_menu_items = soup.select("li[id^='menu-item-']")
        if not all_menu_items:
            logger.error("âŒ Ù‡ÛŒÚ† Ø¢ÛŒØªÙ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø± HTML Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            return []
        logger.info(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ {len(all_menu_items)} Ø¢ÛŒØªÙ… Ù…Ù†Ùˆ Ù¾ÛŒØ¯Ø§ Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")

        cats_map = {}
        for item in all_menu_items:
            cat_id_raw = item.get('id', '')
            match = re.search(r'(\d+)', cat_id_raw)
            if not match:
                continue
            cat_menu_id = int(match.group(1))
            a_tag = item.find('a', recursive=False) or item.select_one("a")
            if not a_tag or not a_tag.get('href'):
                continue
            name = a_tag.text.strip()
            real_id_match = re.search(r'/Store/List/(\d+)', a_tag['href'])
            real_id = int(real_id_match.group(1)) if real_id_match else None
            if name and real_id and name != "#":
                cats_map[cat_menu_id] = {"id": real_id, "name": name, "parent_id": None}
        for item in all_menu_items:
            cat_id_raw = item.get('id', '')
            match = re.search(r'(\d+)', cat_id_raw)
            if not match:
                continue
            cat_menu_id = int(match.group(1))
            parent_li = item.find_parent("li", class_="menu-item-has-children")
            if parent_li:
                parent_id_raw = parent_li.get('id', '')
                parent_match = re.search(r'(\d+)', parent_id_raw)
                if parent_match:
                    parent_menu_id = int(parent_match.group(1))
                    if cat_menu_id in cats_map and parent_menu_id in cats_map:
                        cats_map[cat_menu_id]['parent_id'] = cats_map[parent_menu_id]['id']
        final_cats = list(cats_map.values())
        logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(final_cats)} Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
        return final_cats
    except requests.RequestException as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§: {e}")
        return None

# ==============================================================================
# --- Ú¯Ø±ÙØªÙ† Ù…Ø­ØµÙˆÙ„Ø§Øª Ù‡Ø± Ø¯Ø³ØªÙ‡ (ÙÙ‚Ø· Ù…ÙˆØ¬ÙˆØ¯Ù‡Ø§ Ùˆ ØªÙˆÙ‚Ù Ù‡ÙˆØ´Ù…Ù†Ø¯) ---
# ==============================================================================
@retry(
    retry=retry_if_exception_type((requests.exceptions.RequestException, requests.exceptions.HTTPError)),
    stop=stop_after_attempt(4),
    wait=wait_random_exponential(multiplier=1, max=10),
    reraise=True
)
def get_products_from_category_page(session, category_id, max_pages=10, delay=0.5):
    all_products_in_category = []
    seen_product_ids = set()
    page = 1
    error_count = 0
    while page <= max_pages:
        # --- Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ HTML (Ù¾Ø§Ø±Ø§Ù…ØªØ± text Ø­Ø°Ù Ø´Ø¯) ---
        if page == 1:
            url = f"{BASE_URL}/Store/List/{category_id}/2/2/0/0/0/10000000000"
        else:
            url = f"{BASE_URL}/Store/List/{category_id}/2/2/{page-1}/0/0/10000000000?brands=&isMobile=false"
        logger.info(f"â³ Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ø² HTML ØµÙØ­Ù‡ {page} ...")
        try:
            resp = session.get(url, timeout=30)
            if resp.status_code != 200:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª HTML ØµÙØ­Ù‡ {page} - status: {resp.status_code} - url: {url}")
                break
            soup = BeautifulSoup(resp.text, 'lxml')
            product_blocks = soup.select(".goods-record")
            html_products = []
            for block in product_blocks:
                a_tag = block.select_one("a")
                name_tag = block.select_one("span.goods-record-title")
                unavailable = block.select_one(".goods-record-unavailable")
                is_available = unavailable is None
                if a_tag and name_tag:
                    product_id = None
                    href = a_tag['href']
                    match = re.search(r'/Store/Detail/\d+/(\d+)', href)
                    if match:
                        product_id = match.group(1)
                    name = name_tag.text.strip()
                    price_tag = block.select_one("span.goods-record-price")
                    price_text = price_tag.text.strip() if price_tag else ""
                    price = re.sub(r'[^\d]', '', price_text) if price_text else "0"
                    image_tag = block.select_one("img.goods-record-image")
                    image_url = ""
                    if image_tag:
                        image_url = image_tag.get('data-src', '') or image_tag.get('src', '')
                        image_url = abs_url(image_url)
                    if is_available and product_id and product_id not in seen_product_ids:
                        specs = get_product_details(session, category_id, product_id)
                        html_products.append({
                            'id': product_id,
                            'name': name,
                            'category_id': category_id,
                            'price': price,
                            'stock': 1,
                            'image': image_url,
                            'specs': specs,
                        })
                        seen_product_ids.add(product_id)
                        time.sleep(random.uniform(delay, delay + 0.2))
            logger.info(f"ğŸŸ¢ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§ÙˆÙ„ÛŒÙ‡ (HTML) ØµÙØ­Ù‡ {page}: {len(html_products)}")

            # --- Ù…Ø­ØµÙˆÙ„Ø§Øª Lazy (ÙÙ‚Ø· Ù…ÙˆØ¬ÙˆØ¯Ù‡Ø§: Available=1) ---
            lazy_products = []
            lazy_page = 1
            referer_url = url
            while True:
                data = {
                    "ListViewType": 0,
                    "CatId": category_id,
                    "Order": 2,
                    "Sort": 2,
                    "LazyPageIndex": lazy_page,
                    "PageIndex": page - 1,
                    "PageSize": 24,
                    "Available": 1,  # ÙÙ‚Ø· Ù…ÙˆØ¬ÙˆØ¯Ù‡Ø§
                    "MinPrice": 0,
                    "MaxPrice": 10000000000,
                    "IsLazyLoading": "true"
                }
                headers = {
                    "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
                    "X-Requested-With": "XMLHttpRequest",
                    "Referer": referer_url
                }
                logger.info(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª LazyPageIndex={lazy_page} ØµÙØ­Ù‡ {page} ...")
                resp = session.post(f"{BASE_URL}/Store/ListLazy", data=data, headers=headers, timeout=30)
                if resp.status_code != 200:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª (Ú©Ø¯: {resp.status_code})")
                    break
                try:
                    result = resp.json()
                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù¾Ø§Ø³Ø® Ø¨Ù‡ json: {e}")
                    logger.error(f"Ù…ØªÙ† Ù¾Ø§Ø³Ø® Ø³Ø±ÙˆØ±:\n{resp.text[:500]}")
                    break
                if not result or "Goods" not in result or not result["Goods"]:
                    logger.info(f"ğŸš© Ø¨Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Lazy ØµÙØ­Ù‡ {page} Ø±Ø³ÛŒØ¯ÛŒÙ… ÛŒØ§ Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
                    break
                goods = result["Goods"]
                for g in goods:
                    if g.get("Availability", True):
                        product_id = str(g["Id"])
                        if product_id not in seen_product_ids:
                            specs = get_product_details(session, category_id, product_id)
                            lazy_products.append({
                                "id": product_id,
                                "name": g["Name"],
                                "category_id": category_id,
                                "price": g.get("Price", "0"),
                                "stock": 1,
                                "image": abs_url(g.get("ImageUrl", "")),
                                "specs": specs,
                            })
                            seen_product_ids.add(product_id)
                            time.sleep(random.uniform(delay, delay + 0.2))
                logger.info(f"ğŸŸ¢ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§ÛŒÙ† ØµÙØ­Ù‡ Lazy: {len([g for g in goods if g.get('Availability', True)])}")
                lazy_page += 1

            # Ø¬Ù…Ø¹ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§ÛŒÙ† ØµÙØ­Ù‡
            available_in_page = html_products + lazy_products
            if not available_in_page:
                logger.info(f"â›”ï¸ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ø¯Ø± ØµÙØ­Ù‡ {page} Ù†Ø¨ÙˆØ¯. Ø¨Ø±Ø±Ø³ÛŒ ØµÙØ­Ø§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
                break
            all_products_in_category.extend(available_in_page)
            page += 1
            error_count = 0
        except Exception as e:
            error_count += 1
            logger.error(f"    - Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙØ­Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª: {e} (ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·Ø§: {error_count})")
            if error_count >= 3:
                logger.critical(f"ğŸš¨ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…ØªÙˆØ§Ù„ÛŒ Ø¯Ø± Ø¯Ø³ØªÙ‡ {category_id} Ø¨Ù‡ {error_count} Ø±Ø³ÛŒØ¯! ØªÙˆÙ‚Ù Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡.")
                break
            time.sleep(2)
    logger.info(f"    - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ø§Ø² Ø¯Ø³ØªÙ‡ {category_id}: {len(all_products_in_category)}")
    return all_products_in_category

# ==============================================================================
# --- Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª (Ú©Ù„ÛŒØ¯ Ø¬Ø¯ÛŒØ¯: ÙÙ‚Ø· id) ---
# ==============================================================================
def load_cache():
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
            logger.info(f"âœ… Ú©Ø´ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± Ú©Ø´: {len(cache)}")
            return cache
    logger.info("âš ï¸ Ú©Ø´ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù…Ù„ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    return {}

def save_cache(products):
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(products, f, ensure_ascii=False, indent=4)
    logger.info(f"âœ… Ú©Ø´ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª: {len(products)}")

# ==============================================================================
# --- ØªÙˆØ§Ø¨Ø¹ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ ---
# ==============================================================================
def get_wc_categories():
    wc_cats, page = [], 1
    while True:
        try:
            res = requests.get(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), params={"per_page": 100, "page": page}, verify=False)
            res.raise_for_status()
            data = res.json()
            if not data:
                break
            wc_cats.extend(data)
            if len(data) < 100:
                break
            page += 1
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³: {e}")
            break
    logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒâ€ŒØ´Ø¯Ù‡: {len(wc_cats)}")
    return wc_cats

def get_all_wc_products_with_prefix(prefix="EWAYS-"):
    products = []
    page = 1
    while True:
        try:
            res = requests.get(f"{WC_API_URL}/products", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), params={
                "per_page": 100, "page": page
            }, verify=False)
            res.raise_for_status()
            data = res.json()
            if not data:
                break
            filtered = [p for p in data if p.get('sku', '').startswith(prefix)]
            products.extend(filtered)
            logger.debug(f"      - ØµÙØ­Ù‡ {page}: {len(filtered)} Ù…Ø­ØµÙˆÙ„ Ø¨Ø§ Ù¾ÛŒØ´ÙˆÙ†Ø¯ {prefix} Ù¾ÛŒØ¯Ø§ Ø´Ø¯.")
            if len(data) < 100:
                break
            page += 1
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ (ØµÙØ­Ù‡ {page}): {e}")
            break
    logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø§ Ù¾ÛŒØ´ÙˆÙ†Ø¯ '{prefix}' Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒâ€ŒØ´Ø¯Ù‡: {len(products)}")
    return products

def check_existing_category(name, parent):
    try:
        res = requests.get(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), params={
            "search": name, "per_page": 1, "parent": parent
        }, verify=False)
        res.raise_for_status()
        data = res.json()
        for cat in data:
            if cat["name"].strip() == name and cat["parent"] == parent:
                return cat["id"]
        return None
    except Exception as e:
        logger.debug(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ú†Ú© ÙˆØ¬ÙˆØ¯ Ø¯Ø³ØªÙ‡ '{name}' (parent: {parent}): {e}")
        return None

def transfer_categories_to_wc(source_categories):
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")
    wc_cats = get_wc_categories()
    wc_cats_map = {}
    for cat in wc_cats:
        key = (cat["name"].strip(), cat.get("parent", 0))
        wc_cats_map[key] = cat["id"]

    # ØªØ±ØªÛŒØ¨ ÙˆØ§Ù„Ø¯ Ù‚Ø¨Ù„ Ø§Ø² ÙØ±Ø²Ù†Ø¯
    sorted_cats = []
    id_to_cat = {cat['id']: cat for cat in source_categories}
    def add_with_parents(cat):
        if cat['parent_id'] and cat['parent_id'] in id_to_cat:
            parent_cat = id_to_cat[cat['parent_id']]
            if parent_cat not in sorted_cats:
                add_with_parents(parent_cat)
        if cat not in sorted_cats:
            sorted_cats.append(cat)
    for cat in source_categories:
        add_with_parents(cat)

    source_to_wc_id_map = {}
    transferred = 0
    for cat in tqdm(sorted_cats, desc="Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§"):
        name = cat["name"].strip()
        parent_id = cat.get("parent_id") or 0
        wc_parent = source_to_wc_id_map.get(parent_id, 0)
        lookup_key = (name, wc_parent)
        existing_id = check_existing_category(name, wc_parent)
        if existing_id:
            source_to_wc_id_map[cat["id"]] = existing_id
            logger.debug(f"âœ… Ø¯Ø³ØªÙ‡ '{name}' (parent: {wc_parent}) Ù‚Ø¨Ù„Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ (ID: {existing_id}). Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ÙˆØ¬ÙˆØ¯.")
            transferred += 1
            continue
        data = {"name": name, "parent": wc_parent}
        try:
            res = requests.post(f"{WC_API_URL}/products/categories", auth=(WC_CONSUMER_KEY, WC_CONSUMER_SECRET), json=data, verify=False)
            if res.status_code in [200, 201]:
                new_id = res.json()["id"]
                source_to_wc_id_map[cat["id"]] = new_id
                wc_cats_map[lookup_key] = new_id
                logger.debug(f"âœ… Ø¯Ø³ØªÙ‡ '{name}' (parent: {wc_parent}) Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ (ID: {new_id}).")
                transferred += 1
            else:
                error_data = res.json()
                if error_data.get("code") == "term_exists" and "data" in error_data and "resource_id" in error_data["data"]:
                    existing_id = error_data["data"]["resource_id"]
                    source_to_wc_id_map[cat["id"]] = existing_id
                    wc_cats_map[lookup_key] = existing_id
                    logger.info(f"âœ… Ø¯Ø³ØªÙ‡ '{name}' (parent: {wc_parent}) ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´Øª (ID: {existing_id}). Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² resource_id Ù…ÙˆØ¬ÙˆØ¯.")
                    transferred += 1
                else:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ '{name}' (parent: {wc_parent}): {res.text}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ø³Ø§Ø®Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ '{name}': {e}")
    logger.info(f"âœ… Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†ØªÙ‚Ù„â€ŒØ´Ø¯Ù‡: {transferred}/{len(source_categories)}")
    return source_to_wc_id_map

def process_price(price_value):
    try:
        price_value = float(re.sub(r'[^\d.]', '', str(price_value)))
        price_value /= 10
    except (ValueError, TypeError):
        return "0"
    if price_value <= 1:
        return "0"
    elif price_value <= 7000000:
        new_price = price_value + 260000
    elif price_value <= 10000000:
        new_price = price_value * 1.035
    elif price_value <= 20000000:
        new_price = price_value * 1.025
    elif price_value <= 30000000:
        new_price = price_value * 1.02
    else:
        new_price = price_value * 1.015
    return str(int(round(new_price, -4)))

@retry(
    retry=retry_if_exception_type((requests.exceptions.RequestException, requests.exceptions.HTTPError)),
    stop=stop_after_attempt(3),
    wait=wait_random_exponential(multiplier=1, max=10),
    reraise=True
)
def _send_to_woocommerce(sku, data, stats):
    try:
        auth = (WC_CONSUMER_KEY, WC_CONSUMER_SECRET)
        logger.debug(f"   - Ú†Ú© SKU {sku}...")
        check_url = f"{WC_API_URL}/products?sku={sku}"
        r_check = requests.get(check_url, auth=auth, verify=False, timeout=20)
        r_check.raise_for_status()
        existing = r_check.json()
        if existing:
            product_id = existing[0]['id']
            update_data = {
                "regular_price": data["regular_price"],
                "stock_quantity": data["stock_quantity"],
                "stock_status": data["stock_status"],
                "attributes": data["attributes"],
                "tags": data.get("tags", []),
                "categories": data.get("categories", []),  # Ù‡Ù…Ú¯Ø§Ù…â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ (ÙÙ‚Ø· leaf)
            }
            logger.debug(f"   - Ø¢Ù¾Ø¯ÛŒØª Ù…Ø­ØµÙˆÙ„ {product_id} Ø¨Ø§ {len(update_data['attributes'])} Ù…Ø´Ø®ØµÙ‡ ÙÙ†ÛŒ Ùˆ Ø¯Ø³ØªÙ‡ leaf...")
            res = requests.put(f"{WC_API_URL}/products/{product_id}", auth=auth, json=update_data, verify=False, timeout=20)
            res.raise_for_status()
            with stats['lock']:
                stats['updated'] += 1
        else:
            logger.debug(f"   - Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ {sku} Ùˆ {len(data['attributes'])} Ù…Ø´Ø®ØµÙ‡ ÙÙ†ÛŒ...")
            res = requests.post(f"{WC_API_URL}/products", auth=auth, json=data, verify=False, timeout=20)
            res.raise_for_status()
            with stats['lock']:
                stats['created'] += 1
    except requests.exceptions.HTTPError as e:
        logger.error(f"   âŒ HTTP Ø®Ø·Ø§ Ø¨Ø±Ø§ÛŒ SKU {sku}: {e.response.status_code} - Response: {e.response.text}")
        raise
    except Exception as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø±Ø§ÛŒ SKU {sku}: {e}")
        raise

@retry(
    retry=retry_if_exception_type((requests.exceptions.RequestException, requests.exceptions.HTTPError)),
    stop=stop_after_attempt(3),
    wait=wait_random_exponential(multiplier=1, max=10),
    reraise=True
)
def update_to_outofstock(product_id, stats):
    try:
        auth = (WC_CONSUMER_KEY, WC_CONSUMER_SECRET)
        update_data = {
            "stock_quantity": 0,
            "stock_status": "outofstock",
            "manage_stock": True
        }
        res = requests.put(f"{WC_API_URL}/products/{product_id}", auth=auth, json=update_data, verify=False, timeout=20)
        res.raise_for_status()
        logger.info(f"   âœ… Ù…Ø­ØµÙˆÙ„ {product_id} Ø¨Ù‡ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯ Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯.")
        with stats['lock']:
            stats['outofstock_updated'] += 1
    except Exception as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ø¯ÛŒØª Ù…Ø­ØµÙˆÙ„ {product_id} Ø¨Ù‡ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯: {e}")
        with stats['lock']:
            stats['failed'] += 1

# ==============================================================================
# --- Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø³Ø¦Ùˆ Ù…Ø­ÙˆØ± ---
# ==============================================================================
def smart_tags_for_product(product, cat_map):
    tags = set()
    name = product.get('name', '')
    specs = product.get('specs', {})
    cat_id = product.get('category_id')
    cat_name = cat_map.get(cat_id, '').strip()
    price = int(product.get('price', 0))

    name_parts = [w for w in re.split(r'\s+', name) if w and len(w) > 2]
    common_words = {'Ú¯ÙˆØ´ÛŒ', 'Ù…ÙˆØ¨Ø§ÛŒÙ„', 'ØªØ¨Ù„Øª', 'Ù„Ù¾ØªØ§Ù¾', 'Ù„Ù¾â€ŒØªØ§Ù¾', 'Ù…Ø¯Ù„', 'Ù…Ø­ØµÙˆÙ„', 'Ú©Ø§Ù„Ø§', 'Ø¬Ø¯ÛŒØ¯'}
    for part in name_parts[:2]:
        if part not in common_words:
            tags.add(part)

    if cat_name and cat_name not in common_words:
        tags.add(cat_name)

    important_keys = ['Ø±Ù†Ú¯', 'Color', 'Ø­Ø§ÙØ¸Ù‡', 'Ø¸Ø±ÙÛŒØª', 'Ø§Ù†Ø¯Ø§Ø²Ù‡', 'Ø³Ø§ÛŒØ²', 'Size', 'Ù…Ø¯Ù„', 'Ø¨Ø±Ù†Ø¯']
    for key, value in specs.items():
        if any(imp in key for imp in important_keys):
            val = value.strip()
            if 2 < len(val) < 30 and val not in common_words:
                tags.add(val)

    if price > 0:
        if price < 5000000:
            tags.add('Ø§Ù‚ØªØµØ§Ø¯ÛŒ')
        elif price > 20000000:
            tags.add('Ù„ÙˆÚ©Ø³')

    tags.add('Ø®Ø±ÛŒØ¯ Ø¢Ù†Ù„Ø§ÛŒÙ†')
    tags.add('Ú¯Ø§Ø±Ø§Ù†ØªÛŒ Ø¯Ø§Ø±')

    tags = {t for t in tags if t and len(t) <= 30 and t.lower() not in ['test', 'spam', 'Ù…Ø­ØµÙˆÙ„', 'Ú©Ø§Ù„Ø§']}

    return [{"name": t} for t in sorted(tags)]

# ==============================================================================
# --- Ø§Ø±Ø³Ø§Ù„ Ù…Ø­ØµÙˆÙ„ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø¨Ø§ Ø¨Ø±Ú†Ø³Ø¨ Ù‡ÙˆØ´Ù…Ù†Ø¯ ---
# ==============================================================================
def process_product_wrapper(args):
    product, stats, category_mapping, cat_map = args
    try:
        wc_cat_id = category_mapping.get(product.get('category_id'))
        if not wc_cat_id:
            logger.warning(f"   âš ï¸ Ø¯Ø³ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {product.get('id')} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø±Ø¯ Ú©Ø±Ø¯Ù†...")
            with stats['lock']:
                stats['no_category'] = stats.get('no_category', 0) + 1
            return
        specs = product.get('specs', {})
        if not specs:
            logger.warning(f"   âš ï¸ Ù…Ø´Ø®ØµØ§Øª Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {product.get('id')} Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ø§Ø±Ø³Ø§Ù„ Ø¨Ø¯ÙˆÙ† attributes.")
        attributes = []
        position = 0
        for key, value in specs.items():
            attributes.append({
                "name": key,
                "options": [value],
                "position": position,
                "visible": True,
                "variation": False
            })
            position += 1

        tags = smart_tags_for_product(product, cat_map)

        wc_data = {
            "name": product.get('name', 'Ø¨Ø¯ÙˆÙ† Ù†Ø§Ù…'),
            "type": "simple",
            "sku": f"EWAYS-{product.get('id')}",
            "regular_price": process_price(product.get('price', 0)),
            "categories": [{"id": wc_cat_id}],  # ÙÙ‚Ø· Ø¨Ø±Ú¯ (leaf)
            "images": [{"src": abs_url(product.get("image"))}] if product.get("image") else [],
            "stock_quantity": product.get('stock', 0),
            "manage_stock": True,
            "stock_status": "instock" if product.get('stock', 0) > 0 else "outofstock",
            "attributes": attributes,
            "tags": tags,
            "status": "publish"
        }
        _send_to_woocommerce(wc_data['sku'], wc_data, stats)
        time.sleep(random.uniform(0.5, 1.5))
    except Exception as e:
        logger.error(f"   âŒ Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØµÙˆÙ„ {product.get('id', '')}: {e}")
        with stats['lock']:
            stats['failed'] += 1

# ==============================================================================
# --- Ù¾Ø±ÛŒÙ†Øª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø´Ø§Ø®Ù‡â€ŒØ§ÛŒ Ùˆ Ù…Ø±ØªØ¨ (Ù†Ø³Ø®Ù‡Ù” Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ pid) ---
# ==============================================================================
def print_products_tree_by_leaf(products_by_pid, categories):
    cat_map = {cat['id']: cat['name'] for cat in categories}
    tree = defaultdict(list)
    for pid, p in products_by_pid.items():
        catid = p.get('category_id')
        tree[catid].append(p)
    for catid in sorted(tree, key=lambda x: (0 if x is None else int(x))):
        logger.info(f"Ø¯Ø³ØªÙ‡ [{catid}] {cat_map.get(int(catid), 'Ù†Ø§Ù…Ø´Ø®Øµ') if catid else 'Ù†Ø§Ù…Ø´Ø®Øµ'}:")
        for p in sorted(tree[catid], key=lambda x: int(x['id'])):
            logger.info(f"   - {p['name']} (ID: {p['id']})")

# ==============================================================================
# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ---
# ==============================================================================
def main():
    session = login_eways(EWAYS_USERNAME, EWAYS_PASSWORD)
    if not session:
        logger.error("âŒ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ Ù¾Ù†Ù„ eways Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
        return

    all_cats = get_and_parse_categories(session)
    if not all_cats:
        logger.error("âŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯.")
        return
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ 1: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯: {len(all_cats)}")

    SELECTED_IDS_STRING = "16777:all-allz"
    parsed_selection = parse_selected_ids_string(SELECTED_IDS_STRING)
    logger.info(f"âœ… Ø§Ù†ØªØ®Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø¯Ù„Ø®ÙˆØ§Ù‡: {parsed_selection}")

    # Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³Ú©Ø±Ù¾ Ùˆ Ø§Ù†ØªÙ‚Ø§Ù„ (ÙˆØ§Ù„Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³)
    scrape_categories, transfer_categories = get_selected_categories_according_to_selection(parsed_selection, all_cats)
    logger.info(f"âœ… Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³Ú©Ø±Ù¾: {[cat['name'] for cat in scrape_categories]}")
    logger.info(f"âœ… Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ (Ø¨Ø§ ÙˆØ§Ù„Ø¯Ù‡Ø§): {[cat['name'] for cat in transfer_categories]}")

    category_mapping = transfer_categories_to_wc(transfer_categories)
    if not category_mapping:
        logger.error("âŒ Ù†Ú¯Ø§Ø´Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø®Ø§ØªÙ…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯.")
        return
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ 5: Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù†Ú¯Ø§Ø´Øªâ€ŒØ´Ø¯Ù‡: {len(category_mapping)}")

    # Ú©Ø´ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø¨Ù‡ ÙØ±Ù…Øª Ø¬Ø¯ÛŒØ¯ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†
    cached_products_raw = load_cache()
    cached_products = normalize_cache(cached_products_raw, transfer_categories)

    # ==============================================================================
    # --- Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ throttle ØªØ·Ø¨ÛŒÙ‚ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ (ØµÙ Ø¯Ø³ØªÙ‡ + ØªØ§Ø®ÛŒØ± Ù…Ø´ØªØ±Ú©) ---
    # ==============================================================================
    selected_ids = [cat['id'] for cat in scrape_categories]
    all_products = {}
    all_lock = Lock()
    cat_queue = Queue()
    for cat_id in selected_ids:
        cat_queue.put(cat_id)

    # throttle
    shared = {'delay': 0.5}
    delay_lock = Lock()
    min_delay = 0.2
    max_delay = 2.0
    num_cat_workers = 3

    logger.info(f"\nâ³ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ØªÙ…Ø§Ù… Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ù‡Ù…Ù‡ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ...")
    pbar = tqdm(total=len(selected_ids), desc="Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§")
    pbar_lock = Lock()

    def cat_worker():
        while True:
            try:
                cat_id = cat_queue.get_nowait()
            except Exception:
                break
            with delay_lock:
                d = shared['delay']
            try:
                products_in_cat = get_products_from_category_page(session, cat_id, 10, d)
                with all_lock:
                    for product in products_in_cat:
                        key = f"{product['id']}|{cat_id}"
                        all_products[key] = product
                with delay_lock:
                    if len(products_in_cat) > 0:
                        shared['delay'] = max(min_delay, shared['delay'] - 0.05)
                    else:
                        shared['delay'] = min(max_delay, shared['delay'] + 0.1)
            except Exception as e:
                logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø³ØªÙ‡ {cat_id}: {e}")
                with delay_lock:
                    shared['delay'] = min(max_delay, shared['delay'] + 0.2)
                logger.warning(f"ğŸš¦ Ø³Ø±Ø¹Øª Ú©Ù… Ø´Ø¯: delay={shared['delay']:.2f}")
            finally:
                with pbar_lock:
                    pbar.update(1)
                cat_queue.task_done()

    threads = []
    for _ in range(num_cat_workers):
        t = Thread(target=cat_worker, daemon=True)
        t.start()
        threads.append(t)
    for t in threads:
        t.join()
    pbar.close()

    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ 6: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØµÙˆÙ„Ø§Øª Ú©Ø§Ù…Ù„ Ø´Ø¯. (Ú©Ù„ id|cat: {len(all_products)})")

    # ØªØ¨Ø¯ÛŒÙ„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ Ù†Ú¯Ø§Ø´Øª Ø¨Ø± Ø§Ø³Ø§Ø³ pid Ø¨Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ø¹Ù…ÛŒÙ‚â€ŒØªØ±ÛŒÙ† Ø²ÛŒØ±Ø´Ø§Ø®Ù‡ (leaf)
    canonical_products = condense_products_to_leaf(all_products, transfer_categories)
    logger.info(f"ğŸ§­ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø³ Ø§Ø² Ù†Ú¯Ø§Ø´Øª Ø¨Ù‡ Ø¹Ù…ÛŒÙ‚â€ŒØªØ±ÛŒÙ† Ø²ÛŒØ±Ø´Ø§Ø®Ù‡: {len(canonical_products)}")
    print_products_tree_by_leaf(canonical_products, transfer_categories)

    # ==============================================================================
    # --- Ø§Ø¯ØºØ§Ù… Ø¨Ø§ Ú©Ø´ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª ØªØºÛŒÛŒØ±Ú©Ø±Ø¯Ù‡/Ø¬Ø¯ÛŒØ¯ (ØªØ´Ø®ÛŒØµ ØªØºÛŒÛŒØ± Ø¯Ø³ØªÙ‡ Ù‡Ù… Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯) ---
    # ==============================================================================
    updated_cache = {}
    changed_items = {}
    new_products_by_category = {}

    for pid, p in canonical_products.items():
        old = cached_products.get(pid)
        # ØªØ´Ø®ÛŒØµ ØªØºÛŒÛŒØ±: Ù‚ÛŒÙ…ØªØŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØŒ Ù…Ø´Ø®ØµØ§Øª ÛŒØ§ Ø¯Ø³ØªÙ‡
        if (not old or
            old.get('price') != p.get('price') or
            old.get('stock') != p.get('stock') or
            old.get('specs') != p.get('specs') or
            old.get('category_id') != p.get('category_id')):
            changed_items[pid] = p
            updated_cache[pid] = p
            cat_id = p['category_id']
            new_products_by_category[cat_id] = new_products_by_category.get(cat_id, 0) + 1
        else:
            updated_cache[pid] = old

    changed_count = len(changed_items)
    logger.info(f"âœ… Ù…Ø±Ø­Ù„Ù‡ 7: Ø§Ø¯ØºØ§Ù… Ø¨Ø§ Ú©Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª ØªØºÛŒÛŒØ±Ø´Ø¯Ù‡/Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„: {changed_count}")

    logger.info("ğŸ“Š Ø¢Ù…Ø§Ø± Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯/ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ (leaf):")
    cat_map = {cat['id']: cat['name'] for cat in transfer_categories}
    for cat_id, count in sorted(new_products_by_category.items(), key=lambda x: -x[1]):
        logger.info(f"  - {cat_map.get(cat_id, str(cat_id))}: {count} Ù…Ø­ØµÙˆÙ„")

    save_cache(updated_cache)

    # ==============================================================================
    # --- Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯ (Ø¨Ø¯ÙˆÙ† ØªÚ©Ø±Ø§Ø±) ---
    # ==============================================================================
    logger.info("\nâ³ Ø´Ø±ÙˆØ¹ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯...")
    wc_products = get_all_wc_products_with_prefix("EWAYS-")
    extracted_skus = {f"EWAYS-{pid}" for pid in canonical_products.keys()}
    to_oos_ids = set()

    # Ø¨Ø§ ØªÚ©ÛŒÙ‡ Ø¨Ø± Ú©Ø´ Ù‚Ø¨Ù„ÛŒ (Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡) + ÙˆÙˆÚ©Ø§Ù…Ø±Ø³
    for pid in cached_products.keys():
        sku = f"EWAYS-{pid}"
        if sku not in extracted_skus:
            for wc_p in wc_products:
                if wc_p['sku'] == sku and wc_p.get('stock_status') != "outofstock":
                    to_oos_ids.add(wc_p['id'])

    for wc_p in wc_products:
        if wc_p['sku'] not in extracted_skus and wc_p.get('stock_status') != "outofstock":
            to_oos_ids.add(wc_p['id'])

    outofstock_queue = Queue()
    for pid in to_oos_ids:
        outofstock_queue.put(pid)

    outofstock_count = len(to_oos_ids)
    logger.info(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ø¯ÛŒØª Ø¨Ù‡ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯: {outofstock_count}")

    # ==============================================================================
    # --- Ø§Ø±Ø³Ø§Ù„ ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª ØªØºÛŒÛŒØ±Ú©Ø±Ø¯Ù‡/Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³ (Ø¨Ø§ Ø¯Ø³ØªÙ‡ leaf) ---
    # ==============================================================================
    stats = {'created': 0, 'updated': 0, 'failed': 0, 'no_category': 0, 'outofstock_updated': 0, 'lock': Lock()}
    logger.info(f"\nğŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø§Ø±Ø³Ø§Ù„ {changed_count} Ù…Ø­ØµÙˆÙ„ (ØªØºÛŒÛŒØ±Ø´Ø¯Ù‡/Ø¬Ø¯ÛŒØ¯) Ø¨Ù‡ ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")

    product_queue = Queue()
    for p in changed_items.values():
        product_queue.put(p)

    def worker():
        while True:
            try:
                product = product_queue.get_nowait()
            except Exception:
                break
            process_product_wrapper((product, stats, category_mapping, cat_map))
            product_queue.task_done()

    num_workers = 3
    threads = []
    for _ in range(num_workers):
        t = Thread(target=worker)
        t.start()
        threads.append(t)
    for t in threads:
        t.join()

    logger.info(f"\nğŸš§ Ø´Ø±ÙˆØ¹ Ø¢Ù¾Ø¯ÛŒØª {outofstock_count} Ù…Ø­ØµÙˆÙ„ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± ÙˆÙˆÚ©Ø§Ù…Ø±Ø³...")

    def outofstock_worker():
        while True:
            try:
                product_id = outofstock_queue.get_nowait()
            except Exception:
                break
            update_to_outofstock(product_id, stats)
            time.sleep(random.uniform(0.5, 1.5))
            outofstock_queue.task_done()

    outofstock_threads = []
    for _ in range(num_workers):
        t = Thread(target=outofstock_worker)
        t.start()
        outofstock_threads.append(t)
    for t in outofstock_threads:
        t.join()

    logger.info("\n===============================")
    logger.info(f"ğŸ“¦ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ (Ù…ÙˆØ¬ÙˆØ¯): {changed_count}")
    logger.info(f"ğŸŸ¢ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: {stats['created']}")
    logger.info(f"ğŸ”µ Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯Ù‡: {stats['updated']}")
    logger.info(f"ğŸŸ  Ø¢Ù¾Ø¯ÛŒØª Ø¨Ù‡ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯: {stats['outofstock_updated']}")
    logger.info(f"ğŸ”´ Ø´Ú©Ø³Øªâ€ŒØ®ÙˆØ±Ø¯Ù‡: {stats['failed']}")
    logger.info(f"ğŸŸ¡ Ø¨Ø¯ÙˆÙ† Ø¯Ø³ØªÙ‡: {stats.get('no_category', 0)}")
    logger.info("===============================\nØªÙ…Ø§Ù…!")

if __name__ == "__main__":
    main()
